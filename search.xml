<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JUC并发包-lucks]]></title>
    <url>%2F2019%2F09%2F21%2FJUC%E5%B9%B6%E5%8F%91%E5%8C%85-lucks%2F</url>
    <content type="text"><![CDATA[AQS简介AbstractQueuedSynchronizer抽象类（以下简称AQS）是整个java.util.concurrent包的核心。在JDK1.5时，Doug Lea引入了J.U.C包，该包中的大多数同步器都是基于AQS来构建的。AQS框架提供了一套通用的机制来管理同步状态（synchronization state）、阻塞/唤醒线程、管理等待队列。 我们所熟知的ReentrantLock、CountDownLatch、CyclicBarrier等同步器，其实都是通过内部类实现了AQS框架暴露的API，以此实现各类同步器功能。这些同步器的主要区别其实就是对同步状态（synchronization state）的定义不同。 AQS框架，分离了构建同步器时的一系列关注点，它的所有操作都围绕着资源——同步状态（synchronization state）来展开，并替用户解决了如下问题： 资源是可以被同时访问？还是在同一时间只能被一个线程访问？（共享/独占功能） 访问资源的线程如何进行并发管理？（等待队列） 如果线程等不及资源了，如何从等待队列退出？（超时/中断） 这其实是一种典型的模板方法设计模式：父类（AQS框架）定义好骨架和内部操作细节，具体规则由子类去实现。AQS框架将剩下的一个问题留给用户： 什么是资源？如何定义资源是否可以被访问？ 我们来看下几个常见的同步器对这一问题的定义： 同步器 资源的定义 ReentrantLock 资源表示独占锁。State为0表示锁可用；为1表示被占用；为N表示重入的次数 CountDownLatch 资源表示倒数计数器。State为0表示计数器归零，所有线程都可以访问资源；为N表示计数器未归零，所有线程都需要阻塞。 Semaphore 资源表示信号量或者令牌。State≤0表示没有令牌可用，所有线程都需要阻塞；大于0表示由令牌可用，线程每获取一个令牌，State减1，线程没释放一个令牌，State加1。 ReentrantReadWriteLock 资源表示共享的读锁和独占的写锁。state逻辑上被分成两个16位的unsigned short， 原理简述AQS框架分离了构建同步器时的一系列关注点，它的所有操作都围绕着资源——同步状态（synchronization state）来展开因此，围绕着资源，衍生出三个基本问题： 同步状态（synchronization state）的管理 阻塞/唤醒线程的操作 线程等待队列的管理 同步状态同步状态，其实就是资源。AQS使用单个int（32位）来保存同步状态，并暴露出getState、setState以及compareAndSetState操作来读取和更新这个状态。 12345678910111213141516171819/** * 同步状态. */private volatile int state;protected final int getState() &#123; return state;&#125;protected final void setState(int newState) &#123; state = newState;&#125;/** * 以原子的方式更新同步状态. * 利用Unsafe类实现 */protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 线程的阻塞/唤醒使用了LockSupport类 等待队列等待队列，是AQS框架的核心，整个框架的关键其实就是如何在并发状态下管理被阻塞的线程。等待队列是严格的FIFO队列，是Craig，Landin和Hagersten锁（CLH锁）的一种变种，采用双向链表实现，因此也叫CLH队列。 结点定义CLH队列中的结点是对线程的包装，结点一共有两种类型：独占（EXCLUSIVE）和共享（SHARED）。每种类型的结点都有一些状态，其中独占结点使用其中的CANCELLED(1)、SIGNAL(-1)、CONDITION(-2)，共享结点使用其中的CANCELLED(1)、SIGNAL(-1)、PROPAGATE(-3)。 结点状态 值 描述 CANCELLED 1 取消。表示当前结点被中断或超时，需要移出队列 SIGNAL -1 发信号。表示后驱结点被阻塞了（当前结点在入队后、阻塞前，应确保将其prev结点类型改为SIGNAL，以便prev结点取消或释放时将当前结点唤醒。） CONDITION -2 Condition专用。表示当前结点在Condition队列中，因为等待某个条件而被阻塞了 PROPAGATE -3 传播。适用于共享模式（比如连续的读操作结点可以依次进入临界区，设为PROPAGATE有助于实现这种迭代操作。） INITIAL 0 默认。新结点会处于这种状态 AQS使用CLH队列实现线程的结构管理，而CLH结构正是用前一结点某一属性表示当前结点的状态，之所以这种做是因为在双向链表的结构下，这样更容易实现取消和超时功能。 next指针：用于维护队列顺序，当临界区的资源被释放时，头结点通过next指针找到队首结点。prev指针：用于在结点（线程）被取消时，让当前结点的前驱直接指向当前结点的后驱完成出队动作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293static final class Node &#123; // 共享模式结点 static final Node SHARED = new Node(); // 独占模式结点 static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; /** * INITAL： 0 - 默认，新结点会处于这种状态。 * CANCELLED： 1 - 取消，表示当前结点被中断或超时，需要移出队列； * SIGNAL： -1- 发信号，表示后续结点被阻塞了；（当前结点在入队后、阻塞前，应确保将其prev结点类型改为SIGNAL，以便prev结点取消或释放时将当前结点唤醒。） * CONDITION： -2- Condition专用，表示当前结点在Condition队列中，因为等待某个条件而被阻塞了； * PROPAGATE： -3- 传播，适用于共享模式。（比如连续的读操作结点可以依次进入临界区，设为PROPAGATE有助于实现这种迭代操作。） * * waitStatus表示的是后续结点状态，这是因为AQS中使用CLH队列实现线程的结构管理，而CLH结构正是用前一结点某一属性表示当前结点的状态，这样更容易实现取消和超时功能。 */ volatile int waitStatus; // 前驱指针 volatile Node prev; // 后驱指针 volatile Node next; // 结点所包装的线程 volatile Thread thread; // Condition队列使用，存储condition队列中的后继节点 Node nextWaiter; Node() &#123; &#125; Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125;&#125; /** * 添加节点到等待队列, 如果有必须就初始化Node. * 自选CAS添加等待队列尾部. 直到成功 * @param node the node to insert * @return node's predecessor */ private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; /** * Creates and enqueues node for current thread and given mode. * 创建node并入队, 设置当期线程和指定锁的类型 是独占还是共享 * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 尝试快速设置 将node加入队列尾. 如果失败了就交个end方法. 自旋去 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; CAS操作CAS，即CompareAndSet，在Java中CAS操作的实现都委托给一个名为UnSafe类， 方法名 修饰符 描述 compareAndSetState protected final CAS修改同步状态值 compareAndSetHead private final CAS修改等待队列的头指针 compareAndSetTail private final CAS修改等待队列的尾指针 compareAndSetWaitStatus private static final CAS修改结点的等待状态 compareAndSetNext private static final CAS修改结点的next指针 ReentrantLock的公平策略原理 假设现在有3个线程：ThreadA、ThreadB、ThreadC，一个公平的独占锁，3个线程会依次尝试去获取锁：ReentrantLock lock=new ReentrantLock(true); 线程操作如下 1234567891011//ThreadA lock//ThreadB lock//ThreadC lock//ThreadA release//ThreadB release//ThreadC release TA首先获得锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public void lock() &#123; sync.lock();&#125; static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125;&#125; public final void acquire(int arg) &#123; // arg =1 if ( !tryAcquire(arg) //尝试获取资源 &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; /** * * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; //acquires =1 final Thread current = Thread.currentThread(); //获得当期线程 int c = getState(); // 获得同步状态 if (c == 0) &#123; // 0代表锁并未被占用 //如果等待队列中. 在当期线程前没有其他线程. 则用CAS获得锁 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; //更新成功. 将锁的占有线程设置为当期线程 setExclusiveOwnerThread(current); return true; &#125; &#125; //c!=0 说明锁被占用. 判断是否是重入的情况 else if (current == getExclusiveOwnerThread()) &#123; // state+1 int nextc = c + acquires; // 重入次数过大. 溢出了 if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); //设置状态 setState(nextc); return true; &#125; return false; &#125;public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; ReentrantLock中 state的状态代表 0 表示锁可用. 1 锁占用 &gt;1 表示锁被占用 值表示被重入的次数 TB开始获取锁先lock-&gt;sync.lock(1) -&gt; 如下 12345678910111213141516171819202122232425262728293031323334353637383940414243public final void acquire(int arg) &#123; // arg =1 if ( //尝试获取锁 这里是失败的. 因为A已经获得锁了. c!=0 并且 current != getExclusiveOwnerThread() !tryAcquire(arg) //尝试获取资源 //将当期线程包装成节点加入等待队列 &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 中断自己 selfInterrupt();&#125;private Node addWaiter(Node mode) &#123; // 将线程包装成节点 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 视图快速将自己设置成尾节点. 先尝试一次, 如果成功就不用end() 失败. 自旋去 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 将节点加入等待队列的尾部 enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 现在TB已经加入等待队列尾部了. 接下来会调用acquireQueued方法. ，这也是AQS中最重要的方法之一 123456789101112131415161718192021222324252627//从等待列表中获得node的前节点, 果然获取不到. 就要确保前置节点能唤醒自己的情况下. 自己进入阻塞状态,// 正常情况下: 该方法会一直阻塞当期线程. 知道获得锁才返回. 但是如果执行过程中,抛异常(tryAcquire方法) 那么会将当期节点移除等待队列. 继续向上抛出异常. final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 获得node的前一个节点p final Node p = node.predecessor(); // 如果p是首节点, 然后去尝试获得锁. 因为TA在持有锁, 这里返回false if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 将自己设置为head 表示自己占用锁 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 判断是否需要阻塞线程. 也就是判断TB是否要阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 在AQS中，等待队列中的线程都是阻塞的，当某个线程被唤醒时，只有该线程是首结点（线程）时，才有权去尝试获取锁。 上述方法中，将ThreadB包装成结点插入队尾后，先判断ThreadB是否是首结点（注意不是头结点，头结点是个dummy结点），发现确实是首结点（node.predecessor==head），于是调用tryAcquire尝试获取锁，但是获取失败了（此时ThreadA占有着锁），就要判断是否需要阻塞当前线程。 判断是否需要阻塞线程 12345678910111213141516171819202122232425262728293031323334private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus;//获得node的前节点的等待状态 if (ws == Node.SIGNAL) // 如果是SIGNAL(-1): 后置节点需要唤醒. 自己就可以放心阻塞了. 将来会唤醒我的. /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; // 也就是CANCELLED 取消状态. 说明前置节点因为中断或者取消. 需要在等待队列中移除 /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. * 知道遇到前置节点的状态小于等为止. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); // 将前置节点的后置节点设置成自己. pred.next = node; &#125; else &#123; //如果既不是SIGNAL也不是CANCELED. 那么就将前置节点的waitStatus设置成SIGNAL. /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; //阻塞在这里. 并检查线程是否被中断. private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; TC开始获取锁流程和TB获取锁是一样的. 1)尝试获取锁, 失败. 因为A在占用. 2)将自己包装成node.并加入等待队列尾部 3) 检查自己的前置节点是否是首节点 false. 4) 检查自己是否需要阻塞. 检查前置节点的等待状态发现是0(因为刚加入). 那就将其设置为SIGNAL(-1). 自己进入阻塞状态 TA释放锁TA使用完了临界区资源. 需要释放锁了. 调用unlock 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void unlock() &#123; sync.release(1);&#125;// arg =1public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; // h要值. 表示有线程在等待. h.waitStatus !=0 表示h不是新加入的节点. 在h!=null的情况. waitStatus==0 那么说明后置节点在唤醒中 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); //释放成功, 则唤醒首节点. return true; &#125; return false;&#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; // 将当期状态-1 //获得锁的线程和释放锁的线程不一样. 抛异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // c ==0 表示锁处于空闲状态了 if (c == 0) &#123; free = true; // 将锁的拥有者设置为null setExclusiveOwnerThread(null); &#125; // 将状态设置为 更新状态值 setState(c); return free;&#125;private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. 获得首节点的状态 */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 将状态设置为0 表示后置节点即将被唤醒 /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. * */ Node s = node.next; //得到后置节点 //当后置节点为null或者s.waitStats=1 也就是取消状态时 if (s == null || s.waitStatus &gt; 0) &#123; s = null; //从尾部开始向前遍历. 直到找到一个waitStatus&lt;=0的. 并将其唤醒 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //正常状态下 直接唤醒后置节点的线程 if (s != null) LockSupport.unpark(s.thread);&#125; TB被唤醒并继续执行现在head把他的后置节点唤醒了. ThreadB会继续从以下位置开始执行，先返回一个中断标识，用于表示ThreadB在阻塞期间有没被中断过： 123456789101112131415161718192021222324252627 //继续从这里开始执行 .返回中断标识, 表示自己在阻塞期间没有被状态过. private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125;final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 因为自旋的缘故. 会继续执行下面代码 12345678910final Node p = node.predecessor(); //唤醒线程的节点的前置节点是head, 尝试获取锁. 能成功的 //tryAcquire加锁逻辑和A的加锁逻辑一样 1) 获得当期线程 2)获得状态 3 状态==0 判断是否存在排队的前辈 设置状态为1, 将锁的拥有者设置为自己 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 将直接的节点设置为Head setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; TB和TC释放锁TB释放锁的逻辑和TA释放锁的逻辑一致. 在醒来后.返回中断标识. 获取锁. 成功将自己设置为锁的使用者.并将自己设置为head. TC释放锁, 发现自己没有后置节点了. 从队尾开始遍历.发现tail == 当前的自己. 什么也不做 ReentrantLock的非公平策略原理公平锁和非公平锁获取逻辑主要差别: 123456789101112131415161718192021222324252627final void lock() &#123; // 1直接尝试获取锁. 不管等待队列 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //这里和公平锁相比缺少了是否有线程排在自己之前等待(hasQueuedPredecessors)判断. if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 这就导致了 大家一起竞争锁. CountDownLatch分析AQS的共享功能 假设现在有3个线程，ThreadA、ThreadB、mainThread，CountDownLatch初始计数为1：CountDownLatch switcher = new CountDownLatch(1);线程的调用时序如下： 12345//ThreadA调用await()方法等待//ThreadB调用await()方法等待//主线程main调用countDown()放行 AQS共享功能的原理创建CountDownLatchCountDownLatch的创建没什么特殊，调用唯一的构造器，传入一个初始计数值，内部实例化一个AQS子类： CountDownLatch switcher = new CountDownLatch(1); 12345678public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException("count &lt; 0"); this.sync = new Sync(count);&#125;Sync(int count) &#123; setState(count);&#125; 初始计数值count其实就是同步状态值，在CountDownLatch中，同步状态State表示CountDownLatch的计数器的初始大小。 ThreadA调用await()方法等待CountDownLatch的await方法是响应中断的，该方法其实是调用了AQS的acquireSharedInterruptibly方法： 12345678910111213141516public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) //响应线程中断 throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) // 尝试获取锁. &lt;0 就是失败 ,&gt;0 成功, 0 无锁状态. 这里当然是失败的 以为我们初始化的状态count =1. doAcquireSharedInterruptibly(arg);&#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; 之前说了在CountDownLatch中，同步状态State表示CountDownLatch的计数器的初始值，当State==0时，表示无锁状态，且一旦State变为0，就永远处于无锁状态了，此时所有线程在await上等待的线程都可以继续执行。而在ReentrantLock中，State==0时，虽然也表示无锁状态，但是只有一个线程可以重置State的值。这就是共享锁的含义。 继续向下执行，ThreadA尝试获取锁失败后，会调用doAcquireSharedInterruptibly： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); //将当期线程加入等待队列尾部. 和独占锁的流程一样, 区别在于mode是共享锁类型 boolean failed = true; try &#123; for (;;) &#123; // node也就是当期节点的前置节点 final Node p = node.predecessor(); if (p == head) &#123; // 当期节点的前置节点如果是head int r = tryAcquireShared(arg); // 尝试获得共享锁 这里当然也是失败的 if (r &gt;= 0) &#123; //成功 键 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 如果node的前置节点不是head节点. or 获取共享锁失败. if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; //这个方法和独占锁一样, 都是判断自己是否要阻塞 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus;// 前置节点的等待状态 if (ws == Node.SIGNAL) // SIGNAL的化 自己就可以安心等待被唤醒了 /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; // 如果是CANCELED. 进入循环向前查找. 知道找到一个&lt;0的节点 /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //都不是 也就是锁状态可能是 0 -2 -3 /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); // 将前置节点设置为SIGNAL. &#125; return false; &#125; //将自己阻塞掉. 唤醒时会返回中断状态. private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; TA的加入等待队列并阻塞了. ThreadB调用await()方法等待流程和步骤2完全相同，调用后ThreadB也被加入到等待队列中：1)尝试获取共享锁. 失败. 2) 将TB包装成共享节点node 加入等待队列. 3) 查看当期节点的前置节点是否和head相等. 如果相等. 就再次尝试获取共享锁. 继续失败 4) 判断自己是否需要被阻塞. 查看前置节点的等待状态 如果==SIGNAL 自己可以安心等待被唤醒了 如果&gt;0 也就是CANCELED. 就向前遍历链表. 直到找到一个小于等于0 并将节点的next设置称自己. 自己的prev设置成它. 如果 小于等于0. 那么cas的将前置节点的状态设置为SIGNAL. 5) 将自己阻塞. 主线程main调用countDown()放行ThreadA和ThreadB调用了await()方法后都在等待了，现在主线程main开始调用countDown()方法，该方法调用后，ThreadA和ThreadB都会被唤醒，并继续往下执行，达到类似门栓的作用。 123public void countDown() &#123; sync.releaseShared(1); //释放共享锁&#125; 该方法内部调用了AQS的releaseShared方法，先尝试一次释放锁，tryReleaseShared方法是一个钩子方法，由CountDownLatch实现，当同步State状态值首次变为0时，会返回true： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; //尝试一次释放锁 doReleaseShared(); return true; &#125; return false;&#125;protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero // 自旋的释放锁 知道count ==0 for (;;) &#123; int c = getState(); // 获取共享锁状态 if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125;private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. * 释放锁之后 将等待队列中的线程唤醒 */ for (;;) &#123; // 唤醒下一个等待的节点. 自旋是为了保证state能够设置成功. Node h = head; // 拿到首节点 if (h != null &amp;&amp; h != tail) &#123; //哨兵 int ws = h.waitStatus; // 获得首节点的等待状态 if (ws == Node.SIGNAL) &#123; // ==SIGNAL CAS的将状态设置为0 直到成功 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); //唤醒 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125;//唤醒逻辑 private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; //获得当期节点的等待状态 if (ws &lt; 0) // 小于0 将其设置为0 compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; // 获得后置节点 if (s == null || s.waitStatus &gt; 0) &#123; //如果是null或者 是CANCELED. 从尾部开始向前遍历. 直到找到下于等于0的节点 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) //唤醒他 LockSupport.unpark(s.thread);&#125; TA在阻塞除开始执行12345678910111213141516171819202122232425262728private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); //将当期线程加入等待队列尾部. 和独占锁的流程一样, 区别在于mode是共享锁类型 boolean failed = true; try &#123; for (;;) &#123; // node也就是当期节点的前置节点 final Node p = node.predecessor(); if (p == head) &#123; // 当期节点的前置节点如果是head int r = tryAcquireShared(arg); // 尝试获得共享锁 这里当然也是失败的 if (r &gt;= 0) &#123; //成功 键 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 从这里被唤醒. if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); //如果阻塞期间被中断. 抛出中断异常作为相应中断 &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 由于自旋的存在. 它将获取自己的前置节点和head比较, 如果等于. 就尝试获取共享锁. 会成功的. 以为我们已经将count自旋的减到0了. 接下来执行setHeadAndPropagate 123456789101112131415161718192021222324252627282930//将当期节点设置为head. 并尝试唤醒并释放后续节点 private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node);// 将自己设置为head /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway */ //判断是否要唤醒后置节点. if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; //唤醒后置节点. 也就是唤醒B if (s == null || s.isShared()) doReleaseShared(); &#125; &#125; ThreadB从原阻塞处继续向下执行TB也在同样的位置醒来. 1) 判断前置节点是否为head , 2) 尝试获得共享锁. 3)将自己设置为head. 并判断是否需要唤醒后置节点. 请参考多线程进阶AQS剖析 多线程进阶]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>并发包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bean之AbstractBeanFactory类createBean方法]]></title>
    <url>%2F2019%2F09%2F18%2FBean%E4%B9%8BAbstractBeanFactory%E7%B1%BBcreateBean%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[创建bean实例的核心方法，填充bean实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162@Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Creating instance of bean '" + beanName + "'"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. //确保bean类在这一点上已经被解析，并且 //在动态解析类的情况下克隆bean定义 //不能存储在共享合并bean定义中 Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. try &#123; //对override属性进行标记及验证 mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, "Validation of method overrides failed", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. //给BeanPostProcessors一个机会来返回代理来替代真正的实例 实质上是执行InstantiationAwareBeanPostProcessor接口的postProcessBeforeInstantiation()方法返回代理类, 然后执行BeanPostProcessor#postProcessAfterInitialization方法 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); // 当经过前置处理后的返回结果如果不为空，那么会直接略过后续bean的创建直接返回结果。这一特性虽然很容易被忽略，但是 // 却起着至关重要的作用，我们熟知的AOP功能就是基于这里的判断的 if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, "BeanPostProcessor before instantiation of bean failed", ex); &#125; try &#123; // 核心方法创建bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isTraceEnabled()) &#123; logger.trace("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance; &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123; // A previously detected exception with proper bean creation context already, // or illegal singleton state to be communicated up to DefaultSingletonBeanRegistry. throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, "Unexpected exception during bean creation", ex); &#125; &#125; protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Invalid destruction signature", ex); &#125; return exposedObject; &#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[@Autowired注解背后的故事]]></title>
    <url>%2F2019%2F09%2F12%2FAutowired%E6%B3%A8%E8%A7%A3%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%85%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[AutowiredAnnotationBeanPostProcessor类注册和执行AutowiredAnnotationBeanPostProcessor是BeanPostProcessor的子类. so它的执行就是是在AbstractApplicationContext#refresh(): 1.registerBeanPostProcessors(beanFactory)-&gt; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this) 将BeanPostProcessors类的注入初始化了 123456789101112131415161718192021222324252627282930313233343536373839// Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; //beanFactory就是DefaultListableBeanFactory. DefaultListableBeanFactory没有实现PriorityOrdered. if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, register the BeanPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : orderedPostProcessorNames) &#123; //这里是触发点.DefaultListableBeanFactory.getBean() BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class)一直跟踪这个方法,路径是AbstractBeanFactory#getBean -&gt; AbstractBeanFactory#doGetBean() -&gt; AbstractAutowireCapableBeanFactory#createBean() -&gt; AbstractAutowireCapableBeanFactory#doCreateBean() 也就是下面的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; //执行实现了MergedBeanDefinitionPostProcessor类的方法postProcessMergedBeanDefinition() //(AutowiredAnnotationBeanPostProcessor#postProcessMergedBeanDefinition() applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Invalid destruction signature", ex); &#125; return exposedObject; &#125; protected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof MergedBeanDefinitionPostProcessor) &#123; MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp; bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName); &#125; &#125; &#125; protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; if (mbd.hasPropertyValues()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance"); &#125; else &#123; // Skip property population phase for null instance. return; &#125; &#125; // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; //AutowiredAnnotationBeanPostProcessor的postProcessAfterInstantiation 一直返回true if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; if (!continueWithPropertyPopulation) &#123; return; &#125; PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE); PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; //AutowiredAnnotationBeanPostProcessor#postProcessProperties 执行对注入 PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; pvs = pvsToUse; &#125; &#125; &#125; if (needsDepCheck) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; if (pvs != null) &#123; applyPropertyValues(beanName, mbd, bw, pvs); &#125; &#125; 先了解一下InstantiationAwareBeanPostProcessor接口 这个接口主要作用在于目标对象的实例化过程中需要处理的事情，包括实例化对象的前后过程以及实例的属性设置 123456789101112131415161718public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor &#123; /** * 是最先执行的方法，它在目标对象实例化之前调用，该方法的返回值类型是Object，我们可以返回任何类型的值。 * 由于这个时候目标对象还未实例化，所以这个返回值可以用来代替原本该生成的目标对象的实例(比如代理对象)。 * 如果该方法的返回值代替原本该生成的目标对象， */ Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException; /** * 在目标对象实例化之后调用，这个时候对象已经被实例化，但是该实例的属性还未被设置都是null */ boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException; /** * 对属性值进行修改(这个时候属性值还未被设置，但是我们可以修改原本该设置进去的属性值)。 */ PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException;&#125; AutowiredAnnotationBeanPostProcessor#postProcessMergedBeanDefinition方法这个方法的主要作用就是将那些标记@Autowired、@Value、@Inject注解的Element封装成InjectionMetadata. 放入injectionMetadataCache中. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101@Overridepublic void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName) &#123; //获取InjectionMetadata对象（其实InjectionElement集合） InjectionMetadata metadata = findAutowiringMetadata(beanName, beanType, null); metadata.checkConfigMembers(beanDefinition);&#125;private InjectionMetadata findAutowiringMetadata(String beanName, Class&lt;?&gt; clazz, @Nullable PropertyValues pvs) &#123; // Fall back to class name as cache key, for backwards compatibility with custom callers. String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName()); // Quick check on the concurrent map first, with minimal locking. 先在缓存中获取 InjectionMetadata metadata = this.injectionMetadataCache.get(cacheKey); //metadata ==null || metadata.targetClass != clazz if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; synchronized (this.injectionMetadataCache) &#123; metadata = this.injectionMetadataCache.get(cacheKey); if (InjectionMetadata.needsRefresh(metadata, clazz)) &#123; if (metadata != null) &#123; metadata.clear(pvs); &#125; metadata = buildAutowiringMetadata(clazz); //加入缓存中 this.injectionMetadataCache.put(cacheKey, metadata); &#125; &#125; &#125; return metadata;&#125; //找到哪些属性需要被自动装配，也就是查找被@Autowired、@Value、@Inject注解标记的元素，封装为InjectionMetadataprivate InjectionMetadata buildAutowiringMetadata(final Class&lt;?&gt; clazz) &#123; //注入元素的集合 List&lt;InjectionMetadata.InjectedElement&gt; elements = new ArrayList&lt;&gt;(); Class&lt;?&gt; targetClass = clazz; do &#123; final List&lt;InjectionMetadata.InjectedElement&gt; currElements = new ArrayList&lt;&gt;(); // 遍历所有属性上标记@Autowired、@Value、@Inject ReflectionUtils.doWithLocalFields(targetClass, field -&gt; &#123; AnnotationAttributes ann = findAutowiredAnnotation(field); if (ann != null) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Autowired annotation is not supported on static fields: " + field); &#125; return; &#125; boolean required = determineRequiredStatus(ann); currElements.add(new AutowiredFieldElement(field, required)); &#125; &#125;); // 遍历所有方法上标记@Autowired、@Value、@Inject ReflectionUtils.doWithLocalMethods(targetClass, method -&gt; &#123; Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(method); if (!BridgeMethodResolver.isVisibilityBridgeMethodPair(method, bridgedMethod)) &#123; return; &#125; AnnotationAttributes ann = findAutowiredAnnotation(bridgedMethod); if (ann != null &amp;&amp; method.equals(ClassUtils.getMostSpecificMethod(method, clazz))) &#123; if (Modifier.isStatic(method.getModifiers())) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Autowired annotation is not supported on static methods: " + method); &#125; return; &#125; if (method.getParameterCount() == 0) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Autowired annotation should only be used on methods with parameters: " + method); &#125; &#125; boolean required = determineRequiredStatus(ann); PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz); currElements.add(new AutowiredMethodElement(method, required, pd)); &#125; &#125;); elements.addAll(0, currElements); targetClass = targetClass.getSuperclass(); &#125; while (targetClass != null &amp;&amp; targetClass != Object.class); return new InjectionMetadata(clazz, elements);&#125;@Overridepublic PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) &#123; //这里基本是从cache中获取元数据. 也不排除 InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs); try &#123; //执行注入 metadata.inject(bean, beanName, pvs); &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, "Injection of autowired dependencies failed", ex); &#125; return pvs;&#125; @Autowired和@Resource这两个注解是我们开发过程中经常使用的注解@Autowired默认按类型装配，默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，例如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用@Resource，默认安装名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行安装名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。@Autowired、@Value、@Inject 注解的实现大体逻辑是先获取哪些需要注入的属性，然后调用反射进行赋值 finishBeanFactoryInitialization()-&gt;DefaultListableBeanFactory#preInstantiateSingletons()解决注册表中的也就是@AutoConfigurationPackage注解扫描注册DefaultListableBeanFactory#beanDefinitionNames属性中的注入 最终的调用路径也是AbstractBeanFactory#getBean -&gt; AbstractBeanFactory#doGetBean() -&gt; AbstractAutowireCapableBeanFactory#createBean() -&gt; AbstractAutowireCapableBeanFactory#doCreateBean().]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件]]></title>
    <url>%2F2019%2F09%2F10%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[rabbitmqExchangeTypes direct bindingKey和routingKey完全匹配的queue中 Fanout 不管routingKey是什么.他都会把消息发送到与exchange绑定的所有queue中 Topic exchange将消息发送到routingKey模式匹配的queue中. #表示匹配多个单词 *表示匹配一个单词 单词之间用.分隔 RPC 客户端C发送请求（消息）时，在消息的属性（MessageProperties）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败. 服务器端S处理完消息后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性。客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理. virtualhost每一个vhost本质上是一个mini-rabbitmq server，分别管理各自的exchange和bindings。vhost相当于物理的server，可以为不同app提供边界隔离，使得应用安全的运行在不同的vhost实例上，相互之间不会干扰。producer和consumer连接rabbit server需要指定一个vhost。 消息存储 disc 则需要对exchange／queue／delivery mode都要设置成durable模式。当RabbitMQ失效了，message仍然可以在重启之后恢复. ram RabbitMQ处理message的效率要高很多，ram和disc两种方式的效率比大概是3:1。如果在有其它HA手段保障的情况下，选用ram方式是可以提高消息队列的工作效率的。如果使用ram方式，RabbitMQ能够承载的访问量则取决于可用的内存大小。 队列详情普通队列通常队列由两部分组成：一部分是AMQQueue，负责AMQP协议相关的消息处理，即接收生产者发布的消息、向消费者投递消息、处理消息confirm、acknowledge等等；另一部分是BackingQueue，它提供了相关的接口供AMQQueue调用，完成消息的存储以及可能的持久化工作等。 在RabbitMQ中BackingQueue又由5个子队列组成：Q1, Q2, Delta, Q3和Q4。RabbitMQ中的消息一旦进入队列，不是固定不变的，它会随着系统的负载在队列中不断流动，消息不断发生变化。在BackingQueue中，消息的生命周期分为4个状态： Alpha：消息的内容和消息索引都在RAM中。Q1和Q4的状态。 Beta：消息的内容保存在DISK上，消息索引保存在RAM中。Q2和Q3的状态。 Gamma：消息内容保存在DISK上，消息索引在DISK和RAM都有。Q2和Q3的状态。 Delta：消息内容和索引都在DISK上。Delta的状态。 上述就是RabbitMQ的多层队列结构的设计，我们可以看出从Q1到Q4，基本经历RAM-&gt;DISK-&gt;RAM这样的过程。这样设计的好处是：当队列负载很高的情况下，能够通过将一部分消息由磁盘保存来节省内存空间，当负载降低的时候，这部分消息又渐渐回到内存，被消费者获取，使得整个队列具有很好的弹性。从Q1-&gt;Q2-&gt;delta这一个过程是将消息逐步从RAM移动到DISK的过程，而delta-&gt;Q3-&gt;Q4是从DISK逐步移动到RAM的过程。 引起消息流动主要有两方面因素：其一是消费者获取消息；其二是由于内存不足引起消息换出到磁盘。RabbitMQ在系统运行时会根据消息传输的速度计算一个当前内存中能够保存的最大消息数量（Target_RAM_Count），当内存中的消息数量大于该值时，就会引起消息的流动。进入队列的消息，一般会按照Q1-&gt;Q2-&gt;Delta-&gt;Q3-&gt;Q4的顺序进行流动，但是并不是每条消息都一定会经历所有的状态，这个取决于当前系统的负载状况。 通常在负载正常时，如果消息被消费的速度不小于接收新消息的速度，对于不需要保证可靠不丢的消息极可能只会有Alpha状态。对于durable=true的消息，它一定会进入gamma状态，若开启publish confirm机制，只有到了这个阶段才会确认该消息已经被接受，若消息消费速度足够快，内存也充足，这些消息也不会继续走到下一状态。 通常在系统负载较高时，已接受到的消息若不能很快被消费掉，这些消息就会进入到很深的队列中去，增加处理每个消息的平均开销。因为要花更多的时间和资源处理“积压”的消息，所以用于处理新来的消息的能力就会降低，使得后来的消息又被积压进入很深的队列，继续加大处理每个消息的平均开销，这样情况就会越来越恶化，使得系统的处理能力大大降低。 镜像队列 镜像队列是一种特殊的队列. 它内部包裹了一个普通BackingQueue做本地消息持久化处理，在此基础上增加了将消息,ack复制到所有镜像的功能,所有对mirror_queue_master的操作，会通过组播GM的方式同步到各slave节点。GM负责消息的广播，mirror_queue_slave负责回调处理，而master上的回调处理是由coordinator负责完成。mirror_queue_slave中包含了普通的BackingQueue进行消息的存储，master节点中BackingQueue包含在mirror_queue_master中由AMQQueue进行调用。 消息的发布（除了Basic.Publish之外）与消费都是通过master节点完成。master节点对消息进行处理的同时将消息的处理动作通过GM广播给所有的slave节点，slave节点的GM收到消息后，通过回调交由mirror_queue_slave进行实际的处理。 对于Basic.Publish，消息同时发送到master和所有slave上，如果此时master宕掉了，消息还发送slave上，这样当slave提升为master的时候消息也不会丢失。 组播（GM） GM,Guarenteed Multicast. GM模块实现的一种可靠的组播通讯协议，该协议能够保证组播消息的原子性，即保证组中活着的节点要么都收到消息要么都收不到。它的实现大致如下： 将所有的节点形成一个循环链表，每个节点都会监控位于自己左右两边的节点，当有节点新增时，相邻的节点保证当前广播的消息会复制到新的节点上；当有节点失效时，相邻的节点会接管保证本次广播的消息会复制到所有的节点。在master节点和slave节点上的这些gm形成一个group，group（gm_group）的信息会记录在mnesia中。不同的镜像队列形成不同的group。从master节点发出gm后，消息顺着链表依次传送到所有的节点，由于所有节点组成一个循环链表，master节点对应的gm最终会收到自己发送的消息，这个时候master节点就知道消息已经复制到所有的slave节点了。 节点的失效 如果某个slave失效了，系统除了做些记录外几乎啥都不做：master依旧是master，客户端不需要采取任何行动，或者被通知slave失效。 如果master失效了，那么slave中的一个必须被选中为master。被选中作为新的master的slave通常是最老的那个，因为最老的slave与前任master之间的同步状态应该是最好的。然而，需要注意的是，如果存在没有任何一个slave与master完全同步的情况，那么前任master中未被同步的消息将会丢失。 集群镜像队列1RabbitMQ集群的队列(Queue)在默认的情况下只存在单一节点（node）上。我们也可以把队列配置成同时存在在多个节点上，也就是说队列可以被镜像到多个节点上。发布(publish)到镜像队列上的消息(message)会被复制(replicated)到所有的节点上。一个镜像队列包含一个主(master)和多个从(slave)。 非同步的Slave（unsynchronised slave）在rabbitmq中同步(synchronised)是用来描述master和slave之间的数据状态是否一致的。如果slave包含master中的所有message，则这个slave是synchronised，如果这个slave并没有包含master中所有的message，则这个slave是unsynchronised。 在什么情况下会出现unsynchronisedslave当一个新slave加入到一个镜像队列时，这时这个新slave是空的，而master中这时可能包含之前接收到的消息。假设这时master包含了N条消息，这是第N+1条消息被添加到这个镜像队列中，这个新slave会从这个第N+1条消息开始接收。此时这个slave就是unsynchronised slave。随着前5条消息从镜像队列中被消费掉（consumed）, 这个slave变成了synchronised。 slave 重新加入(rejoin)到镜像队列时，也会出现非同步的情况。一个slave要重新加入镜像队列之前，slave可能已经接收了一些消息，要重新加入镜像队列，就要清空自己之前已经接收的所有消息，好像自己是第一次加入队列一样。（slave在很多情况下会需要重新加入镜像队列，例如：网络分区(networkpartition)） 服务可用性（Availablity）与数据可靠性（Reliability） 选主的方式. 当master因为某种原因失效时，最早加入镜像队列的slave被提升成master。 单节点 如果RabbitMQ集群只有一个broker节点，那么该节点的失效将导致整个服务临时性的不可用，并且可能会导致message的丢失（尤其是在非持久化message存储于非持久化queue中的时候）。当然可以将所有的publish的message都设置为持久化的，并且使用持久化的queue，但是这样仍然无法避免由于缓存导致的问题：因为message在发送之后和被写入磁盘并执行fsync之间存在一个虽然短暂但是会产生问题的时间窗。通过publisher的confirm机制能够确保客户端知道哪些message已经存入磁盘，尽管如此，一般不希望遇到因单点故障导致的服务不可用。 普通队列 如果RabbitMQ集群是由多个broker节点构成的，那么从服务的整体可用性上来讲，该集群对于单点失效是有弹性的，但是同时也需要注意：尽管exchange和binding能够在单点失效问题上幸免于难，但是queue和其上持有的message却不行，这是因为queue及其内容仅仅存储于单个节点之上，所以一个节点的失效表现为其对应的queue不可用。 镜像队列 RabbitMQ的镜像队列机制是将queue镜像到cluster中其他的节点之上。在通常的用法中，针对每一个镜像队列都包含一个master和多个slave，分别位于于不同的节点。slave会准确地按照master执行命令的顺序进行命令执行，故slave与master上维护的状态应该是相同的。所有动作都只会向master发送，然后由master将命令执行的结果广播给slave们，故看似从镜像队列中的消费操作实际上是在master上执行的。 在该实现下，如果镜像队列中的一个master失效了，集群自动选出一个slave（最老的slave）提升为master，此后message可以继续发送到队列上。 RabbitMQ的镜像队列同时支持publisher confirm和事务两种机制。在事务机制中，只有当前事务在全部镜像queue中执行之后，客户端才会收到Tx.CommitOk的消息。同样的，在publisher confirm机制中，向publisher进行当前message确认的前提是该message被全部镜像所接受了。 kafka]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[innoDB相关]]></title>
    <url>%2F2019%2F09%2F05%2FinnoDB%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[体系结构 InnoDB存储引擎由多个内存块组成. 可以认为这些内存块组成了一个很大的内存池. 主要负责: 维护所有进程/线程需要访问的多个内部数据数据 缓存磁盘上的数据. 方便快速的读取.同时在对磁盘文件进行修改之前在这里缓存 重做日志redo log缓冲 后台线程innoDB是个多线程模型. 因此很多线程都具有不同的分工. Master Thread 核心的后台线程. 负责将缓冲池中的数据异步刷新到磁盘. 保证一致性. 包括脏页, 合并插入缓冲. undo页回收. IO Thread 存储引擎中使用了大量的AIO来处理写IO请求. 而IO Thread工作主要负责这些IO请求的回调(callback)处理. 大致分为几类: read, write, insert buffer, log. purge Thread. 在事务提交之后. 其所使用的undolog可能不再需要了. 因此需要此线程来回收已经使用并分配的undo页. page cleaner Thread 脏页的刷新操作 内存 缓冲池innoDB存储引擎是基于磁盘存储的. 存储其中的记录是按照页的方式进行管理. 由于CPU速度和磁盘速度的鸿沟, 采用缓冲池技术来提供数据库整体效率. 缓冲池是一块简单的内存区域. 在数据库读取页时. 首先从磁盘中读到的页存放到缓冲池中, 这个操作称为页FIX, 下次读取相同页的时候, 判断是否在缓冲池中, 若在称该页在缓冲池中被命中. 直接读取.否则读取磁盘上的页. 对于数据库中的页的修改操作. 则首先修改缓冲池中的页. 然后以一定频率刷新到磁盘中上. 缓冲池中的页刷新到磁盘上. 不是每次页发生修改时就触发. 而是通过checkpoint机制刷新回磁盘上. 具体来说缓冲池中的页类型有: 索引页. 数据页, undo页, 插入缓冲, 自适应哈希索引. innoDB存储的锁信息. 数据字典信息等. innoDB如何管理缓冲池这个很大的内存区域(LRU list,Free list, Flush list)InnoDB使用优化过的LRU(最近最少使用)算法来管理. 在LRU列表中加入了midpoint位. 新读的页,虽然是最新访问的页. 并不是直接放入LRU列表首部. 而是放入到LRU列表中的midpoint位置. 这个算法在innoDB中成为 midpoint insertion strategy. 默认情况下 midpoint在LRU列表的5/8位置. midpoint之前的称为new列表 之后的称为old列表 可以简单理解为new列表是热点数据. 为什么不采用朴素的LRU算法呢 是因为若是直接把页放在LRU列表首部. 那么某些sql操作可能会使缓冲池中的页被刷新出. 影响缓冲池的效率. 例如索引和数据扫描操作 这里操作可能访问很多页,或者全部页. 而这些操作通常来说仅在这次查询中需要. 斌不是热点数据. 如果放在了首部. 很可能需要的热点数据页从LRU列表中移除. 下次需要读取该页的时候, 就要去磁盘中读取了. 当数据库当启动时,LRU列表是空的.这些页都存放在free列表中,从需要从缓冲池分页时, 先在free列表中查找是否有空闲页, 有在在free中删除, 放入LRU列表中. 否则根据LRU淘汰算法. 淘汰尾端的页. 将腾出来的内存空间分配给新的页. 重做日志缓冲innoDB引擎首先将重做日志信息放入到这个缓冲区.然后按一定频率将其刷新到重做日志文件中, 这个缓冲区不用很大. 只要保证一秒内事务量在这个缓冲区大小之内即可. 通常8M大小能够满足绝大部分需求.重做日志在三种情况下会将缓冲区日志刷新到日志文件中. master Thread每个一秒将重做日志缓冲刷新到重做日志文件中去. 每个事务提交时, 将重做日志缓冲区刷新到重做日志文件中. 当重做日志缓冲池剩余空间小于1/2时. InnDB的关键特性插入缓冲(提升性能)在innoDB存储引擎中.主键是行唯一标识符. 因此插入聚集索引是顺序的. 同时页中的行记录按照主键顺序存放的. 因此这种情况下的插入式非常快的.并不是所有主键插入都是顺序的. 比如主键是UUID.插入就是随机的. 或者指定主键的值插入. 也会是随机的. 在大部分应用中，很少出现表中只有一个聚集索引的情况，更多情况下，表上会有多个非聚集的secondary index （辅助索引）对于非聚集索引的插入和更新. innodb不是每一次都插入到索引页中. 而是判断插入的非聚集索引是否在缓冲池中. 若在直接插入. 若不再插入insert buffer对象中. 然后再以一定的频率和情况进行insert buffer和索引页子节点的merge合并操作. 这通常将多个插入合并到一个操作.这就大大提高了对于非聚集索引的插入性能. 这里存在一个问题. 当写密集时. insert buffer会占用过多的内存缓冲区. 默认最大是1/2. 如果这时宕机了, 会导致大量的insert buffer并没有合并到实际的非聚集索引中去. 导致这是恢复会需要很长时间. 极端的时候可能要几小时 change buffer. 可以视为insert buffer的升级版, innoDB对DML语句都进行缓存.分别是insert/update/delete buffer.和之前的insert buffer一样, change buffer依然适用于非唯一的辅助索引. 写缓充 双写(提升页可靠性)双写分为两部分: 一部分是内存中的doublewrite buffer 大小为2MB. 另一部分是物理磁盘上共享表空间中连续的128页, 即两个区, 大小同样为2MB. 当对缓冲区脏页进行刷新时. 先将脏页复制到doublewrite buffer中. 之后通过doublewrite buffer再分两次, 每次1M顺序的写入磁盘上的共享表空间, 马上调用asyc函数, 同步磁盘. 自适应哈希索引哈希是一种非常快的查找方法. 一般情况下时间复杂大度O(1), 仅需要一次查找就能定位数据. 而B+树的查找次数, 取决于树的高度. 如果是3层 则需要3次查找.innoDB会监控对表上各个索引的查询. 如果观察到建立哈希索引能提升查询效率.则建立哈希索引, 这种行为叫自适应哈希索引.AHI. innoDB会根据访问分频率和模式来自动的为热点查询建立哈希索引. 条件是以同样的查询条件查询了一定次数, 比如100.页通过该模式访问了N次. 其中N=页中记录*1/16. 异步IO为了提高磁盘操作效率. 数据库采用异步IO(AIO)的方式来处理磁盘操作.即每次IO操作都不需要等待上次IO的结束. AIO的另一个优势是可以进行IO merge.也就是将多个AIO和并未一个IO 刷新邻接页当刷新一个脏页时. innoDB引擎会检测改页所在的区(extent)的所有页. 如果有脏页. 那么一起刷新. 在结合AIO可以将多个IO合并为一个IO. 索引和算法B+树是传统意义上的索引. 叶子节点不是具体行的数据, 而是一页数据. 当查找都数据所在的页. 在通过二分查找的方式去查找具体数据. B+树索引B+树是为磁盘或其他直接存取辅助设备设计的一种平衡树. 在树中, 所有的记录节点都是按键值的大小顺序存放在同一层的叶子节点上. 由各个节点的指针相互连接 聚集索引聚集索引是按照每张表的主键构造一颗B+树. 同时叶子节点中存放的即为整张表的行记录数据. 叶子节点称之为数据页. 每个数据页都通过一个双向链表进行连接. 聚集索引的存储并不是物理上连续的. 而是逻辑上连续的. 页时按照主键的顺序排序. 每个页中的记录也是通过双向链表进行维护的. 辅助索引也叫非聚集索引. 叶子节点并不包含行记录的全部数据,叶子节点出了包含键值之外. 每个叶子节点中的索引行中还包含了一个书签.该书签用来告诉InnoDB引擎哪里可以找到与索引相对应的行数据.由于InnoDB存储引擎表示索引组织表,因此InnoDB存储引擎的辅助索引书签就是响应的聚集索引键. 辅助索引的存在并不影响数据在聚集索引中的组织. 当通过辅助索引来查询数据时. InnoDB存储引擎会遍历辅助索引并通过叶级别指针获得指向主键索引的主键, 然后在通过主键索引来找到一条完整的行记录. 举例来说. 如果一颗高为3的辅助索引树中查找数据. 首先通过3次查询找到主键. 然后在通过3次对聚集索引的查询. 最终找到一个完整的行数据. 因此需要6次逻辑IO访问以得到最终的一个数据页. 联合索引由多个表字段组成的索引. 注意联合索引的顺序. 比如索引(a,b,c) where a= “” 是可以应用到索引的 where a= “” and b= “” 可以应用 where a= “” and b =”” and c=’’ 可以 where a= “” order by b 可以. 顺便还使用了索引的有序性. where a=”” order by c 应用了索引但没有应用有序性. 因为c是无序的. where a =”” and c=”” 不能应用索引 覆盖索引innoDB支持覆盖索引. 即从辅助索引就可以得到查询记录.而不需要查询聚集索引中的记录. 使用覆盖索引的好处是, 辅助索引不包含整行记录的所有信息.故其大小要远远小于聚集索引.因此可以减少IO操作. 覆盖索引的通俗说法就是, 查询条件和返回的数据. 都是索引的内容. 覆盖索引的另一个好处在于对统计而言的. multi-range read优化针对range ref eq-ref类的查询的优化, 将随机IO改变为顺序IO. 查询得到的辅助索引键值放在一个缓存中, 辅助索引中的数据是根据辅助索引键值排序的. 将缓存中键值按照RowId进行排序. 根据RowId的顺利访问实际的数据文件. index condition pushdown优化首先索引查询时. 先按照索引来查找记录, 在根据where条件过滤数据. 在支持index condition pushdown之后, 在索引查找数据的时候就会判断是否可以进行where条件过滤, 也就是将where条件的部分过滤操作放在存储引擎层. 在某些查询下. 可以大大减少上层sql对数据的索取. 从而提升了性能. 全文检索倒序索引全文索引通常使用倒序索引实现, 和索引引用B+树一样. 倒序索引也一种数据结构. 它是以辅助表的形式存在的. 它在辅助表中存储了单词和单词在一个或者文档中所在位置的映射. inverted file index 其表现形式为{单词, 单词所在文档的ID} full inverted index 其表现形式为{单词,(单词所在文档ID, 在具体文档中的位置)} innoDB的全文索引采用的full inverted index的形式. 在innoDB中存在ilist, 因此在全文索引中, 有两个列, 一个是ward列 另一个是ilist字段. 并且在word上有索引, 此外ilist字段存放了position信息, 锁锁的类型InnoDB支持两种行级锁: 共享锁(S LOCK) 允许事务读一行数据 排它锁(X LOCK) 允许事务删除或更新一行数据 X锁和任何锁都不兼容. S锁也只和S锁兼容. 兼容值的是对同一行数据而言的 此外 innoDB支持引擎多颗粒度锁定. 这种锁允许事务在行级上锁和表级上的锁同时存在. 为了支持在不同颗粒度上进行加锁操作. InnoDB支持一种额外的锁方式. 称之为意向锁(intention Lock). 意向锁是将锁定对象分成多个层次. 意向锁意味着事务希望在更细粒度上进行加锁. 意向共享锁(IS LOCK) 事务想要获得一张表中某几行的共享锁. 意向排他锁(IX LOCK) 事务想要获得一张表中某几行的排他锁. 一致性非锁定读是指innoDB通过多版本控制的方式来读取当前执行时间数据库中的数据, 如果读取正在执行UPDATE或者DELETE操作,这时读取操作不会等待行的X锁释放. 相反的innoDB存储引擎会去读取快照数据. 快照数据是指行的之前版本数据. 改实现是通过undo段来完成的. 这是没有任何开销的. 读取快照数据也不需要上锁,因为没有事务会修改历史数据. 非锁定读大大提高了数据库的并发性. 但在不通事务隔离级别下的, 读取方式是同的. MVCC(多版本并发控制) 快照数据就是当期行的之前的历史版本. 每行记录有多个版本. 一个行记录有多个快照数据. 一致性读锁定在某些情况下用户需要显示地对数据库读取操作进行加锁, 保证数据逻辑的一致性. 而这种对数据库支持加锁语句. innoDB对于select语句支持两种一致性锁定读: select….for upadte 在读取是添加行级X锁 select … lock share mode. 在读取是添加行级别S锁 行锁的3种算法 record lock 单个行记录上锁 总是去锁住索引记录, 没有任何一个索引, 就使用隐士的主键进行锁定单条索引记录上加锁，record lock锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么innodb会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。所以说当一条sql没有走任何索引时，那么将会在每一条聚集索引后面加X锁，这个类似于表锁，但原理上和表锁应该是完全不同的。 Gap lock 间隙锁 锁定一个范围 不包含记录本身在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身. Next-key lock: 1+2 锁定一个范围 并且锁定记录本身 phantom problem(幻像问题)phantom problem问题是指 在一个事务下, 连续执行两次同样的SQL语句可能导致不同的结果. 第二次sql可能会返回之前不存在的行. innoDB的默认隔离级别 repeatable read, 通过使用Next-key lock算法来避免phantom problem问题. 在这算法下 对于索引的扫描, 不仅是锁住扫描的索引. 而且还锁住这些索引覆盖的范围(GAP) 因此在这个范围内插入是不允许的. 这样就避免了另外的事务在这个范围内插入数据导致不可重复读问题. 丢失更新问题丢失更新问题是数据级别解决不了. 发送情况是A事务select 数据A. B事务也select A 这是A事务更新数据A为C提交, 然后B事务更新数据A为D. 最后导致C数据丢失. 这个问题需要程序加锁 做全局排序. 死锁innodb采用两种方式解决死锁问题. 1 被动方式: 使用超时锁. 2 主动的方式. wait-for graph(等待图)原理是采用两张链表 1 锁信息链. 2 事务等待链 通过上述链表可以构造出一张图. 如果途中出现回路. 就代表着死锁. 通过深度优先算法. 检测环的存在. 如果出现死锁. innodb选择undo量最小的事务进行回滚. 事务redo日志重做日志用来保证事务的持久性. 由两部分组成, 一部分是内存中的redo log buffer.其实是易失的. 一部分是磁盘文件系统中的redo log file. innodb是事务存储引擎. 通过force log at commit机制实现事务的持久性. 即当事务提交时.必须先将该事务的所有日志写入到重做日志文件中并做持久化.待事务的commit操作完成才算完成, 这里指的日志是重做日志. 在innodb引擎中分为两部分 1是redo 2 undo. redo保证事务的持久性. undo 用来帮助事务回滚和MVCC. 为了保证每次都能写入重做日志文件, 在每次重做日志缓冲写入重做日志文件后. innoDB引擎需要一次fsync操作. fsync的效率取决于磁盘的效率. 也决定了事务的效率. 也决定了数据库的效率. binlog 和 重做日志的区别: binlog存储的是二进制文件. 重做日志存储的是物理格式的文件.实现的层面也不一样, binlog是mysql数据库上层实现的. 支持很多引擎使用. 重做日志是innodb引擎实现的.写入磁盘的时间点也不一样, binlog是只有在事务提交后才写入. 重做日志是事务进行中不停地写入. 这表现为日志并不是随事务提交的顺序写入的. log block重做日志的缓存和文件都已512字节大小的块进行保存.和磁盘扇区的大小一致.因此重做日志的写入具有原子性. 不需要doublewrite技术. 重做日志文件中存储的就是log buffer中保存的log block. innodb存储引擎运行过程. log buffer根据一定的规则将内存中的log block刷新到磁盘, 这个规则具体是: 事务提交时 当log buffer中的可用空间小于一半时. log checkpoint时 innodb_flush_log_at_trx_commit用来控制重做日志刷新到磁盘的策略.0 事务提交时不写入重做日志文件1 表示事务提交时刷新buffer到文件 并他调用一次fsync.2 表示事务提交时将日志写入重做日志文件,但仅写入文件系统缓存中. 不执行fsync操作. LSN 日志序列号单调递增的. 代表了 重做日志写入的总量 checkpoint的位置 页的版本号.LSN不仅记录在重做日志中, 每页的头部都记录了该页LSN.表示该页最后刷新时LSN的位置.因为重做日志记录的是每个页的日志.因此页中LSN用来判断页是否需要进行恢复操作. undo 日志undo日志保证了事务的回滚和MVCC功能. 事务回滚: undo日志存放在重做日志中, 但和redo日志不同, undo存放在数据库内部一个特殊的段中. 叫做undo段.undo段位于共享表空间中. undo是逻辑日志. 回滚操作也不是将数据库物理的恢复到执行语句或事务之前的样子. undo日志只是将数据库逻辑的恢复到原来的样子, 所有的修改被逻辑的取消了.例如用户insert了10W条记录的事务.这个事务会导致表空间增大. 执行回滚操作. 但是表空间的大小并不会因此缩小, 因为innoBD在执行回滚的时候,它实际上做的是与之前相反的工作. 对于每个insert. 引擎会完成一个delete. 对于每个delete, innodb会完成一个insert. 对于update. innodb会执行一个相反的update. MVCC innodb中的MVCC的实现是通过undo日志完成的. 当用户读取记录时. 发现记录被其他事务占用. 当前事务可以通过undo日志读取之前版本的行记录.以此实现非锁定读 undo日志会产生redo日志. 因为undo日志也需要持久化的保护 当事务提交时 innodb引擎会做两件事情. 1将undo log放入列表. 供之后的purge操作 2. 判断undo是否可以重用. 若可以分配给下个事务使用. 事务提交之时. 引擎并不能马上删除undolog及undolog 所有页中的内容.这是因为可能其他事务需要undo日志来得到行记录之前的版本. 故事务提交时将undo log放入一个链表中.是否可以删除相关内容. 则有purge线程判定/. undo日志类型 insert undo log. 因为insert语句只对自己事务可见, 其他事务不可见, 因此该事务在提交之后 undo log可以直接删除. 不需要等到purge. update undo log. 记录的是对delete和update操作产生的undo log. 该日志可能会提供MVCC机制. 因此不能事务提交后删除. 提交时放入undo log链表. 等到purge线程进行最后的删除. purge线程为了节省空间 innoDB在设置undolog时. 一个页上可以保存多个事务的undo日志.因此顺序得不到保证. 因此innoDB还维护了一个history列表,它根据事务提交顺序,将undo log日志进行连接. 先提交的总在尾端. purge从list头开始清除undo, 在清除是会顺便把事务所在页中可以清除的事务一起清除掉. 事务控制语句 start transaction | begin 显式的开启事务 commit 提交事务 rollback 回滚 savepoint identifier, savepoint允许事务中创建一个保存点,一个事务存在多个保存点 release savepoint identifier, 删除一个事务中的保存点 rollback to identifier, 回滚到指定保存点 set transaction 设置事务隔离级别. 事务隔离级别 read uncommited 会出现脏读. 就是读取了未提交的数据. read commited 能读取到别的事务已经提交的信息. 读取已提交 repeatable read innodb默认的 通过next-key lock锁解决了 phantom problem. seriablizale 最严格的的事务级别.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zuul]]></title>
    <url>%2F2019%2F08%2F16%2Fzuul%2F</url>
    <content type="text"><![CDATA[启动zuul网关模块这里涉及了spring的注解驱动. 自动配置等相关知识@EnableZuulProxy-&gt; @import(ZuulProxyMarkerConfiguration.class)-&gt; @Bean就是初始化了Marker类. 相当于打标记 通过Maker类 找到了zuul的自动配置类ZuulProxyAutoConfiguration和父类ZuulServerAutoConfiguration 并在MATA-INF/spring.factories里面找到了这两个类的配置项: 123org.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.cloud.netflix.zuul.ZuulServerAutoConfiguration,\org.springframework.cloud.netflix.zuul.ZuulProxyAutoConfiguration 这两个类的加载都是通过@EnableAutoConfiguration完成的. ZuulServerAutoConfiguration配置类123456789101112131415161718192021222324252627282930313233343536373839404142@Configuration//启动zuul属性. 可以理解为加载ZuulProperties@EnableConfigurationProperties(&#123; ZuulProperties.class &#125;)//条件转载. 需要依赖ZuulServlet和ZuulServletFilter类. 也就是说要依赖zuul-core@ConditionalOnClass(&#123; ZuulServlet.class, ZuulServletFilter.class &#125;)//上下文环境中必须存在Marker这个Bean.@ConditionalOnBean(ZuulServerMarkerConfiguration.Marker.class)public class ZuulServerAutoConfiguration &#123; @Bean // 缺少zuulServlet Bean时加载 @ConditionalOnMissingBean(name = "zuulServlet") // yml文件中配置的属性zuul.use-filter = false或者没有配置时加载 @ConditionalOnProperty(name = "zuul.use-filter", havingValue = "false", matchIfMissing = true) public ServletRegistrationBean zuulServlet() &#123; ServletRegistrationBean&lt;ZuulServlet&gt; servlet = new ServletRegistrationBean&lt;&gt;( new ZuulServlet(), this.zuulProperties.getServletPattern()); // The whole point of exposing this servlet is to provide a route that doesn't // buffer requests. servlet.addInitParameter("buffer-requests", "false"); return servlet; &#125; @Bean @ConditionalOnMissingBean(name = "zuulServletFilter") //yml文件中配置的属性zuul.use-filter = true. 必须要有这个配置还必须是true 才会加载. @ConditionalOnProperty(name = "zuul.use-filter", havingValue = "true", matchIfMissing = false) public FilterRegistrationBean zuulServletFilter() &#123; final FilterRegistrationBean&lt;ZuulServletFilter&gt; filterRegistration = new FilterRegistrationBean&lt;&gt;(); filterRegistration.setUrlPatterns( Collections.singleton(this.zuulProperties.getServletPattern())); filterRegistration.setFilter(new ZuulServletFilter()); filterRegistration.setOrder(Ordered.LOWEST_PRECEDENCE); // The whole point of exposing this servlet is to provide a route that doesn't // buffer requests. filterRegistration.addInitParameter("buffer-requests", "false"); return filterRegistration; &#125;&#125; ZuulServlet类和ZuulServletFilter类是zuul提供的两种启动方式, 对应了servlet和servlet Filter. servlet指南 ZuulServletFilter这个类告诉了zuul filter的执行顺序 init((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); 初始化ZuulRunner preRouting() -&gt; zuulRunner.preRoute() -&gt; FilterProcessor.getInstance().preRoute() -&gt; runFilters(“pre”); pre在请求路由之前执行. 业务上可以做一些验证之类的操作 routing() -&gt; zuulRunner.route(); -&gt; FilterProcessor.getInstance().route() -&gt; runFilters(“route”); route 路由请求时调用. 转发请求. postRouting() -&gt; zuulRunner.postRoute(); -&gt; FilterProcessor.getInstance().postRoute(); -&gt; runFilters(“post”); post: 用来处理响应 error(e) -&gt; zuulRunner.error(); -&gt; FilterProcessor.getInstance().error() -&gt; runFilters(“error”); error 当错误发生时就会调用这个类型的filter ZuulRunner(运行器)类 和 FilterProcessor(执行器)类 真正的核心类ZuulRunner类的作用 调用FilterProcessor 是否要使用HttpServletRequest的包装类HttpServletRequestWrapper(拓展 extends javax.servlet.http.HttpServletRequestWrapper)提供了一些 方便的API. 比如 HashMap&lt;String, String[]&gt; getParameters()等 FilterProcessor类首先是单例. 123456789101112131415161718192021public class FilterProcessor &#123; public Object runFilters(String sType) throws Throwable &#123; if (RequestContext.getCurrentContext().debugRouting()) &#123; Debug.addRoutingDebug("Invoking &#123;" + sType + "&#125; type filters"); &#125; boolean bResult = false; List&lt;ZuulFilter&gt; list = FilterLoader.getInstance().getFiltersByType(sType); if (list != null) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; ZuulFilter zuulFilter = list.get(i); Object result = processZuulFilter(zuulFilter); if (result != null &amp;&amp; result instanceof Boolean) &#123; bResult |= ((Boolean) result); &#125; &#125; &#125; return bResult; &#125;&#125; FilterLoader.getInstance().getFiltersByType(sType); 是获取sType类型的filter. 并按照优先级进行排序.其背后调用了FilterRegistry这个类 这个类很简单, 维护了一个ConcurrentHashMap&lt;String, ZuulFilter&gt; filters 容器.这两个类的初始化都是在ZuulServerAutoConfiguration这个自动装载的 12345678910111213141516@Configuration protected static class ZuulFilterConfiguration &#123; @Autowired private Map&lt;String, ZuulFilter&gt; filters; @Bean public ZuulFilterInitializer zuulFilterInitializer(CounterFactory counterFactory, TracerFactory tracerFactory) &#123; FilterLoader filterLoader = FilterLoader.getInstance(); FilterRegistry filterRegistry = FilterRegistry.instance(); return new ZuulFilterInitializer(this.filters, counterFactory, tracerFactory, filterLoader, filterRegistry); &#125; &#125; 这个filters属性时如何初始化的. 业务自己定义的filter只要交给spring托管, 就可以加载进来. 但是zuul自己提供的10个filter. 就需要FilterFileManager它来负责加载了. pre过滤器ServletDetectionFilter 检测当前请求是通过Spring的DispatcherServlet处理运行，还是通过ZuulServlet来处理运行优先级 -3 Servlet30WrapperFilter 将原始的HttpServletRequest包装成Servlet30RequestWrapper对象优先级 -2 FormBodyWrapperFilter 将符合条件的请求包装成FormBodyRequestWrapper对象优先级 -1 执行条件: application/x-www-form-urlencoded 或者 multipart/form-data 时候执行 DebugFilter 将当前RequestContext中的debugRouting和debugRequest参数设置为true优先级 1 执行条件: 请求中的debug参数（该参数可以通过zuul.debug.parameter来自定义）为true，或者配置参数zuul.debug.request为true时执行 PreDecorationFilter优先级 5 执行条件: RequestContext不存在forward.to和serviceId两个参数时执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class PreDecorationFilter extends ZuulFilter &#123;@Override public Object run() &#123;//获取请求上下文 RequestContext ctx = RequestContext.getCurrentContext();//获取请求路径 final String requestURI = this.urlPathHelper .getPathWithinApplication(ctx.getRequest());//获取路由信息(CompositeRouteLocator 实在自动装配阶段装配的) Route route = this.routeLocator.getMatchingRoute(requestURI);// 路由存在 if (route != null) &#123;//获取路由的定位信息(url或者serviceId) String location = route.getLocation(); if (location != null) &#123;//设置requestURI= path ctx.put(REQUEST_URI_KEY, route.getPath());//设置proxy = routeId ctx.put(PROXY_KEY, route.getId());//不存在自定义的敏感头信息 设置默认的 ("Cookie", "Set-Cookie", "Authorization") if (!route.isCustomSensitiveHeaders()) &#123; this.proxyRequestHelper.addIgnoredHeaders( this.properties.getSensitiveHeaders().toArray(new String[0])); &#125;//存在 就用用户自己定义的 else &#123; this.proxyRequestHelper.addIgnoredHeaders( route.getSensitiveHeaders().toArray(new String[0])); &#125;//设置重试属性 if (route.getRetryable() != null) &#123; ctx.put(RETRYABLE_KEY, route.getRetryable()); &#125;//如果location以http或https开头，将其添加到RequestContext的routeHost中，在RequestContext的originResponseHeaders中添加X-Zuul-Service与location的键值对； if (location.startsWith(HTTP_SCHEME + ":") || location.startsWith(HTTPS_SCHEME + ":")) &#123; ctx.setRouteHost(getUrl(location)); ctx.addOriginResponseHeader(SERVICE_HEADER, location); &#125;//如果location以forward:开头，则将其添加到RequestContext的forward.to中，将RequestContext的routeHost设置为null并返回； else if (location.startsWith(FORWARD_LOCATION_PREFIX)) &#123; ctx.set(FORWARD_TO_KEY, StringUtils.cleanPath( location.substring(FORWARD_LOCATION_PREFIX.length()) + route.getPath())); ctx.setRouteHost(null); return null; &#125;//否则将location添加到RequestContext的serviceId中，将RequestContext的routeHost设置为null，在RequestContext的originResponseHeaders中添加X-Zuul-ServiceId与location的键值对。 else &#123; // set serviceId for use in filters.route.RibbonRequest ctx.set(SERVICE_ID_KEY, location); ctx.setRouteHost(null); ctx.addOriginResponseHeader(SERVICE_ID_HEADER, location); &#125;//如果zuul.addProxyHeaders=true 则在RequestContext的zuulRequestHeaders中添加一系列请求头：X-Forwarded-Host、X-Forwarded-Port、X-Forwarded-Proto、X-Forwarded-Prefix、X-Forwarded-For if (this.properties.isAddProxyHeaders()) &#123; addProxyHeaders(ctx, route); String xforwardedfor = ctx.getRequest() .getHeader(X_FORWARDED_FOR_HEADER); String remoteAddr = ctx.getRequest().getRemoteAddr(); if (xforwardedfor == null) &#123; xforwardedfor = remoteAddr; &#125; else if (!xforwardedfor.contains(remoteAddr)) &#123; // Prevent duplicates xforwardedfor += ", " + remoteAddr; &#125; ctx.addZuulRequestHeader(X_FORWARDED_FOR_HEADER, xforwardedfor); &#125;//如果zuul.addHostHeader=ture 则在则在RequestContext的zuulRequestHeaders中添加host if (this.properties.isAddHostHeader()) &#123; ctx.addZuulRequestHeader(HttpHeaders.HOST, toHostHeader(ctx.getRequest())); &#125; &#125; &#125;//如果 route=null 在RequestContext中将forward.to设置为forwardURI，默认情况下forwardURI为请求路径。 else &#123; log.warn("No route found for uri: " + requestURI); String forwardURI = getForwardUri(requestURI); ctx.set(FORWARD_TO_KEY, forwardURI); &#125; return null; &#125;&#125; route过滤器RibbonRoutingFilter 使用Ribbon和Hystrix来向服务实例发起请求，并将服务实例的请求结果返回优先级 10 执行条件: RequestContext中的routeHost为null，serviceId不为null。sendZuulResponse=true. 即只对通过serviceId配置路由规则的请求生效 使用Ribbon和Hystrix来向服务实例发起请求，并将服务实例的请求结果返回 SimpleHostRoutingFilter优先级 100 执行条件: RequestContext中的routeHost不为null。即只对通过url配置路由规则的请求生效 直接向routeHost参数的物理地址发起请求，该请求是直接通过httpclient包实现的，而没有使用Hystrix命令进行包装，所以这类请求并没有线程隔离和熔断器的保护。 SendForwardFilter 获取forward.to中保存的跳转地址，跳转过去优先级 500 执行条件: RequestContext中的forward.to不为null。即用来处理路由规则中的forward本地跳转配置 post过滤器SendResponseFilter 在请求响应中增加头信息（根据设置有X-Zuul-Debug-Header、Date、Content-Type、Content-Length等）：addResponseHeaders;发送响应内容：writeResponse。优先级 1000 执行条件: 没有抛出异常，RequestContext中的throwable属性为null（如果不为null说明已经被error过滤器处理过了，这里的post过滤器就不需要处理了），并且RequestContext中zuulResponseHeaders、responseDataStream、responseBody三者有一样不为null（说明实际请求的响应不为空）。 LocationRewriteFilter优先级 SendResponseFilter - 100 执行条件: HttpStatus.valueOf(statusCode).is3xxRedirection() 响应码是3XX的时候执行 功能: 将Location信息转化为Zuul URL. error过滤器SendErrorFilter优先级 0 执行条件：RequestContext中的throwable不为null，且sendErrorFilter.ran属性为false。 在request中设置javax.servlet.error.status_code、javax.servlet.error.exception、javax.servlet.error.message三个属性。将RequestContext中的sendErrorFilter.ran属性设置为true。然后组织成一个forward到API网关/error错误端点的请求来产生错误响应。 Ribbon和HystrixZuulProxyAutoConfiguration配置类1234567891011121314151617181920212223242526272829@Configuration//加载这个4个类@Import(&#123; RibbonCommandFactoryConfiguration.RestClientRibbonConfiguration.class, RibbonCommandFactoryConfiguration.OkHttpRibbonConfiguration.class, RibbonCommandFactoryConfiguration.HttpClientRibbonConfiguration.class, HttpClientConfiguration.class &#125;)@ConditionalOnBean(ZuulProxyMarkerConfiguration.Marker.class)public class ZuulProxyAutoConfiguration extends ZuulServerAutoConfiguration &#123; @Bean @ConditionalOnMissingBean(RibbonRoutingFilter.class) public RibbonRoutingFilter ribbonRoutingFilter(ProxyRequestHelper helper, RibbonCommandFactory&lt;?&gt; ribbonCommandFactory) &#123; //ribbonCommandFactory这个具体是什么类型 取决import导入的类 RibbonRoutingFilter filter = new RibbonRoutingFilter(helper, ribbonCommandFactory, this.requestCustomizers); return filter; &#125; @Bean @ConditionalOnMissingBean(&#123; SimpleHostRoutingFilter.class, CloseableHttpClient.class &#125;) public SimpleHostRoutingFilter simpleHostRoutingFilter(ProxyRequestHelper helper, ZuulProperties zuulProperties, ApacheHttpClientConnectionManagerFactory connectionManagerFactory, ApacheHttpClientFactory httpClientFactory) &#123; return new SimpleHostRoutingFilter(helper, zuulProperties, connectionManagerFactory, httpClientFactory); &#125;&#125; ZuulProxyAutoConfiguration自动配置类. 是ZuulServerAutoConfiguration的子类, 加入了RestClientRibbonConfiguration OkHttpRibbonConfiguration HttpClientRibbonConfiguration等类. 还将一些filter交给spring托管了.集成了 注册发现, Ribbon, 健康检查 在RibbonRoutingFilter看到了zuul在什么时候启动ribbon的. 同时出现了RibbonCommand类. 这是实现了HystrixExecutable. 这个类是可以理解为Hystrix的执行器.RibbonCommand有四个子类. 一个抽象类AbstractRibbonCommand和三个实现类 分别是依据httpClient实现的和OkHttp实现的以及RestClient实现的. RibbonCommand创建这里使用了设计模式抽象工厂方法模式. RibbonCommandFactory工厂类接口 AbstractRibbonCommandFactory抽象类. 功能是记录FallbackProvider. 相当于注册表.用map记录.三种RibbonCommand创建都有各自工厂去构建. 三种工厂类的构建RibbonCommandFactoryConfiguration 工厂类自动配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 以okHttp为例子public class RibbonCommandFactoryConfiguration &#123; @Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;) @Retention(RetentionPolicy.RUNTIME) @Documented @Conditional(OnRibbonOkHttpClientCondition.class) @interface ConditionalOnRibbonOkHttpClient &#123; &#125; @Configuration // ribbon.okhttp.enabled yml文件中存在这个属性 @ConditionalOnRibbonOkHttpClient // 环境中存在这个类okhttp3.OkHttpClient @ConditionalOnClass(name = "okhttp3.OkHttpClient") protected static class OkHttpRibbonConfiguration &#123; @Autowired(required = false) //FallbackProvider的所有实现类 必须添加注解@Component. 在这里可以组装完成. private Set&lt;FallbackProvider&gt; zuulFallbackProviders = Collections.emptySet(); // @Bean 注册到Spring IOC容器中. @Bean @ConditionalOnMissingBean public RibbonCommandFactory&lt;?&gt; ribbonCommandFactory( SpringClientFactory clientFactory, ZuulProperties zuulProperties) &#123; return new OkHttpRibbonCommandFactory(clientFactory, zuulProperties, zuulFallbackProviders); &#125; &#125; private static class OnRibbonOkHttpClientCondition extends AnyNestedCondition &#123; OnRibbonOkHttpClientCondition() &#123; super(ConfigurationPhase.PARSE_CONFIGURATION); &#125; @ConditionalOnProperty("ribbon.okhttp.enabled") static class RibbonProperty &#123; &#125; &#125;&#125; 其他的实现也是相同的套路. ribbon.restclient.enabled 使用RestClientRibbonCommandFactoryribbon.okhttp.enabled 使用OkHttpRibbonCommandFactoryribbon.httpclient.enabled matchIfMissing=true 意思是当不设置任何值的时候,默认初始HttpClientRibbonCommandFactory 在结合ZuulProxyAutoConfiguration类中@Bean RibbonRoutingFilter的构建. 在项目启动完成后,RibbonRoutingFilter通过RibbonCommandFactory.create()方法. 是可以构建出RibbonCommand类的. RibbonRoutingFilter 过滤器1234567891011121314151617protected ClientHttpResponse forward(RibbonCommandContext context) throws Exception &#123; Map&lt;String, Object&gt; info = this.helper.debug(context.getMethod(), context.getUri(), context.getHeaders(), context.getParams(), context.getRequestEntity()); // 这里的逻辑就清楚了. RibbonCommand command = this.ribbonCommandFactory.create(context); try &#123; ClientHttpResponse response = command.execute(); this.helper.appendDebug(info, response.getRawStatusCode(), response.getHeaders()); return response; &#125; catch (HystrixRuntimeException ex) &#123; return handleException(info, ex); &#125;&#125; AbstractRibbonCommand类 OkHttpRibbonCommandFactory#create()方法 杂糅了很多类的关键方法.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145@Override public OkHttpRibbonCommand create(final RibbonCommandContext context) &#123;//这个不解释 final String serviceId = context.getServiceId();//依据服务ID获得FallbackProvider FallbackProvider fallbackProvider = getFallbackProvider(serviceId);//创建负载均衡客户端 final OkHttpLoadBalancingClient client = this.clientFactory.getClient(serviceId, OkHttpLoadBalancingClient.class);// 设置负载均衡 client.setLoadBalancer(this.clientFactory.getLoadBalancer(serviceId));//创建OkHttpRibbonCommand实例, return new OkHttpRibbonCommand(serviceId, client, context, zuulProperties, fallbackProvider, clientFactory.getClientConfig(serviceId)); &#125; public OkHttpRibbonCommand(final String commandKey, final OkHttpLoadBalancingClient client, final RibbonCommandContext context, final ZuulProperties zuulProperties, final FallbackProvider zuulFallbackProvider, final IClientConfig config) &#123; //调用父类的构造方法 super(commandKey, client, context, zuulProperties, zuulFallbackProvider, config); &#125; public AbstractRibbonCommand(String commandKey, LBC client, RibbonCommandContext context, ZuulProperties zuulProperties, FallbackProvider fallbackProvider, IClientConfig config) &#123; //getSetter 设置Hystrix的属性值 this(getSetter(commandKey, zuulProperties, config), client, context, fallbackProvider, config); &#125; protected static Setter getSetter(final String commandKey, ZuulProperties zuulProperties, IClientConfig config) &#123; // @formatter:off commandKey= serviceId 每个CommandKey代表一个依赖抽象,相同的依赖要使用相同的CommandKey名称。依赖隔离的根本就是对相同CommandKey的依赖做隔离. //CommandGroup 命令分组用于对依赖操作分组,便于统计,汇总等. Setter commandSetter = Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;RibbonCommand&quot;)) .andCommandKey(HystrixCommandKey.Factory.asKey(commandKey)); // 构建了策略和超时时间 final HystrixCommandProperties.Setter setter = createSetter(config, commandKey, zuulProperties); //信号量方式 if (zuulProperties.getRibbonIsolationStrategy() == ExecutionIsolationStrategy.SEMAPHORE) &#123; final String name = ZuulConstants.ZUUL_EUREKA + commandKey + &quot;.semaphore.maxSemaphores&quot;; // we want to default to semaphore-isolation since this wraps // 2 others commands that are already thread isolated // 获取信号量大小 默认值100 final DynamicIntProperty value = DynamicPropertyFactory.getInstance() .getIntProperty(name, zuulProperties.getSemaphore().getMaxSemaphores()); setter.withExecutionIsolationSemaphoreMaxConcurrentRequests(value.get()); &#125; //线程池方式 else if (zuulProperties.getThreadPool().isUseSeparateThreadPools()) &#123; //每个serviceId一个线程池 final String threadPoolKey = zuulProperties.getThreadPool().getThreadPoolKeyPrefix() + commandKey; commandSetter.andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(threadPoolKey)); &#125; return commandSetter.andCommandPropertiesDefaults(setter); // @formatter:on &#125; protected static HystrixCommandProperties.Setter createSetter(IClientConfig config, String commandKey, ZuulProperties zuulProperties) &#123; //设置Hystrix超时时间 int hystrixTimeout = getHystrixTimeout(config, commandKey); //设置策略 ribbon的默认策略是信息量 return HystrixCommandProperties.Setter() .withExecutionIsolationStrategy( zuulProperties.getRibbonIsolationStrategy()) .withExecutionTimeoutInMilliseconds(hystrixTimeout); &#125;protected static int getHystrixTimeout(IClientConfig config, String commandKey) &#123;//获取Ribbon的超时时间 int ribbonTimeout = getRibbonTimeout(config, commandKey); DynamicPropertyFactory dynamicPropertyFactory = DynamicPropertyFactory .getInstance();// 默认的超时时间 int defaultHystrixTimeout = dynamicPropertyFactory.getIntProperty( &quot;hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds&quot;, 0).get();// 获取针对serviceId设置的超时时间 int commandHystrixTimeout = dynamicPropertyFactory .getIntProperty(&quot;hystrix.command.&quot; + commandKey + &quot;.execution.isolation.thread.timeoutInMilliseconds&quot;, 0) .get(); int hystrixTimeout;// if (commandHystrixTimeout &gt; 0) &#123; hystrixTimeout = commandHystrixTimeout; &#125; else if (defaultHystrixTimeout &gt; 0) &#123; hystrixTimeout = defaultHystrixTimeout; &#125; else &#123; hystrixTimeout = ribbonTimeout; &#125;// 可以理解为 设置了默认的就用默认的. 否则用serviceId的.如果都没设置用ribbon设置的 if (hystrixTimeout &lt; ribbonTimeout) &#123; LOGGER.warn(&quot;The Hystrix timeout of &quot; + hystrixTimeout + &quot;ms for the command &quot; + commandKey + &quot; is set lower than the combination of the Ribbon read and connect timeout, &quot; + ribbonTimeout + &quot;ms.&quot;); &#125; return hystrixTimeout; &#125; protected static int getRibbonTimeout(IClientConfig config, String commandKey) &#123; int ribbonTimeout; //如何用户没有自定义使用系统默认的 2000ms if (config == null) &#123; ribbonTimeout = RibbonClientConfiguration.DEFAULT_READ_TIMEOUT + RibbonClientConfiguration.DEFAULT_CONNECT_TIMEOUT; &#125; //读取用户设置的 else &#123; int ribbonReadTimeout = getTimeout(config, commandKey, &quot;ReadTimeout&quot;, IClientConfigKey.Keys.ReadTimeout, RibbonClientConfiguration.DEFAULT_READ_TIMEOUT); int ribbonConnectTimeout = getTimeout(config, commandKey, &quot;ConnectTimeout&quot;, IClientConfigKey.Keys.ConnectTimeout, RibbonClientConfiguration.DEFAULT_CONNECT_TIMEOUT); int maxAutoRetries = getTimeout(config, commandKey, &quot;MaxAutoRetries&quot;, IClientConfigKey.Keys.MaxAutoRetries, DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES); int maxAutoRetriesNextServer = getTimeout(config, commandKey, &quot;MaxAutoRetriesNextServer&quot;, IClientConfigKey.Keys.MaxAutoRetriesNextServer, DefaultClientConfigImpl.DEFAULT_MAX_AUTO_RETRIES_NEXT_SERVER); ribbonTimeout = (ribbonReadTimeout + ribbonConnectTimeout) * (maxAutoRetries + 1) * (maxAutoRetriesNextServer + 1); &#125; return ribbonTimeout; &#125; private static int getTimeout(IClientConfig config, String commandKey, String property, IClientConfigKey&lt;Integer&gt; configKey, int defaultValue) &#123; DynamicPropertyFactory dynamicPropertyFactory = DynamicPropertyFactory .getInstance(); return dynamicPropertyFactory .getIntProperty(commandKey + &quot;.&quot; + config.getNameSpace() + &quot;.&quot; + property, config.get(configKey, defaultValue)) .get(); &#125; 当OkHttpRibbonCommand创建完成后, 这些数据就都设置完成了,]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringApplication]]></title>
    <url>%2F2019%2F07%2F19%2FSpringApplication%2F</url>
    <content type="text"><![CDATA[SpringApplication构造过程1234567891011//构造SpringApplication public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, "PrimarySources must not be null"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); //推断WEB应用类型 this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &#125; WebApplicationType.deduceFromClasspath() 推断WEB应用类型1234567891011121314151617181920212223242526272829private static final String[] SERVLET_INDICATOR_CLASSES = &#123; "javax.servlet.Servlet", "org.springframework.web.context.ConfigurableWebApplicationContext" &#125;;private static final String WEBMVC_INDICATOR_CLASS = "org.springframework." + "web.servlet.DispatcherServlet";private static final String WEBFLUX_INDICATOR_CLASS = "org." + "springframework.web.reactive.DispatcherHandler";private static final String JERSEY_INDICATOR_CLASS = "org.glassfish.jersey.servlet.ServletContainer";private static final String SERVLET_APPLICATION_CONTEXT_CLASS = "org.springframework.web.context.WebApplicationContext";private static final String REACTIVE_APPLICATION_CONTEXT_CLASS = "org.springframework.boot.web.reactive.context.ReactiveWebApplicationContext";static WebApplicationType deduceFromClasspath() &#123; // 当DispatcherHandler存在, DispatcherServlet不存在 ServletContainer不存在时. 为Reactive Web if (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null) &amp;&amp; !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) &#123; return WebApplicationType.REACTIVE; &#125; //Servlet或者ConfigurableWebApplicationContext不存在时, 非WEB应用 for (String className : SERVLET_INDICATOR_CLASSES) &#123; if (!ClassUtils.isPresent(className, null)) &#123; WebApplicationType.NONE; &#125; &#125; // 嵌入式WEB return WebApplicationType.SERVLET;&#125; setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)) 设置初始化器getSpringFactoriesInstances(ApplicationContextInitializer.class)1234567891011// 获取ApplicationContextInitializer类型的实例集合private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // 加载META-INF/spring.factories配置的ApplicationContextInitializer实现类列表 Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); // 创建实例. 必须有无参数构造器 List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); // 排序 实现了Ordered AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 加载资源(META-INF/spring.factories)中配置的ApplicationContextInitializer实现类名单 调用SpringFactoriesLoader.loadFactoryNames(type, classLoader)); setInitializers()12345// 覆盖设置ApplicationContextInitializer类型的初始化器public void setInitializers(Collection&lt;? extends ApplicationContextInitializer&lt;?&gt;&gt; initializers) &#123; this.initializers = new ArrayList&lt;&gt;(); this.initializers.addAll(initializers); &#125; setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)) 加载事件监听器大同小异 SpringApplication 运行阶段run() 方法调用的开始 1234567891011121314151617181920212223242526272829303132333435363738394041public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); //创建上下文 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context; &#125; getRunListeners(args) 获取监听器12345private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args)); &#125; getSpringFactoriesInstances() 获取META-INF/spring.factories 中SpringApplicationRunListener配置的类 EventPublishingRunListener是spring boot内建唯一的实现类. 构造函数中 12345678public EventPublishingRunListener(SpringApplication application, String[] args) &#123; this.application = application; this.args = args; this.initialMulticaster = new SimpleApplicationEventMulticaster(); for (ApplicationListener&lt;?&gt; listener : application.getListeners()) &#123; this.initialMulticaster.addApplicationListener(listener); &#125; &#125; SimpleApplicationEventMulticaster用于发布Spring应用事件(ApplicationEvent)因此EventPublishingRunListener实际上充当Spring Boot事件发布者的角色. starting() ApplicationStartingEvent environmentPrepared(ConfigurableEnvironment) ApplicationEnvironmentPrepareEvent contextPrepared(ConfigurableApplicationContext) contextLoaded(ConfigurableApplicationContext) ApplicationPreparedEvent started(ConfigurableApplicationContext) ApplicationStartedEvent running(ConfigurableApplicationContext) ApplicationReadyEvent failed(ConfigurableApplicationContext, Throwable) ApplicationFailedEvent 装配ApplicationArgumentsApplicationArguments用于简化Spring boot启动参数封装接口 它的底层实现为SimpleCommandLinePropertySource, SimpleCommandLinePropertySource将命令行参数分为两组 1为选项参数OptionValues, 2为非选项参数NonOptionArgs –前缀是可选参数 反之非选项参数则未包含–前缀的则是命令行参数. 准备ConfigurableEnvironment12345678910111213141516171819202122232425262728 private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment; &#125;private ConfigurableEnvironment getOrCreateEnvironment() &#123; if (this.environment != null) &#123; return this.environment; &#125; switch (this.webApplicationType) &#123; case SERVLET: return new StandardServletEnvironment(); case REACTIVE: return new StandardReactiveWebEnvironment(); default: return new StandardEnvironment(); &#125; &#125; 根据webApplicationType构建环境信息. 创建Spring应用上下文(ConfigurableApplicationContext)SpringApplication通过createApplicationContext()方法创建Spring应用上下文, 实际上Spring应用上下文才是驱动整体Spring boot应用组件的核心引擎. 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*** The class name of application context that will be used by default for non-web* environments.*/public static final String DEFAULT_CONTEXT_CLASS = "org.springframework.context." + "annotation.AnnotationConfigApplicationContext";/*** The class name of application context that will be used by default for web* environments.*/public static final String DEFAULT_SERVLET_WEB_CONTEXT_CLASS = "org.springframework.boot." + "web.servlet.context.AnnotationConfigServletWebServerApplicationContext";/*** The class name of application context that will be used by default for reactive web* environments.*/public static final String DEFAULT_REACTIVE_WEB_CONTEXT_CLASS = "org.springframework." + "boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext";protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( "Unable create a default ApplicationContext, " + "please specify an ApplicationContextClass", ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass); &#125; 可以看出是根据WebApplicationType创建Spring应用上下文. SERVLET -&gt; AnnotationConfigServletWebServerApplicationContext. (BeanUtils.instantiateClass(contextClass))注解配置的应用上下文.AutowiredAnnotationBeanPostProcessor这个类就是在这个阶段注册的REACTIVE -&gt; AnnotationConfigReactiveWebServerApplicationContext,NONE -&gt; AnnotationConfigApplicationContext. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public AnnotationConfigServletWebServerApplicationContext(DefaultListableBeanFactory beanFactory) &#123; super(beanFactory); this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this);&#125; public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry, Environment environment) &#123; Assert.notNull(registry, "BeanDefinitionRegistry must not be null"); Assert.notNull(environment, "Environment must not be null"); this.registry = registry; this.conditionEvaluator = new ConditionEvaluator(registry, environment, null); AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry);&#125; public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, @Nullable Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8); /// 注册 @Configuration解析类 if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // 注册`@Autowired/@Value解析类 if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. // 注册@PostConstruct @PreDestroy @Resource 及JSR-250支持注解解析类 if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor. // 注册JPA注解解析类 if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, AnnotationConfigUtils.class.getClassLoader())); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( "Cannot load optional framework class: " + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME)); &#125; if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME)); &#125; return beanDefs;&#125; Spring应用上下文运行前准备 准备阶段. prepareContext -&gt; SpringApplicationRunListeners#contextPrepared context.setEnvironment(environment) 关联上下文和环境 SpringApplication#postProcessApplicationContext(ConfigurableApplicationContext) 1234567891011121314151617181920protected void postProcessApplicationContext(ConfigurableApplicationContext context) &#123; //将会影响ConfigurableApplicationContext注解驱动Bean名的生成. if (this.beanNameGenerator != null) &#123; context.getBeanFactory().registerSingleton(AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; //AnnotationConfigServletWebServerApplicationContext 是 GenericApplicationContext的子类 if (context instanceof GenericApplicationContext) &#123; ((GenericApplicationContext) context).setResourceLoader(this.resourceLoader); &#125; //AnnotationConfigServletWebServerApplicationContext 是 DefaultResourceLoader的子类 if (context instanceof DefaultResourceLoader) &#123; ((DefaultResourceLoader) context).setClassLoader(this.resourceLoader.getClassLoader()); &#125; &#125; if (this.addConversionService) &#123; context.getBeanFactory().setConversionService(ApplicationConversionService.getSharedInstance()); &#125; &#125; SpringApplication存在自定义属性beanNameGenerator时, 这个方法将该对象注册成名为”org.springframework.context.annotation.internalConfigurationBeanNameGenerator”的BeanNameGenerator Bean. 最终将影响ConfigurableApplicationContext注解驱动Bean名的生成. 在ConfigurationClassPostProcessor(@Configuration, context:component-scan/的底层实现: AnnotationConfigBeanDefinitionParser和context:annotation-config/的底层实现ComponentScanBeanDefinitionParser)类中找到了这样的代码 1234567891011121314151617181920212223public static final String CONFIGURATION_BEAN_NAME_GENERATOR ="org.springframework.context.annotation.internalConfigurationBeanNameGenerator"; SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) &#123; BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) &#123; this.componentScanBeanNameGenerator = generator; this.importBeanNameGenerator = generator; &#125; &#125; &#125; if (this.environment == null) &#123; this.environment = new StandardEnvironment(); &#125; // Parse each @Configuration class ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); applyInitializers(context) 执行Spring应用上下文初始化器 123456789101112131415161718protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, "Unable to call initializer."); initializer.initialize(context); &#125;&#125;//获取初始化清public Set&lt;ApplicationContextInitializer&lt;?&gt;&gt; getInitializers() &#123; return asUnmodifiableOrderedSet(this.initializers);&#125;//排序去重(实现hashcode和equals才可以)private static &lt;E&gt; Set&lt;E&gt; asUnmodifiableOrderedSet(Collection&lt;E&gt; elements) &#123; List&lt;E&gt; list = new ArrayList&lt;&gt;(elements); list.sort(AnnotationAwareOrderComparator.INSTANCE); return new LinkedHashSet&lt;&gt;(list);&#125; this.initializers 就是在构造SpringApplication时, set的初始化器(MATE-INF/spring.factories文件中写的内容), 执行listeners.contextPrepared(context). 当spring应用上下文创建并准备完毕时. Spring应用上下文装载阶段 注册spring boot Bean 123456789ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();beanFactory.registerSingleton("springApplicationArguments", applicationArguments);if (printedBanner != null) &#123; beanFactory.registerSingleton("springBootBanner", printedBanner);&#125;if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding);&#125; 合并Spring应用上下文配置源 12345678910111213Set&lt;Object&gt; sources = getAllSources();//返回一个只读的SETpublic Set&lt;Object&gt; getAllSources() &#123; Set&lt;Object&gt; allSources = new LinkedHashSet&lt;&gt;(); if (!CollectionUtils.isEmpty(this.primarySources)) &#123; allSources.addAll(this.primarySources); &#125; if (!CollectionUtils.isEmpty(this.sources)) &#123; allSources.addAll(this.sources); &#125; return Collections.unmodifiableSet(allSources);&#125; primarySources来自于SpringApplication构造器, sources来自于setSources(Set). getAllSources()方法皆用于存储Configuration Class, 类名, 包名, 及Spring XML配置的资源目录. 加载Spring应用上下文配置源 12345678910111213141516protected void load(ApplicationContext context, Object[] sources) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Loading source " + StringUtils.arrayToCommaDelimitedString(sources)); &#125; BeanDefinitionLoader loader = createBeanDefinitionLoader(getBeanDefinitionRegistry(context), sources); if (this.beanNameGenerator != null) &#123; loader.setBeanNameGenerator(this.beanNameGenerator); &#125; if (this.resourceLoader != null) &#123; loader.setResourceLoader(this.resourceLoader); &#125; if (this.environment != null) &#123; loader.setEnvironment(this.environment); &#125; loader.load();&#125; 该方法将应用上下文Bean装载任务交给了BeanDefinitionLoader. 12345678910111213class BeanDefinitionLoader &#123; private final Object[] sources; private final AnnotatedBeanDefinitionReader annotatedReader; private final XmlBeanDefinitionReader xmlReader; private BeanDefinitionReader groovyReader; private final ClassPathBeanDefinitionScanner scanner; private ResourceLoader resourceLoader; 这些属性值应该是很熟悉了. AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner 是AnnotationConfigApplicationContext扫描和注册配置类的基础. XmlBeanDefinitionReader和BeanDefinitionReader是注解@ImportResource读取BeanDefinition的底层实现. 执行listeners.contextLoaded(context) Spring应用上下文启动阶段1234567891011121314151617181920private void refreshContext(ConfigurableApplicationContext context) &#123; refresh(context); if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException ex) &#123; // Not allowed in some environments. &#125; &#125;&#125;/*** Refresh the underlying &#123;@link ApplicationContext&#125;.* @param applicationContext the application context to refresh*/protected void refresh(ApplicationContext applicationContext) &#123; Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext); ((AbstractApplicationContext) applicationContext).refresh();&#125; 继续追踪到AbstractApplicationContext#refresh()方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. // 准备更新上下文，设置开始时间，标记活动标志，初始化配置文件中的占位符 prepareRefresh(); // Tell the subclass to refresh the internal bean factory. // 一、 web工程 AbstractRefreshableApplicationContext // 将 bean 定义加载到给定的 BeanFactory 中 // 1. createBeanFactory(); 为此上下文创建内部 BeanFactory // 2. customizeBeanFactory(beanFactory); 定制 BeanFactory，是否允许 BeanDefinition 覆盖、是否允许循环引用 // 3. loadBeanDefinitions(beanFactory); 通过 BeanDefinitionReader 解析 xml 文件，解析封装信息到 BeanDefinition，并将其 register 到 BeanFactory 中 // 以 beanName为key将beanDefinition 存到 DefaultListableBeanFactory#beanDefinitionMap 中 // 二、 SpringBoot GenericApplicationContext，实际 register 过程在 invokeBeanFactoryPostProcessors 中 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. // 准备 BeanFactory 以便在此上下文中使用。 // 1. 设置 BeanFactory 的类加载器 // 2. 添加几个 BeanPostProcessor， // 3. 实例化几个特殊的 bean prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. // 在 AbstractApplicationContext#postProcessBeanFactory 为空实现，留给子类做扩展，不同 ApplicationContext 实现不同， postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. // Spring 的 SPI // 先调用 BeanDefinitionRegistryPostProcessor 和 ImportBeanDefinitionRegistrar 的实现类 // 再调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 方法 // 例如：ConfigurationClassPostProcessor 会扫描 &lt;context:component-scan/&gt; 和 @SpringBootApplication(scanBasePackages = "") 中的Component，并且将 @Configuration 类中的 @Bean register 到 BeanFactory 中 // 扩展例如：MyBatis MapperScannerConfigurer 和 MapperScannerRegistrar，扫描Mapper register 到 BeanFactory 中 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. // 注册 BeanPostProcessor 的实现类，不同于刚刚的 BeanFactoryPostProcessor // BeanPostProcessor 接口两个方法 postProcessBeforeInitialization 和 postProcessAfterInitialization 会在 Bean 初始化之前和之后调用 // 如果BeanPostProcessor实现了MergedBeanDefinitionPostProcessor. 那么会在这个阶段执行postProcessMergedBeanDefinition()方法 // 比如AutowiredAnnotationBeanPostProcessor // 这边 Bean 还没初始化，下面的 finishBeanFactoryInitialization 才是真正的初始化方法 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. // 初始化当前 ApplicationContext 的 MessageSource，解析消息的策略接口，用于支持消息的国际化和参数化 // Spring 两个开箱即用的实现 ResourceBundleMessageSource 和 ReloadableResourceBundleMessageSource initMessageSource(); // Initialize event multicaster for this context. //初始化当前 ApplicationContext 的事件广播器 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. //典型模板方法 //子类可以在实例化 bean 之前，做一些初始化工作，SpringBoot 会在这边启动 Web 服务 onRefresh(); // Check for listener beans and register them. // 向 initApplicationEventMulticaster() 初始化的 applicationEventMulticaster 注册事件监听器，就是实现 ApplicationListener 接口类 // 观察者模式，例如实现了 ApplicationEvent，通过 ApplicationEventPublisher#publishEvent()，可以通知到各个 ApplicationListener#onApplicationEvent registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. // 初始化所有的 singletons bean（lazy-init 的除外） // Spring bean 初始化核心方法 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. // ApplicationEventPublisher#publishEvent() 初始化完成（ContextRefreshedEvent）事件 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; invokeBeanFactoryPostProcessors()这个方法是我认为的关键方法, 内部执行了PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // Invoke BeanDefinitionRegistryPostProcessors first, if any. Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;(); // ConfigurableListableBeanFactory的子类中实现了BeanDefinitionRegistry类的类. 如果是 执行BeanDefinitionRegistryPostProcessor if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); //在执行BeanDefinitionRegistryPostProcessor之前 先执行beanFactoryPostProcessors集合 for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; //先执行beanFactoryPostProcessors集合中实现了BeanDefinitionRegistryPostProcessor的类. 否则最后执行. if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; //执行postProcessBeanDefinitionRegistry方法. registryProcessor.postProcessBeanDefinitionRegistry(registry); registryProcessors.add(registryProcessor); &#125; else &#123; regularPostProcessors.add(postProcessor); &#125; &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the bean factory post-processors apply to them! // Separate between BeanDefinitionRegistryPostProcessors that implement // PriorityOrdered, Ordered, and the rest. List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;(); // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered. // 获取实现了PriorityOrdered的BeanDefinitionRegistryPostProcessor集合, 然后按照beanFactory提供的比较器. 排序 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); // 具体的执行逻辑. 注解驱动的基础(ConfigurationClassPostProcessor)就是这时候执行的 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); //清除执行过的集合 currentRegistryProcessors.clear(); // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered. // 再获取实现了Ordered的BeanDefinitionRegistryPostProcessor集合. 然后按照beanFactory提供的比较器, postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); //执行 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); //清空 currentRegistryProcessors.clear(); // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear. //最后执行其他的. 知道执行完成 boolean reiterate = true; while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); reiterate = true; &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); &#125; // Now, invoke the postProcessBeanFactory callback of all processors handled so far. // 最后执行postProcessBeanFactory invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); // 最后的最后执行参数中的postProcessBeanFactory invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // Invoke factory processors registered with the context instance. //如果beanFactory没有实现BeanDefinitionRegistry, 就把参数beanFactoryPostProcessors都执行一遍 invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; //接着从beanFactory中获取实现了BeanFactoryPostProcessor接口的bean（没有被执行过），也是分为三类，PriorityOrdered组优先调用，Ordered其次，其他垫底。 // 最终清除beanFactory的metaData缓存（主要是清除类与beanname的映射缓存） // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the bean factory post-processors apply to them! String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // Separate between BeanFactoryPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, invoke the BeanFactoryPostProcessors that implement Ordered. List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, invoke all other BeanFactoryPostProcessors. List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // Clear cached merged bean definitions since the post-processors might have // modified the original metadata, e.g. replacing placeholders in values... beanFactory.clearMetadataCache(); &#125; 如果beanFactory实现了BeanDefinitionRegistry接口 先执行参数中实现了BeanDefinitionRegistryPostProcessor接口的#postProcessBeanDefinitionRegistry()方法 执行实现了PriorityOrdered接口的 排序后执行 postProcessBeanDefinitionRegistry() 执行实现了Ordered接口的. 排序后执行 postProcessBeanDefinitionRegistry() 在执行剩余的. postProcessBeanDefinitionRegistry() 执行实现了BeanDefinitionRegistryPostProcessor接口的postProcessBeanFactory()方法 执行参数中没有实现BeanDefinitionRegistryPostProcessor的postProcessBeanFactory()方法 如果beanFactory没有实现了BeanDefinitionRegistry接口.直接把参数中beanFactoryPostProcessors#postProcessBeanFactory()都执行了 上边都做完了，接着从beanFactory中获取实现了BeanFactoryPostProcessor接口的bean（没有被执行过的），也是分为三类，PriorityOrdered组优先调用，Ordered其次，其他垫底。 最终清除beanFactory的metaData缓存（主要是清除类与beanname的映射缓存） 注解驱动的核心类ConfigurationClassPostProcessor就是时候执行的. 其核心方法postProcessBeanFactory() 内部执行了processConfigBeanDefinitions(), 前者多了一层是否加载过的判断. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); String[] candidateNames = registry.getBeanDefinitionNames(); for (String beanName : candidateNames) &#123; BeanDefinition beanDef = registry.getBeanDefinition(beanName); if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Bean definition has already been processed as a configuration class: " + beanDef); &#125; &#125; else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); &#125; &#125; // Return immediately if no @Configuration classes were found if (configCandidates.isEmpty()) &#123; return; &#125; // Sort by previously determined @Order value, if applicable configCandidates.sort((bd1, bd2) -&gt; &#123; int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return Integer.compare(i1, i2); &#125;); // Detect any custom bean name generation strategy supplied through the enclosing application context SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) &#123; BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) &#123; this.componentScanBeanNameGenerator = generator; this.importBeanNameGenerator = generator; &#125; &#125; &#125; if (this.environment == null) &#123; this.environment = new StandardEnvironment(); &#125; // Parse each @Configuration class ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; parser.parse(candidates); parser.validate(); Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); configClasses.removeAll(alreadyParsed); // Read the model and create bean definitions based on its content if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader( registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; //通过注册器也就是DefaultListableBeanFactory#registerBeanDefinition()方法注册到自己持有的众多功能不易的注册表里ConcurrentHashMap this.reader.loadBeanDefinitions(configClasses); alreadyParsed.addAll(configClasses); candidates.clear(); if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123; String[] newCandidateNames = registry.getBeanDefinitionNames(); Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames)); Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) &#123; alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); &#125; for (String candidateName : newCandidateNames) &#123; if (!oldCandidateNames.contains(candidateName)) &#123; BeanDefinition bd = registry.getBeanDefinition(candidateName); if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp; !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123; candidates.add(new BeanDefinitionHolder(bd, candidateName)); &#125; &#125; &#125; candidateNames = newCandidateNames; &#125; &#125; while (!candidates.isEmpty()); // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123; sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry()); &#125; if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123; // Clear cache in externally provided MetadataReaderFactory; this is a no-op // for a shared cache since it'll be cleared by the ApplicationContext. ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); &#125; &#125; 注解驱动自动装配这里的核心类是ConfigurationClassParser#parser方法 类内部调用了processConfigurationClass()-&gt;doProcessConfigurationClass()可以理解为doProcessConfigurationClass()这个方法是核心 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123; if (configClass.getMetadata().isAnnotated(Component.class.getName())) &#123; // Recursively process any member (nested) classes first processMemberClasses(configClass, sourceClass); &#125; // Process any @PropertySource annotations for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), PropertySources.class, org.springframework.context.annotation.PropertySource.class)) &#123; if (this.environment instanceof ConfigurableEnvironment) &#123; processPropertySource(propertySource); &#125; else &#123; logger.info("Ignoring @PropertySource annotation on [" + sourceClass.getMetadata().getClassName() + "]. Reason: Environment must implement ConfigurableEnvironment"); &#125; &#125; // Process any @ComponentScan annotations Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; for (AnnotationAttributes componentScan : componentScans) &#123; // The config class is annotated with @ComponentScan -&gt; perform the scan immediately Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); // Check the set of scanned definitions for any further config classes and parse recursively if needed for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) &#123; bdCand = holder.getBeanDefinition(); &#125; if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123; parse(bdCand.getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125; &#125; // Process any @Import annotations processImports(configClass, sourceClass, getImports(sourceClass), true); // Process any @ImportResource annotations AnnotationAttributes importResource = AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class); if (importResource != null) &#123; String[] resources = importResource.getStringArray("locations"); Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass("reader"); for (String resource : resources) &#123; String resolvedResource = this.environment.resolveRequiredPlaceholders(resource); configClass.addImportedResource(resolvedResource, readerClass); &#125; &#125; // Process individual @Bean methods Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass); for (MethodMetadata methodMetadata : beanMethods) &#123; configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass)); &#125; // Process default methods on interfaces processInterfaces(configClass, sourceClass); // Process superclass, if any if (sourceClass.getMetadata().hasSuperClass()) &#123; String superclass = sourceClass.getMetadata().getSuperClassName(); if (superclass != null &amp;&amp; !superclass.startsWith("java") &amp;&amp; !this.knownSuperclasses.containsKey(superclass)) &#123; this.knownSuperclasses.put(superclass, configClass); // Superclass found, return its annotation metadata and recurse return sourceClass.getSuperClass(); &#125; &#125; // No superclass -&gt; processing is complete return null; &#125; 这个方法内看见了很多常用的注解 @Bean(ConfigurationClassParer#retrieveBeanMethodMetadata)@Import(ConfigurationClassParer#collectImports)@ImportResource@PropertySources@PropertySource@ComponentScans@ComponentScan这个方法重点关注了 processImports(configClass, sourceClass, getImports(sourceClass), true) 这里就是注解EnableAutoConfiguration的元注解@Import()导入AutoConfigurationImportSelector类的实现. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass, Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123; if (importCandidates.isEmpty()) &#123; return; &#125; if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123; this.problemReporter.error(new CircularImportProblem(configClass, this.importStack)); &#125; else &#123; this.importStack.push(configClass); try &#123; //自动装载有三种方式 1 实现ImportSelector 2 实现ImportBeanDefinitionRegistrar 3 通过注解@Configuration和@Import配合 for (SourceClass candidate : importCandidates) &#123; //1. 判定AutoConfigurationImportSelector是否是ImportSelector类的实现类. if (candidate.isAssignable(ImportSelector.class)) &#123; // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = candidate.loadClass(); ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); ParserStrategyUtils.invokeAwareMethods( selector, this.environment, this.resourceLoader, this.registry); //这里需要特别注意. DeferredImportSelector(延时导入选择器) deferredImportSelectorHandler这背后是list. if (selector instanceof DeferredImportSelector) &#123; this.deferredImportSelectorHandler.handle(configClass, (DeferredImportSelector) selector); &#125; //如果@Import的选择器没有实现DeferredImportSelector, 那么执行ImportSelector#selectImports方法, else &#123; //已自动装配举例 AutoConfigurationImportSelector#selectImports() 方法执行完成后, 能得到"META-INF/" + "spring-autoconfigure-metadata.properties"中配置的类信息,通过(SimpleMetadataReader)ASM读取注解元数据和类的元数据. 方法内部会进行去重, 去除排除的项, 去掉依赖不存在的, 发布自动装载事件. String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata()); //读取类信息了, 对java开头的核心类, 用ASM. 其他的类都用ASM去读取. 一直追踪会找到SimpleMetadataReader类. 在类的构造器中 //会找到AnnotationMetadataReadingVisitor visitor = new AnnotationMetadataReadingVisitor(classLoader); classReader.accept(visitor, ClassReader.SKIP_DEBUG); 这样的代码. AnnotationMetadataReadingVisitor这个类就是元数据读取器. 内部在读取注解元数据时使用了 AnnotationAttributesReadingVisitor类的visitEnd() 到这里就看到了递归的获取注解的元数据. spring的元注解派生.和多层次派生的秘密就是这个. //AnnotationMetadataReadingVisitor 这个类既是实现了AnnotationMetadata 又继承了ClassMetadataReadingVisitor. ClassMetadataReadingVisitor实现了ClassMetadata, Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames); // 递归直到importSourceClasses为空 processImports(configClass, currentSourceClass, importSourceClasses, false); &#125; &#125; //2.实现ImportBeanDefinitionRegistrar方式 比如@AutoConfigurationPackage的元注解@Import(AutoConfigurationPackages.Registrar.class)中的Registrar类 else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; // Candidate class is an ImportBeanDefinitionRegistrar -&gt; // delegate to it to register additional bean definitions Class&lt;?&gt; candidateClass = candidate.loadClass(); ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); ParserStrategyUtils.invokeAwareMethods( registrar, this.environment, this.resourceLoader, this.registry); configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125; // 3@Configuration方式 到最后还是要到1上去 else &#123; // Candidate class not an ImportSelector or ImportBeanDefinitionRegistrar -&gt; // process it as an @Configuration class this.importStack.registerImport( currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); processConfigurationClass(candidate.asConfigClass(configClass)); &#125; &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( "Failed to process import candidates for configuration class [" + configClass.getMetadata().getClassName() + "]", ex); &#125; finally &#123; this.importStack.pop(); &#125; &#125; &#125; 从而也知道了BeanFactoryPostProcessor BeanPostProcessor 还有 bean构造器 afterPropertisSet Bean定义的init-method方法的执行顺序 BeanFactoryPostProcessor和BeanPostProcessor执行顺序问题 BeanFactoryPostProcessor#BeanFactoryPostProcessor 在容器实例化任何其他bean之前读取配置元数据. 类的构造器 set BeanPostProcessor#postProcessBeforeInitialization() 在Spring容器实例化bean之后 afterPropertiesSet bean定义配置的init-method BeanFactoryPostProcessor#postProcessAfterInitialization()]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis相关2]]></title>
    <url>%2F2019%2F05%2F24%2FRedis%E7%9B%B8%E5%85%B32%2F</url>
    <content type="text"><![CDATA[复制旧版复制功能Redis的复制功能分为同步sync和命令传播command propagate两个操作: 同步操作同于将从服务器的数据库状态更新至主服务器当前所处的状态 命令传播操作用于在主服务器的数据库状态被修改, 导致主从服务器的数据库状态出现不一致时, 让主从服务器的数据库重新回到一致状态 同步当客户端向从服务器发送slaveof命令, 要求从服务器复制主服务器时. 从服务器对主服务器的同步操作需要通过向主服务器发送sync命令来完成. 步骤如下: 从服务器向主服务器发送sync命令 收到sync命令的主服务器执行bgsave命令, 在后台生成一个RDB文件. 并使用一个缓冲区记录从现在开始执行的所有写命令 bgsave执行完毕后. 主服务器会将生成RDB文件发送给从服务器. 从服务器载入RDB文件, 使得自己数据库状态和主服务器执行bgsave命令时的状态一致. 主服务器将缓冲区里面的所有写命令发送给从服务器. 从服务器执行这些写命令, 将自己数据库状态更新至主服务器数据库当前所处的状态. 命令传播 为了让主从服务器再次回到一致状态, 主服务器需要对从服务器执行命令传播操作: 主服务器将自己执行的写命令 ,发送给从服务器执行. 当从服务器执行了相同的写命令之后, 主从服务器将再次回到一致状态. 旧版本复制功能的缺陷2.8版本以前复制可以分为以下两种情况: 1. 初次复制. 从服务器从来没父之过任何主服务器, 从服务器当前要复制主服务器和上一次复制的主服务器的不同. 2. 断线后重复制. 对于初次复制来说, 可以很好的完成工作. 但对于断线后重复制来说, 效率是非常低下的. 原因在于每次断线重复制都要复制完成的数据库状态. 不能复制差值. 新版复制功能2.8版本开始, 使用psync命令代替sync命令来执行复制时的同步操作 psync命令具有完整重同步(full resynchronization)和部分重同步(partial resynchronization), 完整重同步用于初次复制情况, 步骤和sync命令执行基本一样, 都是通过发送RDB文件.和发送保存在缓冲区里面的写命令进行同步的而部分重同步则用于处理断线后重复制的情况 如果条件允许, 主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器, 从服务器接收并执行这些写命令, 就可以将数据库更新至主服务器当前所处的状态 psync高效体现在断线后复制情况. 部分冲同步的实现部分重同步功能由一下三个部分构成: 主服务器的复制偏移量,和从服务器的复制偏移量 主服务器的复制积压缓冲区 服务器的运行ID 复制偏移量执行复制的双方-主从服务器都维护一个复制偏移量, 主服务器每次向从服务器传播N个字节的数据时, 就将自己的复制偏移量的值加上N. 从服务器每次收到主服务器传播来的N个字节的数据时, 就将自己的复制偏移量的值加上N. 这样主从服务器只要对比双方的复制偏移量就可以实现部分同步了. 如果主服务器的offset=10086, 从服务器ABC分别都是offset=10086, 就在主服务器要向从服务器传播33字节的数据之前. 从A下线了. BC分别接受了33字节数据, 主服务器和BC的offset=10119, 而断线的A上线了, 向主服务器发送psync命令, 报告当前A服务器的复制偏移为10086. 那么这时主服务器是执行完整同步还是部分同步呢? 如果执行部分同步, 主服务器如何补偿从服务器A在下线期间丢失的那部分数据呢? 复制积压缓存区复制积压缓冲区是由主服务器维护的一个固定长度先进先出队列, 默认大小1MB, 当主服务器进行命令传播的时候, 不仅会将写命令发送给从服务器, 还会将写命令入队到复制积压缓冲区. 当从服务器重新连上只服务器时, 从服务器会通过psync命令将自己的offset发送给主服务器. 主服务器根据这个offset来决定对从服务器执行何种同步操作: 如果offset偏移量之后的数据(offset+1)仍然存在于复制积压缓存区里面, 那么主服务器将对从服务器执行部分重同步操作. 相反, 那么主服务器将对从服务器执行完整重同步操作. 偏移量 … 10087 10088 … 字节值 … ‘*’ 3 … 服务器运行ID实现部分重同步还需要用到服务器运行ID, 每个Redis服务器, 不论主从都有会自己的运行ID. 当从服务器对主服务器进行初次复制时. 主服务器会将自己的运行ID发送给从服务器. 而从服务器会将这个运行ID保存起来. 当从服务器断线后重新连上一个主服务器时, 从服务器将向当前连接的主服务器发送之前保存的运行ID. 如果从服务器保存的运行ID和当前连接的主服务器的运行ID相同. 那么说明从服务器断线之前复制的就是当前连接的这个服务器, 可以尝试执行部分重同步操作. 相反的. 如果运行ID不相同. 主对从执行完整重同步操作. SentinelRedis的高可用解决方案. 有一个或者多个Sentinel实例组成的Sentinel系统可以监控任意多个主服务器以及这些主服务器的所有从服务器. 并在被监控的主服务器进入下线状态时, 自动将下线的主服务器下属的某个从服务器升级为新的主服务器. 然后由新的主服务器代替已下线的主服务器继续处理命令请求. 启动并初始化Sentinel $ redis-sentinel /path/to/your/sentinel.conf 或者 $ redis-server /path/to/your/sentinel.conf –sentinel这连个命令的效果是一样的. 当一个sentinel启动时, 需要执行几个步骤 初始化服务器 将普通Redis服务器使用代码替换成sentinel专用代码 初始化sentinel状态 根据给定的配置文件. 初始化sentinel的监控主服务器列表. 创建连向主服务器的网络连接. 初始化服务器使用sentinel专用代码初始化sentinel状态执行力sentinel专用代码后, 服务器会初始化一个sentinel.c/sentinelState结构体. 保存了服务器中所有和Sentinel功能相关的状态 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556struct sentinelState &#123; //当前纪元, 用于实现故障转移 uint64_t current_epoch; //保存了所有被这个sentinel监控的主服务器, 字典键是主服务器的名字, 字典值则是指向sentinelRedisInstance结构的指针 dict *masters; //是否进入了TILT模式 int tilt; //目前正在执行的脚本数量 int running_scripts; //进入TILT模式的时间 mstime_t tilt_start_time; //最后一次执行时间处理器的时间 mstime_t previous_time; //一个FIFO队列, 包含了所有需要执行的用户脚本 list *scripts_queue;&#125; sentinel;typedef struct sentinelRedisInstance &#123; // 标识符记录实例的类型, 以及该实例的当前状态 int flags; // 实例名称 格式为ip:port, 例如 127.0.0.1:26379 char *name; //实例的运行ID char *runid; //配置纪元 用于实现故障转移 uint64_t config_epoch; //实例的地址 sentinelAddr *addr; //SENTINEL down-after-milliseconds选项设定的值 实例无响应多少毫秒后才会被判断为主观下线 mstime_t down_after_period; //SENTINEL monitor &lt;master-name&gt; &lt;IP&gt; &lt;port&gt; &lt;quorum&gt;选项中quorum参数. 判断这个实例为客观下线所需的支持投票数量 int quorum; //SENTINEL parallel-syncs &lt;master-name&gt; &lt;number&gt;选项的值, 在执行故障转移操作时, 可以同时对新的主服务器进行同步的从服务器数量 int parallel_syncs; // SENTINEL failover-timeout &lt;master-name&gt; &lt;ms&gt; 选项的值 刷新故障迁移状态的最大实现 mstime_t failover_timeout;&#125; sentinelRedisInstance;typedef struct sentinelAddr &#123; char *ip; int port;&#125; sentinelAddr; 创建连向主服务器的网络连接创建连向呗监控主服务器的网络连接, Sentinel将成为主服务器的客户端. 它可以向主服务器发送命令, 并从命令回复中获取相关的信息. 会创建两个连向主服务器的异步网络连接 一个时命令连接, 这个连接专门用于向主服务器发送命令. 并接收命令回复. 一个时订阅连接. 这个连接专门用于订阅主服务器的sentinel:hello频道. 获取主服务器信息Sentinel默认会以每十秒一次的频率, 通过命令连接向被监控的主服务器发送INFO命令, 并通过分析INFO命令回复来获取主服务器的当前信息. Sentinel可以获取两个方面的信息: 关于主服务器本身的信息. 包括run_id域记录的服务器运行ID 已经role域记录的服务器角色. 关于主服务器属下所有从服务器的信息. 每个从服务器由一个”slave”字符串开头的行记录, 每行的ip=域记录了从服务器的IP地址, 而port=域则记录了从服务器的端口号. 根据run_id域和role域记录的信息, Sentinel将堆主服务器的实例结构进行更新, 获取从服务器信息当Sentinel发现主服务器有新的从服务器出现时, Sentinel除了会为这个新的从服务器创建相应的实例结构之外, 还会创建连接到从服务器的命令和订阅连接. 每隔10秒的频率通过命令连接向从服务器发送INFO命令. 检测主观下线状态在默认情况下,Sentinel会每秒一次的频率向所有与其它创建了命令连接的实例(包括主, 从, 其它Sintinel)发送ping命令. 并通过实例返回的ping命令回复来判断实例是否在线. Sentinel配置文件中的down-after-milliseconds选项指定Sentinel判定实例进入主观下线所需的时间长度. 如果一个实例在毫秒内连续向sentinel返回无效回复. 那么Sentinel会将master标记为主观下线. 并在master所对应的实例结构的flags属性中打开SRI_S_DOWN标识 检查客观下线状态当一个Sentinel键一个主服务器判定为主观下线, 为了确认这个主服务器是否真的下线了, 它会想同样监视着一个主服务器的其他Sentinel进行询问, 看它们是否也认为主服务器已经进入了下线状态, 当Sentinel从其他Sentinel那里接收到足够数量的已下线判断之后, Sentinel就会将从服务器判定为客观下线. 并对主服务器执行故障转移. 选举领头Sentinel当一个主服务器被判断为客观下线时, 监控这个下线主服务器的各个Sentinel会进行协商. 选举一个领头Sentinel, 并由证领头的对下线主服务器执行故障转移操作. 所有在线的Sentinel都有资格被选举为领头的. 每个进行领头Sentinel选举之后, 不论选举是否成功. 所有Sentinel的配置纪元的值都会增长1. 在一个配置纪元里, 所有Sentinel都有一次将某个Sentinel设置为局部领头Sentinel的机会.并且局部领头一旦设置, 在这个配置纪元里面就不能再更改. 每个发现主服务器进入客观下线的Sentinel都会要求其他Sentinel将自己设置为局部领头Sentinel. 当一个Sentinel像另一个Sentinel发送SENTINEL is-master-down-by-addr命令, 其中命令中runid参数不是*而是自己的运行ID时, 这就表示希望对方能选自己为局部领头. 设置局部领头是先到先得的. 当一个Sentinel设置了一个Sentinel节点为局部领头. 在收到其他设置局部领头的请求会被拒绝. 当收到设置局部领头命令后, 会向发送者回复一条命令. 回复中的leader_runid参数和leader_epoch参数分别记录了自己的局部领头Sentinel的运行ID和配置纪元. 源Sentinel在接收到目标Sentinel返回的命令回复之后, 检查回复中的leader_runid参数和leader_epoch参数和自己的是否一致, 如果一致表示对方选了自己当局部领头, 不一致, 就是选了别的节点. 如果某个Sentinel呗半数以上的人节点选为局部领头, 那么这个节点就成为了领头Sentinel. 如果在给定时间内, 没选出来. 那么在过一段时间后, 继续选举. 直到选出领头为止. 故障转移领头Sentinel将对已下线的主服务器执行故障转移: 在已下线的所有从服务器中, 挑选出一个从服务器, 并将其装换为主服务器. 将已下线的主服务器属下的所有从服务器改为复制新的主服务器 将已下线主服务器设置为新的主服务器的从服务器. 如何挑选新的主服务器领头Sentinel会将已经下线的主服务器的所有从服务器维护到一个列表里. 然后按照下面的规则. 一项一项筛选: 删除列表中所有已经处于下线或者断线的从服务器. 删除列表中最后5秒内没有回复领头Sentinel的info命令的从服务器. 删除所有与已下线主服务器断开超过down-after-milliseconds * 10 毫秒的服务器 按照从服务器的优先级排序, 如果优先级相同, 比较复制偏移量offset. 如果offset也一样, 就比较运行ID, 取最小的. 集群是Redis提供的分布式数据库方案, 集群通过分片来进行数据共享. 并提供复制和故障转移. 节点节点会继续使用所有在单机模式中使用的服务器组件. 继续使用文件事件处理器来处理命令请求和返回命令回复. 继续使用时间事件处理器来执行serverCron函数. 而serverCron函数又会调用集群模式特有的clusterCron函数. clusterCron函数负责执行在集群模式下需要执行的常规操作. 继续RDB持久化和AOF持久化模块来执行持久化工作. 继续使用发布订阅来执行publish, subscribe命令. 继续使用复制模块来执行节点复制工作., 继续使用lua脚本来执行客户端输入的lua脚本. 在集群下才会用到的数据. 节点将它们保存打到了cluster.h/clusterNode结构, clusterLink. clusterState. 集群数据结构1234567891011121314151617181920212223242526272829303132333435363738394041struct clusterNode &#123; //节点创建时间 mstime_t ctime; //节点的名称, 由40个十六进制字符串 char name[REDIS_CLUSTER_NAMELEN]; //节点标识 int flags; //节点当前的配置纪元, 用于实现故障转移 uint64_t confifEpoch; //节点的端口号 int port; // 保存连接节点所需的有关信息 clusterLink *link;&#125;;typedef struct clusterLink &#123; //连接的创建时间 mstime_t ctime; // TCP套接字描述符 int fd; // 输出缓冲区, 保存着等待发送给其他节点的消息 sds sndbuf; //输入缓冲区, 保存着从其他节点接收的消息 sds rcvbuf; //与这个连接相关连的节点. 如果没有的话就为NULL struct clusterNode *node;&#125; clusterLink;typedef struct clusterState &#123; //指向当前节点的指针 clusterNode *myself; //集群当前的配置纪元, 用于实现故障转移 uint64_t currentEpoch; // 集群当前的状态. 是在线还是下线 int state; // 集群中至少处理着一个槽的节点的数量. int size; // 集群节点名单(包含myself节点) // 字典的键为节点名称. 字典的值为节点对应的clusterNode结构 dict *nodes;&#125; clusterState; Cluster meet命令的实现1cluster meet &lt;ip&gt; &lt;port&gt; 通过向节点A发送cluster meet命令, 客户端可以让接收命令的节点A将另一个节点B添加到节点A当前所在的集群中. A会为B创建clusterNode结构, 并将该结构添加到自己的clusterState.nodes字典中. A将根据cluster meet命令给定的IP地址和端口号. 向节点B发送一条MEET消息. 如果一切顺利, 节点B将接收到节点A发送MEET消息, 节点B会为A创建一个clusterNode机构, 并将该结构添加到自己的clusterState.nodes字典中. B将向节点A返回一条PONG消息 A将接收到节点B放回的PONG消息, 通过这条PONG消息节点A可以知道节点B已经成功接收到了自己发送的MEET消息. 节点A将向节点B返回一条ping信息. B将节点A返回的Ping消息,通过这条PING消息节点B可以知道节点A已经成功地接收到了自己返回PONG消息. 握手完成. 指派槽通过分片的方式来保存数据中的键值对的. 集群的整个数据库被分为16384个槽slot, 数据库中的每个键都属于这16384中的一个. 集群中每个节点可以处理0到16384个槽. 当数据库中的16384个槽都有节点在处理时, 集群处于上线状态. 如果数据库中任何一个槽没有得到处理, 集群初一fail状态. 1234cluster addslots &lt;slot&gt; [slot ...]//表示将0至5000指派给了自己cluster addslots 0 1 2 3 4 ... 5000 记录节点的槽指派信息1234struct clusterNode &#123; unsigned char slots[16384/8]; int numslots;&#125; slots属性是一个二进制数组. 长度为16384/8=2048. 图中数组索引1,3,5,8,9,10的二进制值为1. 其他为0, 表示节点负责处理槽1,3,5,8,9,10因为取出和设置slots数组中的任意一个二进制的值的复杂度仅为O(1) numslots 属性则记录节点负责处理的槽的数量, 也就是slots数组中值为1的二进制位的数量. 记录集群所有槽的指派信息123typedef struct clusterState &#123; clusterNode *slots[16384]&#125; clusterState; slots数组包含16384个项, 每个数组都是指向clusterNode结构的指针. 如果为null, 就是没有指派, 数组项slots[0]至slots[5000]的指针都指向代表A节点clusterNode结构, 表示0-5000都指派给了A. 计算键所属于那个槽和是否由当前节点负责处理12def slot_number(key): return CRC16(key) &amp; 16383 计算出槽号后. 只需要判断clusterState.slots[i]是否等于clusterState.myself, 相等时是当前节点负责. 不等于: 节点会根据clusterState.slots[i]指向的clusterNode结构所记录的IP和端口号. 向客户端放回MOVED错误, 指向客户端转向至正在处理槽I的节点. MOVE错误当节点发现键所在的槽并非由自己负责的时候, 节点就会向客户端返回一个MOVE错误, 指引客户端转向正在负责槽的节点 1move &lt;solt&gt; &lt;ip&gt;:&lt;port&gt; 节点数据库的实现集群节点保存键值对以及键值对过期时间的方式, 和单机Redis服务器保存键值对以及键值对过期时间的方式完全一致. 节点和单机服务器在数据库方面的一个区别是: 节点只能使用0号数据库, 而单机没有这一限制. 除了键值对保存在数据库之外. 节点还会用clusterState结构中的slots_to_keys跳跃表来保存槽和键之间的关系: 123typedef struct clusterState &#123; zskiplist *slots_to_keys;&#125; clusterState; slots_to_keys跳跃表每个节点的分值都是一个槽号. 每个节点的成员都是一个数据库键: 每当节点往数据库中添加一个新的键值对时, 节点就会将这个键以及键的槽号关联到slots_to_keys跳跃表 每当节点删除数据库中的某个键值对时. 节点就会从跳跃表中解除呗删除键与槽号的关联. 通过跳跃表中记录各个数据键所属的槽号. 节点可以很方便地对属于某个或某些槽的所有数据库键进行批量操作. 例如命令 1cluster getkeysinslot &lt;slot&gt; &lt;count&gt; 重新分片集群的重新分片操作可以将任意数量已经指派给某个节点的槽改为指派另一个节点, 并且相关槽所属的键值对也会从源节点移动到目标节点. redis-trib对集群的单个槽slot重新分片的步骤: redis-trib对目标节点发送命令, 让目标节点准备好从源节点导入属于槽slot的键值对. 1cluster setslot &lt;slot&gt; importing &lt;source_id&gt; redis-trib对源节点发送命令 让源节点准备好将属于槽slot的键值对迁移至目标节点. 1cluster setslot &lt;slot&gt; migeating &lt;target_id&gt; redis-trib向源节点发送命令. 获得最多count个属于槽slot的键值对的键名 1cluster getkeysinslot &lt;slot&gt; &lt;count&gt; 对于获得的每个键名, redis-trib都向源节点发送命令. 将被选中的键原子地从源节点迁移至目标节点 1migrate &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt; 重复执行3和4, 知道源节点保存的所有属于槽slot的键值都被迁移至目标节点为止. redis-trib向集群中的任意一个节点发送命令, 将槽slot指派给目标节点, 这一指派信息会传播到整个集群. 1cluster setslot &lt;slot&gt; node &lt;target_id&gt; ACK错误在进行分片期间, 源节点向目标节点迁移一个槽的过程中. 可能会出现客户端发送一个与数据库键相关的命令, 并且命令要处理的数据库键签好就属于正在迁移的槽时: 如果键还在自己数据库中, 直接执行命令返回客户端, 如果没有, 那么这个键可能在目标节点. 源节点会向客户端返回ack错误, 指引客户端向正在导入槽的目标节点, 并在此发送之前想要执行的命令. 1234567typedef struct clusterState &#123; // 记录当前节点正在从其他节点导入的槽, 不为null, 就代表了当前节点正在从clusterNode所代表的节点导入槽i. clusterNode *importing_slots_from[16384]; // 记录当前节点正在迁移至其他节点的槽, 不为null, 就代表了当前节点正在将槽迁移至从clusterNode所代表 clusterNode *migrating_slots_to[16384];&#125; clusterState; 判断是否键在迁移中, 只要看slot[i]中是否有该键. 如果有则向客户端返回ask错误. 引导客户端去目标节点查找key. 接收到ask的客户端根据错误提示的Ip和port, 转向至正在导入槽的目标节点. 然后首先向目标节点发送asking命令, 之后在发送原本想要执行的命令. 原因在于不发送asking. 目标节点会拒绝客户单发送的命令. ACK和MOVE的区别 当客户端收到MOVE错误时, 都可以直接将命令请求发送到move错误所指向的节点. 因为该节点就是目前负责槽IDE节点 ASK错误只是两个节点迁移槽过程中使用的一种临时措施. 当客户端收到ACK错误, 会将命令发送到指向的目标节点上, 但之后客户端依然会将槽i的命令发送至目前负责的处理槽i的节点. 除非ACK错误再次出现. 复制和故障转移为了保障其高可用性. Redis集群提供了给集群节点设置从节点功能. 从节点和主节点数据保持一致, 当主节点宕机后, 选举其他从节点继续处理命令请求. 12345678910struct clusterNode &#123; //如果这是一个从节点, 那么指向主节点 struct clusterNode *slaveof; //正在复制这个主节点的从节点数量 int numslaves; // 数组, 每个数组指向一个正在复制这个主节点的从节点clusterNode结构 struct clusterNode **slaves;&#125; 节点复制和单机Redis复制是一样的. 都是向从节点slaveof master_ip master_port 故障检测集群中的每个节点都会定期地向集群中的其他节点发送PING消息, 以此来检测对方是否在线. 如果接收PING消息的节点没有在规定的时间内, 向发送PING消息的节点返回PONG消息, 那么发送PING消息的节点就会将接收PING消息的节点标记为疑似下线PFAIL. 当半数以上负责处理的主节点都将某个节点X报告为疑似下线. 那么这个主节点X将被标记为已下线(FAIL), 将主节点X标记为已下线的节点会向集群广播一条关于主节点X的FAIL消息, 所有收到这条fail消息的节点都会立即将主节点X标记为已下线. 复制下线主节点的所有从节点里面, 会有一个从节点被选择. 被选中的从节点会执行SLAVEOF no one命令, 成为新的主节点. 新的主节点会撤销所有对已下线主节点的指派槽, 并将这些槽全部指派给自己. 新的主节点向集群广播一条PONG消息, 这些PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点, 并且这个主节点已经接管了原本由已下线节点负责处理的槽. 新的主节点开始接受和自己负责处理的槽有关的命令请求. 故障转移完成. 选举新的主节点1.集群的配置纪元是一个自增计数器, 它的初始值为02.当集群里的某个节点开始一次故障转移操作时. 集群配置纪元的值会被增1. 对于每个配置纪元. 集群里每个负责处理槽的主节点都有一次投票的机会, 而第一个向主节点要求投票的从节点将获得主节点的投票. 当从节点发现自己正在复制的主节点进入下线状态时. 从节点会向集群广播一条消息, 要求所有具有投票权的主节点向自己投票. 如果一个主节点具有投票权, 并且这个主节点尚未投票给其他从节点, 那么主节点将向要求投票的从节点返回消息, 表示自己支持从节点成为新的主节点. 每个参与选举的从节点都会接受到消息,并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持. 如果集群里有N个具有投票权的主节点, 那么当一个从节点收集到大于等于N/2+1张支持票, 这个从节点就会当选为新的主节点. 因为每个配置纪元每个节点只能有一次投票的机会. 能确保新的主节点只会有一个. 如果在一个配置纪元里面没从节点能收集到足够多的支持票, name集群进入一个新纪元, 并再次进行选举, 知道选出新的主节点为止. MEET消息 当发送者收到客户端发送的cluster meet命令时, 发送者会向接收者发送MEET消息, 请求接收者加入到发送者集群. PING消息, 集群中每个节点每隔一秒就会从已知节点列表中随机选出五个节点, 然后对这五个节点中最长时间没有发送ping消息的节点发送ping消息. 以此来检测被选中的节点是否在线. PONG消息, 当收到MEET或者PING消息, 为了向发送者确认这条消息已到达, 接收者会向发送者返回一条PONG消息. FAIL消息,当一个主节点A判断另一个主节点B已经进入FAIL状态时, 节点A会向集群广播一条关于节点B的fail消息 PUBLISH消息, 当节点接收到一个PUBLISH命令时, 节点会执行这个命令, 并向集群广播一条publish消息. 选举领头Sentinel和选举新主节点的方法是非常相似的. 因为两个都是基于Raft算法的领头选举方法来实现的.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>分布式缓存</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql相关]]></title>
    <url>%2F2019%2F05%2F24%2Fmysql%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[引擎及其事务并发控制读写锁为了获得更好的并发控制, 在处理并发读或者写时, 可以通过实现一个由两种类型的锁组成的锁系统来解决问题, 通常称之为为 共享锁和排他锁, 也叫读锁和写锁. 读锁是共享的, 多个客户在同一个时刻同时读取一个资源. 而互不干扰. 写锁是排他的. 一个写锁会阻塞其他的写锁和读锁. 这是出于安全策略的考虑. 锁的颗粒度表锁. 开销最小的策略. 它会锁整张表, 一个用户在对表进行写操作(CUD)前. 需要选获得写锁, 这会阻塞其他用户对改表的所有读写操作. 行级别锁. 最大程度的支持并发处理. 事务隔离级别A 原子性, 每个事务都不可分割. 事务中的所有操作要么全部提交. 要么全部回滚. C 一致性 从一个一致性状态装换到另一个一致性状态. I 隔离性 一个事务所做的修改在最终提交之前, 其他事务是不可见的. D 持久性 一旦事务提交. 则其所做的修改就会永久保存到数据库, 即便是系统崩溃. 修改的数据也不会丢失. read uncommitted 未提交读: 事务中的修改. 即便是未提交. 对其他事务也都是可见的. 俗称脏读. read committed 提交读: 一个事务开始时, 只能看见已经提交的事务所做的修改.一个事务从开始到提交之前. 所做的任何修改对其他事务都是不可见的. 也叫不可重复读. repeatable read 可重复读: 解决了脏读问题, 保证了在同一事务中多次读取同样记录的结果是一致的. 但会产生幻读问题. 当前事务在读取某个范围内的记录时. 另外一个事务又在该范围内插入了新的记录. 当之前的事务再次读取改范围的记录时. 会产生幻行. serializable 可串行化. 通过强制事务串行执行. 避免了幻读. 事务日志使用事务日志, 存储引擎在修改表的数据只需要修改其内部拷贝. 再把该修改行为记录到持久在硬盘上的事务日志中, 而不用每次都将修改的数据本身持久到磁盘. 事务日志采用的是追加的方式. 是磁盘上一小块区域内的顺序I/O. 多版本并发控制InnDB的MVCC是通过每行记录后面保存两个隐藏的列来实现的. 一个保存了行的创建时间. 一个保存了行的过期时间或者是删除时间. 当然存储的斌不是时间的时间值 而是系统版本号. 每开始一个事务, 系统版本号都会自动递增.事务开始时刻的系统版本号会作为事务的版本号. 用来和查询到的每行记录的版本号进行比较. select InnoDB只查找版本早于当前事务版本的数据行. 查找&lt;=事务的系统版本号的. 行的删除版本号要么未定义. 要么大于当前事务版本号. 这样能保证事务开始之前数据行未被删除. insert InnoDB为新插入的每一行保存当前系统版本号作为行版本号 delete InnoDB为删除的每一行保存当前系统版本号为行删除标记. update InnoDB为插入一行新记录. 保存当前系统版本号作为行版本号, 同时保存当前系统版本号到原来的行作为行删除标识. 保存这两个额外系统版本号, 使大多数操作都可以不同加锁. MVCC只在repeattable read和read committed两个隔离级别下工作. 引擎InnoDB默认事务性引擎, 被设计用来处理大量的短期事务, 短期事务大部分是正常提交的. 很少有会被回滚. 采用MVCC来支持高并发, 内部做了很多优化. 包括从磁盘去读数据时采用的可预测预读. 能够自动在内存中创建hash索引以加速读操作的自适应哈希索引. MyISAM存储引擎不支持事务和行级锁, 而且有一个毫无疑问缺陷就是奔溃后无法完全恢复. 对于只读的数据, 或者表比较小. 依然可以继续使用. 创建高性能的索引索引在mysql中也key, 是存储引擎用于快速找到记录的一种数据结构. 索引类型 B-Tree索引 当没有做特别说明的时候, 说到索引基本是指B-Tree索引. 它使用B-Tree数据结构来存储数据. 大多数Mysql引擎支持这种索引. 不过. 底层的存储引擎也可能使用不同的存储结构. 例如 InnoDB是B+Tree. B-Tree通常意味着所有的值是按顺序存储的. 并且每个叶子页到根的距离是相同的. 能够加快访问数据的速度. 因此存储引擎不在需要进行全表扫描来获取需要的数据. 只需要从根节点开始搜索. 根节点存储了指向子节点的指针. 存储引擎根据这些指针向下层查找. 通过比较节点页的值和要查找的值可以找到合适的指针进入下层子节点. 这些指针实际上定义了子节点页中指的上下限. 最终存储引擎要么找到对应的值. 要么该记录不存在. B-Tree对索引列是顺序组织存储的. 所以很适合查找范围数据. 1234567CREATE TABLE `people` ( `last_name` varchar(50) NOT NULL, `first_name` varchar(50) NOT NULL, `dob` date NOT NULL, `gender` enum('m','f') NOT NULL, KEY `last_name` (`last_name`,`first_name`,`dob`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 对于表中每行数据. 索引包含,last_name, first_name, dob列的值. 可以使用B-Tree索引的查询类型. B-Tree索引适用于全键值, 键值范围或者键前缀查找, 其中键前缀查找只适用于根据最左前缀的查找. 全值查询 全值匹配是指和索引中的所有列进行匹配, 例如 last_name = “Allen” AND first_name = “Cuba” AND dob = ‘1900-01-01’; 匹配最左前缀 用于查询所有姓为Allen的人, 即指使用了索引的第一列 last_name 匹配列前缀 也可以匹配某一列的值的开头部分. 例如 查找所有J开头的姓的人, last_name like ‘J%’, 也只是用了索引第一列. 精确匹配某一列并范围匹配另一列, 例如 last_name=’Allen’ and frist_name like ‘K%’ 只访问索引查询 B-Tree通常是可以支持只访问索引查询, 即查询只访问索引. 二无需访问数据行 因为索引树中节点是有序的. 所以除了按值查询之处, 索引还可以用于查询中Order By操作. 一般来说B-Tree可以按照某种方式查询, 那么也可以按照某种方式用于排序, 如果Order by子句满足前面列出的几种查询类型. 则这个索引页可以妈祖对应的排序需求. B-Tree索引的限制: 如果不是按照索引的最左列开始查找, 则无法使用索引. 例如: 索引无法查找名字为bill的人, 无法查找某个特定生日的人, 因为这两列都不是最左数据列, 类似的也无法查找姓氏以某个字母结尾的人. 不能跳出索引中的列 如果查询中某个列的范围查询. 则其右边所有列都无法使用所以优化查询. 例如: last_name = “Allen” AND frist_name like ‘K%’ AND dob = ‘1900-01-01’ 这个查询只能使用索引的前两列, 因为这里like是范围条件. 如果范围查询列值的数量有限.那么可以通过使用多个等于条件代替范围条件. 哈希索引基于哈希表实现. 只有精确匹配索引所有列的查询才有效. 对于每一行数据. 存储引擎都会对所有的索引列计算一个哈希码, 哈希码是一个较小的值. 并且不同键值的行计算出来的哈希码也不一样. 用拉链发解决哈希冲突. 因为索引自身只需存储对应的哈希值. 所以索引的结构十分紧凑. 这也让哈希索引查询的速度非常快. 限制: 哈希索引只包含哈希值和行指针. 而不存储字段值. 所以不能使用索引的值来避免读取行. 哈希索引数据并不是按照索引值顺序存储的. 所以也就无法用于排序. 哈希索引也不支持部分索引列匹配查询. 因为哈希索引始终是使用索引列的全部内容来计算哈希值的 哈希索引只支持等值比较查询. 包括= in != 访问哈希索引的数据非常快, 除非有很多哈希冲突. 如果哈希冲突很多. 一些索引维护操作的代价也会很高. InnoDB引擎有一个特殊的功能叫做自适应哈希索引 当InnoDB注意到这些索引值被使用的非常频繁是, 它会在内存中基于B-Tree索引之上再创建一个哈希索引. 这样就让B-Tree索引页具有哈希索引的一些优点. 创建自定义哈希索引1234567891011121314151617181920// 建表create table pseudohash( id int unsigned not null auto_increment, url varchar(255) not null, url_crc int unsigned not null default 0, primary key(id));// 创建触发器delimiter //create trigger pseudohash_crc_ins before insert on pseudohash for each row begin set NEW.url_crc=crc32(NEW.url);end;//create trigger pseudohash_crc_upd defore update on pseudohash for each row begin set NEW.url_crc=crc32(NEW.url);end;//delimiter ; 如果数据量非常大, CRC32()会出现大量的冲突, 则可以考虑哈希冲突较少的hash函数例如 FNV64. 另外在查询的时候. 必须在where子句中包含 哈希字段url_crc和url. 这样一方面优化哈希函数. 减少哈希冲突. 另一方面即便出现哈希冲突. 也能在有效的数据行内.进行查找. 相当于遍历链表嘛. 索引的优点索引可以让服务器快速的定位到表的指定位置. 但这并不是索引的唯一目的. 减少服务器需要扫描的数据量 可以帮助服务器避免排序和临时表 将随机I/O变成顺序I/O 三星系统 : 索引将相关的记录放到一起则获得一星. 如果索引总的数据顺序和查找中的排序顺序一致则获得二星. 如果索引中的列包含了查询中需要的全部列则获得三星. 高性能的索引策略独立的列意思是 where actor_id+1=5. 这是用不了索引的. 应该写成actor=4. 不要再查询条件里写函数. 前缀索引和索引选择性索引选择性是指. 不重复的索引值和数据表的记录总数T的比值. 范围从1/T到1直接. 索引的选择性越高则查询效率越高. 选择性越高意味着查询时过滤掉了更多的数据行. 唯一索引的选择性是1. 12345select count(distinct left(city,3))/count(*) as sel3, count(distinct left(city,4))/count(*) as sel4, count(distinct left(city,5))/count(*) as sel5, count(distinct left(city,6))/count(*) as sel6, count(distinct left(city,6))/count(*) as sel7 from city; 查询显示前缀达到6的时候, 再增加前缀长度, 选择性就不变了.所以创建前缀索引 1alter table city add key (city(6)); 前缀索引是一种嫩使索引更小, 更快的有效办法. 当另外一方面的缺点是: Mysql无法使用前缀索引做order by和group by, 也无法使用前缀索引做覆盖查询. 多列索引这种索引策略, 经常被误解为每个列都建立索引. 或者按照错误的顺序创建多列索引 在多个列上建立单独索引大部分情况下并不能提高Mysql的查询性能. 在5.0版本以后引入了索引合并的策略. 一定程度上可以使用表上的多个单列索引来定位指定的行. 这种算法有三个变种: or条件的联合(union), and条件的相交. 索引合并策略有时候时钟优化的结果. 但实际上更多时候说明了表上的索引建的很糟糕: 当出现服务器对多个索引做相交操作时. 多个and条件. 意味着需要一个包含所有相关列的多列索引. 而不是多个独立的单列索引 当服务器对多个索引做联合操作时. 通常需要消耗大量CPU的内存资源在算法的缓存. 排序和合并操作上. 特别是当其中有些索引的选择性不高. 需要合并扫描放回大量数据的时候. 更重要的是. 优化器不会吧这些计算到查询成本中. 优化器只关心随机页面读取. 这会使得查询的成本被低估. 导致该执行计划还不如直接走全表扫描. 通常来说将查询改写成union方式往往更好. 选择合适的索引列顺序将选择性最高的列放在索引最前列通常不如避免随机IO和排序那么重要. 如果不考虑排序和分组. 将选择性最高的列放在前面通常是很好的. 簇租索引这不是一种单独的索引类型. 而是一种数据存储方式. 具体细节依赖其实现方式, 单InnoDB的簇租索引实际上在同一个结构中保存了B-Tree和数据行. InnoDB中叶子页包含了行的全部数据, 节点页包含了索引列. InnoDB通过主键聚集数据.如果没有定义主键. InnoDB会选择一个唯一为空索引代替, 如果没有这样的索引, InnoDB会隐世定义一个主键来作为簇租索引. InnoDB只聚集在同一个页面中的记录. 包含相邻键值的页面可能会很远. 优点: 可以吧相关数据保存在一起. 例如实现电子邮件时. 可以根据用户ID来聚集数据, 这样只需要从磁盘读取少的数据页就能获取某个用户的全部邮件. 数据访问更快. 聚簇索引和数据保存在同一个B-Tree中, 因此从聚簇索引中获取数据通常比在非聚簇索引中查询要快. 使用覆盖索引扫描的查询可以执行使用页节点中的主键值. 缺点: 聚簇数据最大限度提高了I/O密集度性应用的性能. 但如果数据全部都放在内存中. 则访问顺序就没那么重要了. 插入数据严重依赖查询顺序. 如果按照主键的顺序插入加载数据到InnoDB表中速度最快的方式. 但如果不是按照主键顺序加载数据, 那么在加载完成后最好使用Optimize table命令重新组织一下表. 更新聚簇索引列的代价很高. 因为会强制InnoDB将每个被更新的行移动到新的位置. 基于聚簇索引的表在插入新行, 或者主键呗更新导致需要移动行的时候, 可能面临”页分裂”的问题. 聚簇索引可能导致全表扫描变慢. 尤其是行比较稀疏, 或者由于页分裂导致数据存储不连续的时候. 二级索引可能比想象的要更大. 因为在二级索引的叶子节点包含了引用行的主键列. 二级索引访问需要两次索引查找. 而不是一次. 覆盖索引如果一个索引包所有需要查询的字段的值, 称为覆盖索引. 使用索引扫描来排序123456789101112131415unique key rental_date(rental_date, inventory_id, customer_id)// 这个查询没有问题. 因为order by 使用的两列就是索引的最左前缀where rental_date &gt; '2005-05-25' order by rental_date, inventory_id;// 这个使用了两种不同的排序方向, 但是索引都是正序排序的where rental_date = '2005-05-25' order by inventory_id DESC, customer_id ASC;// 这个查询的ORDER BY子句中引用了一个不再索引中的列where rental_date = '2005-05-25' order by inventory_id, staff_id;// 这个查询的where和order by中的列无法组合成索引的最左前缀where rental_date = '2005-05-25' order by customer_id;// 这个查询在索引列的第一列上是范围条件, 所以Mysql无法使用索引的其余列where rental_date &gt; '2005-05-25' order by inventory_id, customer_id;// 这个查询在inventory_id列上有多个等于条件, 对于排序来说, 这也是一种范围查询where rental_date = '2005-05-25' and inventory_id in(1,2) order by customer_id; 冗余和重复索引mysql允许在相同列上创建多个索引. 无论是有意还是无意. mysql需要单独维护重复的索引. 并且优化器在优化查询的时候也需要逐个地进行考虑. 这回影响性能. 重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引. 发现以后应该立即删除. 创建了索引(A,B), 再创建索引A就是冗余索引. 但是在创建索引(B,A), 这不是冗余索引. 索引B也不是冗余了. 延时关联 Select from profiles inner join (select from profiles where x.sex=”M” order by rating limit 100000, 10) as x using();]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis相关]]></title>
    <url>%2F2019%2F05%2F16%2FRedis%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[数据结构简单动态字符串 (SDS)12345678struct sdshdr &#123; // 记录buf[]数组中已经使用字节的数量, 等于SDS所保存字符串长度 int len; // 记录buf数组中未使用字节的数量 int free; // 字节数组, 用于保存字符串 char buf[]&#125; 由于len的存在. 保证了获取一个SDS的长度复杂度为O(1); 由于free属性的存在. 避免了C字符串的内存泄漏问题, 也减少了修改字符串时带来的内存重分配次数 空间预分配 如果对SDS进行修改之后, SDS长度将小于1MB. 那么程序分配和len属性同样大小的未使用空间 如果对SDS进行修改之后. SDS长度将大于1MB, 那么程序会分配1MB未使用空间. 二进制安全不仅可以保存文本数据. 还可以保存任意格式的二进制数据. 链表链表和链表节点实现123456789101112131415161718192021222324typedef struct listNode&#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点数据 void *value;&#125;listNode;typedef struct list &#123; //表头节点 listNode *head; //表尾节点 listNode *tail; //链表所包含节点数 unsigned long len; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void (*free)(void *ptr); //节点值对比函数 int (*match) (void *ptr, void *key);&#125; list; 特性: 双端 获取某个节点前置节点和后置节点的复杂度都是O(1); 无环 表头节点prev和表尾节点tail指针都指向NULLl; 带表头和表尾指针, 获取表头和表尾复杂度为O(1); 带链表长度计数器 获取链表中节点数量的复杂度0(1); 多态 链表可以用于保存各种不同类型的值 字典又称符号表,关联数组,映射是一种用于保存键值对的抽象数据结构. 字典的实现使用哈希表作为底层实现. 一个哈希表里面可以有多个哈希表节点, 而每个哈希表节点就保存了字典中的一个键值对. 哈希表123456789101112131415161718192021222324typedef struct dictht &#123; // 哈希表 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码, 用于计算索引值 总是等于size-1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;&#125; dicthttypedef struct dictEntry &#123; // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; // 指向下个哈希表节点, 行程链表 struct dictEntry *next;&#125; dictEntry; table是一个数组, 每个dictEntry结构保存着一个键值对. size属性记录了哈希表的大小. 也就是table的大小. used属性则记录了哈希表目前已有节点数量. sizemask属性的值总是等于size-1, 这个属性和哈希值一起决定一个键应该被放到table数组的那个索引上面. key属性保存着键值对中的键. v 属性则保存着简直对中的值. 其中键值对的值可以是一个指针, 或者是uint64_t整数. 又或是一个int64_t整数 next属性是指向另一个哈希表的指针. 字典实现12345678910111213typedef struct dict &#123; // 类型特定函数 dictType * type; // 私有数据 void *privdata; // 哈希表 dictht ht[2]; // rehash索引 当rehash不在进行时, 值为-1 int trehashidx;&#125; dict; type属性是一个指向dictType结构的指针, 每个dictType结构保存了一簇用于操作特定类型键值对的函数 而privdata属性则保存了需要传给那些类型特定函数的可选参数 ht属性是一个包含两个项的数组, 数组中每个项都是dictht哈希表, 一把情况下 字典只使用ht[0]哈希表, ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用. trehashidx 记录rehash目前的进度. 解决键冲突拉链法. dictEntry节点组成的链表没有执行链表表尾的指针. 程序将新节点添加到链表的表头位置. rehash随着操作的不断执行, 哈希表保存的键值对会逐渐地增多或者减少, 为了让哈希表负载因子维持在一个合理的范围内. 程序需要对哈希表的大小进行相应的拓展和收缩. 拓展和收缩哈希表的工作可以通过执行rehash操作来完成. 步骤: 为字典ht[1]哈希表分配空间, 这个哈希表的空间大小取决于要执行的操作, 以及ht[0]当前包含的键值对数量. 即是ht[0].used属性的值. 将保存在ht[0]中的所有键值对rehash到ht[1]上面. 当ht[0]所包含的键值对都迁移到了ht[1]之后. 释放ht[0], 将ht[1]设置为ht[0], 并在ht[1]新创建一个空白哈希表. 为下一次rehash做准备. 渐进式rehashrehash动作并不是一次性, 集中式的完成, 而是分多次, 渐进式的完成. 在rehash进行期间, 每次对字典执行添加. 删除, 查找或者更新操作时. 程序除了执行指定的操作以外. 还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]. 在渐进式rehash执行期间. 字典的删除 查找 更新等操作会在两个哈希表上进行. 例如查找一个键的话. 程序会先在ht[0]里面进行查找. 如果没找到. 会继续到ht[1]里面进行查找. 另外, 新增的字典键值对一律保存到ht[1]里面. 跳跃表有序数据结构, 他通过在每个节点中维护多个指向其他节点的指针, 从而达到库快速访问节点的目的. 实现 header 指向跳跃表的头节点 tail 指向跳跃表的表尾节点 level 记录目前跳跃表内. 层数最大的那个节点的层数.(表头节点的层数不计算在内) length 记录跳跃表的长度. 也是跳跃表目前包含节点的数量.(表头节点的层数不计算在内) 1234567891011121314151617//跳跃表节点typedef struct zskiplistNode &#123; // 后退指针 struct zskiplistNode *backward; //分值 double score; //成员对象 robj *obj; // 层 struct zskiplistLevel &#123; // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; &#125; level[];&#125; zskiplistNode; 层. 跳跃表节点的level数组可以包含多个元素. 每个元素都包含一个指向其他节点的指针. 每次创建一个新跳跃表节点的时候, 程序都根据幂次定律(越大的数出现的概率越小)随机生成一个介于1和32之前的值作为level数组的大小. 这个大小就是层的高度 前进指针. 每一层都有一个指向表尾方向的前进指针(level[i].forward)属性, 用于从表头向表尾方向访问节点. 跨度 层的跨度(level[i].span属性)用于记录两个节点之间的距离. 跨度越大, 相距距离越远.指向null的所有前进指针的跨度为0. 跨度是用来计算rank的. 后退指针. 节点的后退指针(backward属性)用于从表尾向表头方向访问节点: 根可以一次跳过多个节点的前进指针不同. 因为每个节点只有一个后退指针. 所以每次只能后退至前一个节点.5 分值和成员. score是一个double类型的浮点数. 跳跃表中所有节点都按照分值从小到大来排序. member是一个指针. 指向一个字符串对象. 而字符串对象则保存着一个SDS值. 123456789//跳跃表typedef struct zskiplist &#123; //表头和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;&#125;zskiplist; 1.header 指向跳跃表的表头节点2.tail 指向跳跃表的表尾节点3.level 记录目前跳跃表中, 层数最大的那个节点的层数.4.length 记录跳跃表长度, 目前跳跃表包含的节点数量(不计算表头) 整数集合是集合键的底层实现. 当一个集合只包含整数值元素时, 并且这个集合的元素数量不多时, Redis就会使用整数集合作为集合键的底层实现 12345678typedef struct intset &#123;//编码方式uint32_t encoding;// 集合包含的元素数量uint32_t length;// 保存元素的数组int8_t contents[];&#125;intset; contents数组是整数集合的底层实现, 每个元素都是contents数组的一个数组项, 各个项在数组中按值的大小从小到大有序地排列. 不包含重复项. length属性记录了整数集合包含的元素数量. 即使contents数组的长度. encoding编码方式.虽然inset结构将contents属性声明为int8_t类型的数组, 单实际上并不保存任何int8_t类型的值, 数组真正类型取决于该属性的值. 升级每当要将一个元素添加到整数集合里面. 并且新元素的类型比整数集合现有的所有的元素类型都要长. 整数集合需要先进行升级, 然后才将新元素添加到整数集合里面, 升级整数集合并添加新元素共分为三步: 根据新元素的类型, 扩展整数集合底层数组的空间大小. 并为新元素分配空间, 将底层数组现有的所有元素都装换成和新元素相同的类型. 并将类型装换后的元素放置在正确的位置上, 并保证有序性. 将新元素添加到底层数组里面 升级带来了灵活性, 节约内存. 不支持降级. 压缩列表列表键和哈希键的底层实现, 当一个列表建只包含少量列表项,并且每个列表项那么是小整数,要么长度比较短的字符串,那么Redis就用压缩列表做列表键的底层实现.为结余内存开发,由一系列特殊编码的连续内存块组成的顺序型数据结构 实现数据节点结构:previous_entry_length|encoding|content zlbytes 记录整个压缩列表占用的内存字节数 zltail 4字节 记录表尾节点距离起始地址有多少字节数 zllen 2字节 记录压缩列表包含的节点数量,当值小于65535, 这就是长度, 大于就要去遍历了 entryX 列表节点, 数据节点, 节点长度由保存的内容决定 zlend 用于标记压缩列表的末端 previous_entry_length 记录压缩列表前一个节点的长度, 1字节(前一个节点的长度小于254), 5字节(前一个节点长度大于等于254) encoding 记录节点content属性保存数据的类型和长度 content 保存节点值 连锁更新1.新增一个大于254长度的节点到原本只是长度界于(250-253)长度的列表中. 就会导致连锁更新2.删除一个节点, 如果该节点前节点大于254,二后节点小于254, 也会导致连续更新3.保证. 本来连续多个界于250-253大小的本就几率很小, 即便是发生了只要连续更新的节点数量不多, 就不会影响性能 对象Redis用到的所有主要的数据结构, 比如简单动态字符串, 双端链表. 字典. 压缩列表, 整数集合. Redis并没有直接使用这些数据结构来实现键值对数据库, 而是基于这些数据结构创建了一个对象系统. 这个系统包含了字符串对象. 列表对象. 哈希对象. 集合对象. 有序集合对象这五种类型的对象. Redis的对象系统还实现了基于引用计数技术的内存回收机制. 还实现了对象共享机制. 对象的类型和编码1234567891011121314151617typedef struct redisObject &#123; // 类型unsigned type:4;// 编码unsigned encoding:4;//指向底层实现数据结构的指针void *ptr//引用计数int refcount;//对象最后一次被命令程序访问的时间unsigned lru:22;&#125; robj; 类型 类型常量 对象的名称 TYPE命令的输出 REDIS_STRING 字符串对象 “string” REDIS_LSIT 列表对象 “list” REDIS_HASH 哈希对象 “hash” REDIS_SET 集合对象 “set” REDIS_ZSET 有序集合对象 “zset” 编码和底层实现encoding属性记录了对象所使用的编码. 也就是这个对象使用了什么数据结构作为对象的底层实现. 类型 编码 对象 REDIS_STRING REDIS_ENCODING_INT 使用整数值实现的字符串对象。 REDIS_STRING REDIS_ENCODING_EMBSTR 使用 embstr 编码的简单动态字符串实现的字符串对象。 REDIS_STRING REDIS_ENCODING_RAW 使用简单动态字符串实现的字符串对象。 REDIS_LIST REDIS_ENCODING_ZIPLIST 使用压缩列表实现的列表对象。 REDIS_LIST REDIS_ENCODING_LINKEDLIST 使用双端链表实现的列表对象。 REDIS_HASH REDIS_ENCODING_ZIPLIST 使用压缩列表实现的哈希对象。 REDIS_HASH REDIS_ENCODING_HT 使用字典实现的哈希对象。 REDIS_SET REDIS_ENCODING_INTSET 使用整数集合实现的集合对象。 REDIS_SET REDIS_ENCODING_HT 使用字典实现的集合对象。 REDIS_ZSET REDIS_ENCODING_ZIPLIST 使用压缩列表实现的有序集合对象。 REDIS_ZSET REDIS_ENCODING_SKIPLIST 使用跳跃表和字典实现的有序集合对象。 字符串对象字符串对象的编码可以是int raw或者embstr 如果一个字符串对象保存的是整数. 并且这个整数值可以用long类型表示. 那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面.并将对象的编码设置为int. 如果字符串对象保存的是一个字符串值. 并且这个字符串值的长度大于39字节. 那么字符串对象将使用一个简单动态字符串(SDS)来保存这个字符串值, 并将对象的编码设置为raw. 如果字符串对象保存的是一个字符串值,并且长度小于等于39字节.解 那额字符串对象将使用embstr编码方式来保存这个字符串值. embstr编码是专门用来保存短字符串的一种优化编码方式. 这种编码和raw一样. 都是使用redisObject和sdshdr结构来表示字符串对象 当raw编码会调用两次内存分配函数来创建redisObject和sdshdr结构. 而embstr编码则通过调用一次内存分配函数来分配一块连续的空间, 空间依次包含redisObject和sdshdr连个结构 值得注意的是可以用double和long类型表示的浮点数在Redis中也是作为字符串值来保存的. 列表对象列表对象的编码可以是ziplist或者linkedlist. ziplist编码的列表对象使用压缩列表为底层实现. 每个压缩列表节点(entry)保存了一个列表元素. linkedlist编码的列表对象使用双端链表作为底层实现. 每个双端链表节点都保存了一个字符串对象. 而每个字符串对象都保存了一个列表元素. 编码转换当列表对象可以同时满足以下两个条件时. 列表对象使用ziplist编码: 列表对象保存的所有字符串元素的长度都小于64字节. 列表对象保存的元素数量小于512个; 哈希对象哈希对象的编码可以是ziplist或者hashtable. ziplist编码的哈希对象使用列表作为底层实现, 每当有新的键值对要加入到哈希对象时. 程序会先将保存了键的压缩列表节点推入到压缩列表表尾. 然后再降保存了值的压缩节点推入压缩列表表尾. 保存了同一键值对的两个节点总是紧挨在一起, 保存键的节点在前, 保存值的节点在后. 先添加到哈希对象中的键值对会被放在压缩列表的表头方向. 而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向. hashtable编码的哈希对象使用字典作为底层实现. 哈希对象中的每个键值对都使用一个字典键值对来保存的. 字典的每个键都是一个字符串对象. 对象中保存了键值对的键. 字典的每个值都是一个字符串对象. 对象中保存了键值对的值. 哈希对象编码转换当哈希对象可以同时满足以下两个条件. 哈希对象使用ziplist编码: 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节. 哈希对象保存的键值对数量小于512个; 集合对象集合对象的编码可以是intset或者hashtable. intset编码的集合对象使用整数集合作为底层实现. 集合对象包含的所有元素都保存在整数集合里面. 集合对象编码转换当集合对象可以同时满足一下两个条件时, 对象使用intset编码: 集合对象保存的所有元素都是整数数值. 集合对象保存的元素数量不超过512个. 有序集合对象有序集合的编码可以是ziplist或者skiplist. ziplist有序集合对象使用压缩列表作为底层实现. 每个集合元素使用两个紧挨在一起的压缩列表节点来保存. 第一个节点保存元素的成员(member), 而第二个元素则保存元素的分值(score). 压缩列表内的集合元素按分值从小到大进行排序. 分值较小的元素被放置在靠近表头的位置. skiplist编码的有序集合对象使用zset结构作为底层实现. 1234typedef struct zset &#123; zskiplist *zsl; dict *dict;&#125; zset; zset结构中的zsl跳跃表按分值从小到大保存了所有集合元素, 每个跳跃表节点都保存了一个集合元素. 通过这个跳跃表, 程序可以对有序进行范围型操作, 比如ZRANK, ZRANGE等命令都是基于条跳跃表API来实现的. zset结构中的dict字典为有序集合创建了一个从成员到分值的映射. 通过这个字典, 程序可以用0(1)复杂度查找给成员的分值. ZCORE命令实现了这一特性. 为什么有序集合需要同时使用跳跃表和字典来实现为了保证范围发现和精准查询都有效率保证. 有序集合的编码转换当有序集合对象可以同时满足一下两个条件时, 对象使用ziplist编码: 有序集合保存的元素数量小于128个 有序集合保存的所有元素成员的长度都小于64字节. 内存回收因为C语言并不具备自动内存回收功能. 所以Redis在自己的对象系统中构建了一个引用计数计数实现的内存回收机制. 通过这一机制, 程序可以通过跟踪对象的引用计数信息. 在适当的时候自动释放对象并进行内存回收. 在创建一个新对象时, 引用计数的值会被初始化为1; 当对象被一个新程序使用时. 它的引用计数值+1; 当对象不再被一个程序使用时, 它的引用计数值会被-1; 当对象的引用计数值变为0. 对象所占用的内存会被释放. 对象共享假设键A创建了一个包含整数值100的字符串作为值对象. 如果这是B也要创建一个同样保存了整数值100的字符串对象作为值对象. 那么服务器有以下两种做法: 为B新创建一个包含整数值100的字符串对象. 让键A和键B共享同一个字符串对象. 将数据库键的值指针指向一个现有的值对象 将被共享的值对象的引用计数+1 目前来说, Redis会在初始化服务器的时候, 创建一万个字符串对象. 这些对象包含了从0到9999的所有整数值. 当服务器需要用到值0-9999的字符串对象时. 服务器就会使用这些共享对象, 而不是新创建对象. 对象的空转时长redisObject有一个lru属性. 该属性记录了对象最后一次命令程序访问的时间. 如果服务器打开了maxmemory选项. 并且服务器用于回收内存的算法为volatile-lru或者allkeys-lru, 那么当服务器张勇的内存数超过了maxmemory选项设置的上限值时. 空转时长较高的那么部分键会被优先释放. 过期键删除策略Redis数据库结构: 1234567891011121314151617181920struct redisServer &#123; //.... // 数组, 保存着服务器中的所有数据库 redisDb *db; // 服务器的数据库数量 int dbnum; //...&#125;typedef struct redisDb &#123; //... // 数据库键空间, 保存着数据库中所有键值对 dict *dict; // 过期字典, 保存着键的过期时间. dict *expires; //...&#125; redisDb; 定时删除 创建一个定时器(timer) 让定时器在键的过期时间来临时, 立即执行对键的删除操作. 惰性删除 放任键过期不管. 但是每次从键空间获取键时. 都检查取得的键是否过期. 如果过期的话, 就删除键, 如果没有过期就返回该键 定期删除 每隔一段时间, 程序就对数据库进行一次检查, 删除里面的过期键, 至于要删除多少过期键, 以及要检查多少个数据库, 又算法决定. 定时删除对内存是最友好的. 使用定时器, 定时删除策略可以保证过期键会尽可能快地被删除, 并释放过期键所占用的内存. 但是对CPU时间是最不友好的, 过期键比较多的情况下, 删除过期键这一行为坑你会占用相当一部分CPU时间. 这无疑会对服务器的响应时间和吞吐量造成影响 另外创建一个定时器需要用到Redis服务器中的时间事件, 而当前时间事件的实现方式—–无序链表, 查找一个事件的时间复杂度为O(N), 并不能高效地处理大量时间事件. 惰性删除对CPU时间来说是最友好的: 程序只会在取出键时才会对键进行过期检测. 这可以保证删除过期键的操作只会在非做不可的情况下进行. 并且删除的目标仅限于当前处理的键, 它对内存是最不友好的. 键过期了, 依然保存在数据库中, 它所占用的内存就不会被释放. 如果过期键非常多, 而这些过期键又恰好没有被访问到的话, 那么它们也许永远也不会被删除. 定期删除定时和惰性都有各自明显的缺点. 定期删除策略做了一个整合和折中: 定期删除策略每隔一段时间执行一次删除过期键操作. 并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响. 定期删除策略有效的减少了因为过期键而带来的内存浪费 注意事项: 不能太频繁, 一次删除的过期键也不能太少. 如果采用定期删除策略, 服务器必须根据情况吗合理的设置删除操作的执行时长和执行频率. AOF. RDB和复制功能对过期键的处理 生成RDB时. 在执行SAVE和BGSAVE命令创建新RDB文件时. 会对数据库中的键进行检查. 已过期的键不会被保存到新RDB文件中. 载入RDB文件. 以主服务器运行时, 过期键会被忽略 以从服务器模式运行. 文件中保存的所有键都会被载入. 不论是否过期. 因为主从服务器进行数据同步的时候, 从服务器的数据库就会被清空. AOF文件写入. 当过期键杯惰性删除或者定期删除之后, 程序会想AOF文件追加一条del命令. 来显示地记录改间已被删除. AOF重写. 程序会对数据库中的键进行检查, 已过期的键不会被保存到重写后的AOF文件中. 复制 主服务器咋删除一个过期键之后, 会显式地项所有从服务器发送一个DEL命令. 告知从服务器删除这个键. 从服务器咋执行客户端发送读命令时, 即使碰到过期键也不会将过期键删除. 而继续像处理未过期键一样来处理过期键 从服务器只有在接到主服务器发来的DEL命令之后, 才会删除过期键. RDB持久化有两个Redis命令可以用于生产RDB文件, 一个时SAVE, 另一个是BGSAVE. SAVE命令会阻塞Redis服务器进程. 知道RDB文件创建完毕为止. 客户端发送的所有命令请求都会被阻塞. BGSAVE命令会派生出一个子进程. 然后由子进程负责创建RDB文件. 服务器进程继续处理命令请求. RDB文件的载入工作是咋服务器启动时自动执行的, 所以Redis并没有专门用于载入RDB文件的命令. 只要Redis服务器在启动时检测到RDB文件存在. 它就会自动载入RDB文件. 另外值得一提的是, 因为AOF文件的更新频率通常比RDB文件的更新频率高, 所以: 如果服务器开启AOF持久化功能, 那么服务器会优先使用AOF文件来还原数据库状态. 只有在AOF持久化功能处于关闭状态时, 服务器才会使用RDB文件来还原数据库状态. 在BGSAVE命令执行期间, 客户端发送的BGSAVE命令会被服务器拒绝, 因为同时执行两个BGSAVE命令也会产生竞争条件. 最后BGREWRITEAOF和BGSAVE两个命令不能同时执行: 如果BGSAVE命令正在执行, 客户端发送的BGREWRITEAOF命令会被延迟到BGSAVE命令执行完毕之后执行. 如果BGREWRITEAOF正在执行, 那么客户端发送的BGSAVE命令会被服务器拒绝. save 900 1save 300 10save 60 10000 那么只要满足以下三个条件中的任意一个, BGSAVE命令就会被执行: 服务器在900秒之内, 对数据库进行了至少1次修改 服务器在300秒之内, 对数据库进行了至少10次修改 服务器在60秒之内, 对数据进行了至少10000次修改. 设置保存条件12345678910111213141516struct redisServer &#123; //记录了保存条件的数组 struct saveparam *saveparams; // 修改计数器 long long dirty; // 上一次执行保存的时间 time_t lastsave;&#125;struct saveparam &#123; // 秒数 time_t seconds; //修改数 int changes;&#125; 比如上面的save选项设置: 按照配置顺序以数组形式保存. 分别saveparam[0],saveparam[1],saveparam[2] dirty计数器和lastsave属性*dirty计数器记录距离上一次成功执行save命令或者bgsave命令之后, 服务器对数据库状态进行了多少修改,*lastsave属性是一个unix时间戳. 记录了服务器上一次成功执行save命令或者bgsave命令的时间. 检车保存条件是否满足Redis的服务器周期性操作函数serverCron默认每个100毫秒就会执行一次, 该函数用于对正在运行的服务器进行维护, 它的其中一项工作就是检查svae选项所有设置的保存的条件是否已经满足, 如果满足的话, 就执行bgsave命令. AOF持久化的实现AOF持久化的实现可以分为命令追加, 文件写入, 文件同步三个步骤 命令追加当AOF持久化功能处于打开状态时, 服务器在执行完一个写命令之后, 会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾: 1234struct redisServer &#123; //AOF缓冲区 sds aof_buf;&#125; AOF文件的写入和同步Redis的服务器机进程就是一个事件循环, 这个循环中的文件事件负责接收客户端的命令请求, 以及向客户端发送命令回复, 而时间事件则负责执行serverCron函数这样需要定时运行函数. 因为服务器在处理文件事件时可能会执行写命令, 使得一些内容被追加到aof_buf缓冲区里面. 所以在服务器每次结束一个事件循环之前, 它都会调用flushAppendOnyFile函数, 考考是否需要将aof_buf缓冲区中的内容写入和保存到AOF文件里面. 这个函数的行为由服务器配置的appendfsync选项的值来决定. always 将aof_buf缓冲区中的所有内容写入, 并同步到AOF文件 最安全的 everysec 将aof_buf缓冲区的所有内容写入到aof文件. 如果上次同步AOF文件的时间距离现在超过一秒钟. 那么再次对AOF文件进行同步. 并且这个同步操作是由一个线程专门负责执行的.(默认值)足够快, 就算出现故障宕机, 也只会丢失1s的数据 no 将aof_buf缓冲区中的所有内容写入到AOF文件, 但并不对AOF文件进行同步. 何时同步由操作系统来决定.会丢失上次同步到现在的数据. 为了提高文件的写入效率, 现代操作系统中, 当用户调用write函数, 将一些数据写入到文件的时候, 其实是将写入的数据暂存在一个内存缓冲区中, 只有缓冲区空间被填满. 或者超过了指定的时限之后. 才真正将缓冲区中的数据写入磁盘. 如果期间计算器宕机. 那么缓冲区的数据就会丢失. 因此系统提供了fsync和fdatasync两个同步函数, 他们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面.从而来保证写入数据的安全性. AOF文件的载入与数据还原 创建一个不带网络连接的伪客户端 和真实客户端执行命令的效果是一样的 从AOF文件中分析并度去除一条写命令. 使用伪客户端执行被读出的写命令. 一直执行step2和step3, 知道aof文件的所有命令被处理完毕. AOF文件重写aof持久化通过保存被执行的写命令来记录数据库状态. 随着时间的流逝, aof文件中的内容会越来越多, 文件的体积也会越来越大. 如果aof文件体积太大, 也会影响Redis服务器性能. 并且使用aof文件进行数据还原所需的时间也会越来越长. 对于实际应用来说, 写命令的执行次数和频率要很高, 会出现很多冗余命令.比如先添加后删除然后有添加等场景. 为了解决AOF文件体积膨胀的问题. 提供了重写功能, 通过这个功能可以创建一个新AOF文件替换旧的AOF文件. 他们的数据库状态是一样的, 但是新的AOF文件并不会包含任何浪费空间的冗余命令. 使用过bgrewriteaof命令实现的. AOF后台重写BGREWRITRAOF命令是使用子进程完成AOF重写. 但是在重写期间, 客户端的写命令会放到AOF缓冲区和AOF重写缓冲区. 也就是说, 在子进程执行AOF重写期间, 服务器进程需要执行三个工作: 执行客户端发来的写命令 将执行后的写命令追加到AOF缓冲区 将执行后的写命令追加到AOF重写缓冲区. 当子进程完成AOF重写工作之后,会向父进程发送一个信号. 父进程接到该信号后, 会调用信号处理函数. 将AOF重写缓冲区中的所有内容写入新AOF文件中,这是新AOF文件所保存的数据库状态和服务器当前的数据库状态一致, 对新AOF文件进行改名. 原子的覆盖现有的AOF文件, 完成新旧两个AOF文件的替换. 这个信号处理函数执行时会对服务器造成阻塞.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>分布式缓存</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统理论]]></title>
    <url>%2F2019%2F05%2F09%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[分布式系统概念 进程和线程. 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动.进程是系统进行资源分配和调度的一个独立单位. 线程是进程的实体, 是CPU调度和分派的基本单位, 它是比进程更小的能独立运行的基本单位. 并发. 当多个线程在操作时. 如果系统一个CPU. 则它根本不可能真正同时执行一个以上的线程. 它只是把CPU运行时间划分成若干个时间段. 在将时间段分配给各个线程执行. 在一个时间段的线程代码运行时. 其他线程处于挂起状态. 这种方式我们称之为并发(concurrent). 锁, 锁作用于保护临界区的一种机制. 减少或规避锁争用的几种策略: 分拆锁分离锁避免共享变量缓存使用并发容器如Amino使用Immutable数据和ThreadLocal中的数据 并行. 当系统有一个以上CPU时. 则线程的操作有可能非并发. 当一个cpu执行一个线程. 另一个CPU可以执行另一个线程. 两个线程互不抢占CPU资源. 可以同时进行, 这种方式我们称之为并行(Parallel) 集群. 一组相互独立. 通过高速互联计算机, 它们构成了一个组. 并以单一系统的模式加以管理. 分布式系统可以表达为很多机器组成的集群. 靠彼此之间的网络通信. 担当的角色可能不同. 共同完成同一件事情的系统. 节点: 按照协议完成计算工作的一个逻辑实体. 可能是执行某些工作的进程或机器网络: 系统的数据传输通道. 用来彼此通信. 通信是具有方向性的.存储: 持久化数据的数据库或者文件存储.根据典型集群体系. 集群中涉及的关键技术可以归属四个层次:网络层. 网络互连结构 通信协议 信号技术节点机及操作系统层: 高性能客户机 分层 基于微内核的操作系统集群系统管理层: 资源管理 资源调度 负载均衡 并行IPO 安全应用层 并行程序开发环境 串行应用 并行应用 重发和幂等性 当网络发送异常情况是, 迟迟收不到ack. 我们一般会选择超时重发.或者别的重发方案. 但这是接收端就可能出现重复请求的情况. 所以我们要考虑幂等设计.所谓幂等就是调用1层和调用N次要返回一样的结果 分布式系统理论CAP理论提出了一致性, 可用性, 分区容忍行的取舍问题; Paxos Raft 2PC 3PC分别给出了一致性的解决方法; Lease机制主要针对网络阻塞或瞬断的情况下. 出现双主情况的解法; Quorum NWR,和MVCC主要解决分布式存储系统领域的一致性问题; Gossip是中去中心话, 容错而又最终一致性的算法; CAP理论 C 一致性被称为原子对象. 任何读写都应该看起来是原子的. 或串行的. 写后面的读一定能读到前面写的内容. 所有的读写请求都好像被全局排序(在分布式系统中的所有备份. 在同一时刻是否有同样的值.等于所有节点访问同一份最新的数据备份) A 可用性 对任何非失败节点都应该在有限时间内给出请求的回应.(在集群一部分节点故障后. 集群整体是否还能响应客户端的读写请求. 对数据更新具备高可用性) 运行节点之间丢失任意多的消息. 当发生网络分区时. 节点之间的消息可能会完全丢失.(以实际效果而言, 分区相当于对通信的时限要求, 当系统不能在一定时限内达成数据一致性. 即意味着发生了分区. 必须就当前操作在C和A直接做出抉择) CA without p如果不要求P(不允许分区), 则C和A是可以保证的. 很多CA系统是运行分区后各子系统依然保持CA. 典型放弃分区容忍性的例子有关系型数据库. LDAP等 CP without A如果不要求A. 相当于每个请求都需要Server之间强一致. 而P会导致同步时间无限延长. 如此CP也是可以保证的. 很多传统的数据库分布式事务都属于这种模式. 分布式锁也属于这种情况. AP without C要高可用并允许分区, 则需要放弃一致性, 一旦发生分区. 节点之间可能失去联系. 为了高可用 每个节点自能用本地数据提供服务. 而这样导致全局数据的不一致. 现在众多Nosql都属于此类. CAP理论澄清 三选二是伪命题不是为了P分区容忍性, 要在CA之间选择一个. 分区很少出现. CAP大多时候允许完美的C和A, 但当分区存在或可感知其影响的情况下. 就要预备一种策略去探知分区并显式处理其影响. 这种策略应分为三个步骤: 探知分区发生, 进入显式的分区模式以限制某些操作. 启动恢复过程以恢复数据一致性并补偿分区期间发生的错误. 一致性的作用范围其实反映了这样一种观念, 即在一定的边界内状态是一致的, 但超出了边界就无从谈起. 比如在一个主分区内可以保证完备的一致性和可用性.而在分区外服务是不可用的. Paxos算法和原子多播系统一般符合这样的场景. 想google的一般做法是将主分区归属在单个数据中心里面. 然后交给Paxos算法去解决跨区域的问题. 一方面保证全局协商一致.如Chubby, 一方面实现高可用的持久性存储. ACID BASE CAPBASE(基本可用, 软状态, 最终一致性). 其中软状态和最终一致性这两种技巧擅于对付存在分区的场合.并因此提高了可用性. 最终一致性是令人难理解的一个概念. 最终具体是什么时间范围才算. 相对认同的解释: 1.给定足够长的一定时间, 不在发送更新. 则认为所有更新会最终传播到整个系统.且所有副本都会达成一致2.当存在持续更新时. 一个被接受的更新那么要达副本, 要么在到达副本的路上. 比如网络闪断. 有重试机制; 为避免持续压力. 可加大重试时间; 超过重试次数. 则引入手工决策或者第二套方案处理. PaxosPaxos协议是一个解决分布式系统中, 多个节点之间就某个值(提案)达成一致(决议)的通信协议. 它能够处理在少数节点离线的情况下, 剩余的多数节点仍然能都达成一致. 介绍Paxos协议是一个两阶段协议. 分为prepare阶段和accept阶段. 涉及两个角色 proposer(提案者)和acceptor(批准提案). prepare阶段 proposer发送prepare. proposer生成全局唯一且递增的提案ID, 向Poxos集群的所在机器发送请求. 这里无需携带提案内容. 只携带提案ID即可(提案ID叫做pn). acceptor应答prepare. acceptor收到提案请求后, 做出如下约定: 1) 不应答&lt;=pn的prepare请求. 2)对于 &lt; pn的accept请求亦不处理. acceptor做出的处理包括: 1) 应答前要在本地持久化当前提案ID 2)如果现在请求的提案ID–pn大于此前存放的proposalID, 则做如下处理 1if(pn&gt;proposalId) &#123; proposalId = pn&#125; 如果该acceptor accept过的提案. 则返回提案中proposalId最大的那个提案的内容. 否则是空值. accept阶段 proposer收集到多数派应答(就是超过n/2+1, n是机器数量). prepare阶段的返回值后. 从中选择proposalID最大的提案内容, 作为要发起accept的提案. 如果这个提案为空值. 则可以自己随意决定提案内容. 然后携带上当前proposalId, 向Paxos集群的所有机器发送accept请求. acceptor收到accpet请求后. 检查不违背自己之前做出约定的内容下. 持久化当前proposalId和提案内容. 最后proposer收集多数派应答的accept回复后. 形成决议. 2PC在事务处理, 关系型数据库及计算机网络中, 2阶段提交协议是一种典型的原子提交协议. 它是由协调器来处理分布式原子参与者是提交或者回滚事务的分布式算法. 协议包含两个阶段: 提交请求阶段或者投票阶段 该阶段的任务是确定相关参与者对于事务处理是否准备就绪. YES代表可以commit. No则反之. 提交阶段. 基于投票结果, 由协商器决定提交事务抑或是退出事务处理. 各事务参与者遵循指示, 对本地事务资源做需要的动作 2PC最大的不足是提交协议是阻塞性的. 如果事务协调器宕机. 某些参与者将无法解决他们的事务: 一个参与者发送确认消息给协调器. 因为协调器无法工作而导致事务未处理完而处于悬挂状态. 因此在高并发网站中使用分布式事务的2PC协议要把握如下原则: 1) 能不用2PC 就尽量不要用 负责度高, 性能挑战也高2) 要获得事务强一致性, 也要在性能和一致性上做折中. 比如加上超时机制. 阶段性补偿机制. 3PC分为3次交互. 第一阶段 投票, 事务协调器问参与者是否能提交, 都得到肯定回答后. 进入第二阶段 第二阶段 预提交 都确认提交成功后 进入3阶段 第三阶段 真是提交. 成功则完成事务. 失败了则继续重试 Raft提供了和Paxos算法相同的功能和性能, 但是它的算法结构和Paxos不同. Raft算法更加容易理解并且更容易构建实际的系统. 为了提升理解性 Raft将一致性算法分解成几个关键模块. 例如领导人选举 日志复制 安全性. 同时它通过实施一个更强的一致性来减少需要考虑的状态的数量. 在Raft中, 任何时候一个服务器可以扮演下面角色之一: 领导者 处理所有客户端交互 日志复制等动作. 一般一次只有一个领导者 选民 类似选民 完全被动的角色. 这样的服务器等待被通知投票 候选人 候选人就是在选举过程中提名自己的实体, 一旦选举成功, 则成为领导者. 算法分为两个阶段. 首先是选举过程. 它向其他服务器发出要求选举自己的请求, 比如日志复制. 1) 任何一个服务器都可以成为一个候选者, 它向其他服务器(选民)发出要求选举自己的请求,2) 其他服务器同意了 回复ok指令 此时如果有一个follower服务器宕机, 没有收到请求选举的请求. 则只要达到半数以上的票数, 候选人还是可以成为领导者3) 这个候选者成为了领导者. 它可以向选民们发出要执行具体操作动作的指令. 比如进行日志复制.4) 一旦这个leader宕机崩溃了. 那么follower中会有一个成为候选者, 发出邀请选举, 相当于执行1)~2)的步骤. Lease机制Lease是由授权者授予分布式环境一段时间内的承诺.例如 缓存服务器把数据分发给对应节点A B C,其中节点A B得到数据v01, 有效期为12:00:00,而节点C收到数据v02, 有效期为12:15:00, 节点A可以把v01数据缓存到本地. 在Lease时间范围内方向使用 而Server也遵守承诺, 在Lease过期时间内不修改数据.当时间到12:00:01时. 此时v01数据过期, 则AB会删除本地数据. 而此时Server会阻塞一直到已发布的所有Lease都已经过期, 在更新数据并发出新的Lease. 脑裂问题主备是实现高可用的有效方式. 但是存在脑裂问题. 是指一个高可用HA系统中. 当联系着的两个节点断开联时, 本来为一个整体的系统. 分裂为两个独立节点, 这时两个节点开始争抢共享资源. 结果会导致系统混乱 数据损坏. 解决脑裂的问题, 有一种做法是加入仲裁机制. 例如加入第三方检测服务器monitor. Quorum NWRNWR是一种在分布式存储系统中用于控制一致性级别的一种策略. N 同一份数据的拷贝数 W 是更新一个数据对象的时候需要确保成功更新的份数. R读取一个数据需要读取的拷贝的份数. W&gt;N/2 W+R&gt;N 公式表明写操作要确保成功的份数应该高于数据拷贝总份数的一半. 写操作加上读操作的总份数也要高于同一份数据拷贝总份数. Taobao File System 是淘宝针对海量非结构化数据存储设计的分布式系统. 构筑在普通的Linux及其集群上. TFS采用了N=3 W=3的策略. MVCC多版本并发控制. 一般把基于锁的并发控制成为悲观机制. 而把MVCC机制成为乐观机制. 由于MVCC是一种宽松的设计. 读写相互不阻塞. 可以获得较好的并发性能. Mysql的innDB是这样做的. 引擎给每张表都增加两个字段, 分别为create version 和delete version. 插入操作时, 记录的创建版本号就是事务版本号. 修改操作时, 采用的是先标记旧的那行记录为已删除, 并且删除版本号是事务版本号, 然后在出入一行新记录的方式. 删除操作时, 就把事务版本号作为删除版本号. 那么当我们做查询的时候, 当delete version &gt; 当前版本号, 说明删除操作是在当前事务启动之后做的. create version &lt;= 当前版本号 满足这两个条件. 数据就可以查出来的. Gossip对分布式系统而言, 由于状态分散在集群中的各个节点上. 集群的状态同步面临着集中式系统所不具备的问题. 分布式系统设计策略设计策略: 如何检测你还活着? 如何保障高可用 容错处理 重试机制 负载均衡 心跳检测(类似于TCP设置RTO的机制)server端每隔t秒向Node集群发起心跳请求. 设定超时时间. 如果超过超时时间. 则判定死亡. 这里超时时间设置带有随机性. 容易误判. 可以统计实际检测node的返回时间(这里和RTT差不多啊), 包括得到一定周期内的最长时间, 那么可以根据现有没有正确返回的时间在历史统计的分布中计算得到死亡概率. 同时对于宣告濒临死亡的节点可以发起有限次数的重试, 以进一步判定 心跳检测本身也是有效资源利用和成本之间的一种权衡.如果迟迟不能判断节点是否”死亡”, 会影响业务逻辑的处理. 高可用设计 主备模式(Master-Slave) 存在数据延迟风险. 特别是跨域问题. 互备模式(Multi-Master) 两台主机同事运行各自的服务工作且相互监测情况. 集群模式 多个节点在运行. 同时可以通过主控节点分担服务请求. 容错性容错的处理是保障分布式环境下响应系统的高可用或者健壮性, 一个典型的案例就是对于缓存失效的雪崩问题的解决方案. 假设有一个业务, 用户查询不到数据, 可能是数据库没有. 也可能是未知异常. 用户间隔一定时间后重试. 项目中通常都是先检查缓存中是否存在, 如果存在直接返回, 不存在就直接查询数据库然后在缓存查询结果返回. 如果我们查询的某一个数据在缓存中一直不存在. 就会造成每一次请求都查询DB, 这样缓存就时区意义了, 子流量大时. DB可能挂了. 要是有人利用不存在的key频繁攻击我们的应用. 这就是漏洞. 一个比较巧妙的方法就是. 可以将这个不存在的key预设一个值. 比如key=”&amp;&amp;”. 在返回这个值的时候. 我们的应用认为这是一个不存在的key. 那我们的应用就可以决定是否继续等待继续访问. 还是放弃掉这次请求操作. 这样就将大量类似的请求挡在了缓存之中. 负载均衡负载均衡集群: 其关键在于使用多台集群服务器共同分担计算任务. 把网络请求及计算分配到集群可用服务上. 从而达到可用性及较好的用户提交. 以Nginx为例. 负载均衡有以下几种策略: 轮询 按照配置文件中的顺序. 依次把客户端的web请求分发到不同的后端服务器. 最少连接. 当谁连接最少, 分发给谁 IP地址哈希. 确定相同的IP请求可以转发给同一个后端节点处理. 以方便session保持. 基于权重的负载均衡. 配Nginx把请求更多地分发到高配置服务器上. 把相对较少的请求分发到低配置服务器上. 实践全局ID生成 UUID API简单易用, 占用空间大. 字符串本身无法加工. 可读性不强. ID生成表模式 采用Mysql的自增长ID机制. 12345678CREATE TABLE Tickets64 ( id bigint(20) unsigned not null auto_increment, stub char(1) not null default '', unique key stub(stub)) engine=MyISAMreplace into Tickets64(stub) values("a");select LAST_INSERT_ID(); 这样就能拿到不断增长的且不重复的ID了. 从高可用角度考虑. 可以启用两台数据库服务器来生成ID, 通过区分auto_increment的起始值和步长生成奇偶数的ID. Snowflake Twitter开源的服务. 41位的时间序列(精确毫秒, 41位的长度可以使用69年), 10位的机器标识码(10位长度最多支持部署1024个节点), 12位的计数顺序号(12位的计数顺序号支持每个节点没毫秒产生4096个ID序号). 高性能 低延迟 独立应用 按时间有序. 结合缓存去做. 可以采用ID生成表模式成批量获取ID比如1000个放到本地缓存, 这样client使用的时候可以进一步提升性能. 哈希取模哈希方式是常见的数据分布方式, 实现方式是通过描述记录的业务的ID或者KEY, 通过HASH函数的计算求余数. 余数作为处理数据的服务器索引编号处理. 缺点: 服务器数量变化时 数据迁移是麻烦事. 一致性哈希一致性哈希 路由表一般用需要全局计算的节点, 比如用户抽奖. 抽奖是有预算的.由于高并发的情况下比较单行记录热点. 则对预算进行拆分. 并且拆分到不同逻辑数据库中. 数据拆分通过路由函数, 将数据拆分到不同的逻辑库中去. 缓存使用模式 Cache-Aside 读: 从缓存中获取数据, 如果没命中. 则回源到存储系统并将源数据放入缓存供下次使用. 写场景: 先将数据写入到存储系统. 写入成功后同步将数据写入缓存. 或者写入成功后将缓存数据过期, 下次读取时加载缓存. 此模式的优势在于利用数据库比较成熟的高可用机制. 数据库写成功. 则进行缓存数据更新; 如果缓存数据写失败. 可以发起重试 Cache-AS-SoR 业务代码指对Cache操作. Read-Through 业务代码获取数据时, 如果有返回. 则先访问缓存; 如果没有, 则从数据库加载. 然后放入缓存. Refresh-Ahead 业务代码访问数据时, 仅调用cache的get操作. 通过设定数据的过期时间咋数据过期时, 自动从数据库重新加载数据的模式. 此模式相较于Read-Through模式的好处是性能高, 坏处是可能获取到非数据库的最新数据. 对数据精准度有的一定容忍的场景适合使用. write-Through 穿透写模式. 业务代码首先调用Cache写, 实际由Chche更新缓存数据和存储数据. write-Behind 业务代码只更新缓存, 什么时候更新到数据库. 由缓存到数据库的同步策略决定.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>分布式缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性哈希]]></title>
    <url>%2F2019%2F05%2F08%2F%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%2F</url>
    <content type="text"><![CDATA[Redis集群的使用在使用Redis的时候, 为了保证Redis的高可用. 提高读写能力. 最简单的方式会做主从负责. 组成Master-Master或者Master-Slave的形式. 或者搭建Redis集群, 进行数据的读写分离. 类似于数据库的主从辅助和读写分离. 同样类似于数据库, 当单表数据大于一定量的时候需要对其进行分库分表, 当数据量很大的时候, Redis同样需要进行分库分表. 假设一个应用. 需要使用Redis存储图片, 存储的格式是键值对, Key值为图片名称. value为该图片所在文件服务器的路径. 我们根据文件名称查找该文件所在文件服务器上路径, 数据量大概2000w左右. 按照约定要进行分库. 规则是均匀分配. 部署8台缓存服务器. 每台服务器大约500w数据. 并且进行主从复制: 由于要求均匀分布: 一条数据可能存储在任何一组Redis中, 为了找到一张图片. 需要进行轮询1,2,3,4 直到找到. 这显然不是我们想要的结果. 采用数据库分表规则, 按照Hash值, 取模, 按照类别, 按照某一个字段值等等常见规则. 为Redis集群使用hash采用hash方式, 每一张图片在进行分库的时候都可以定位到特定的服务器假设我们查找的是”a.png”，由于有4台服务器（排除从库），因此公式为hash(a.png) % 4 = 2 ，可知定位到了第2号服务器，这样的话就不会遍历所有的服务器，大大提升了性能！ 使用Hash带来的问题使用hash后, 不需要轮询的方式查找了. 单也会出现缺陷. 主要体现在服务器数量变动的时候, 所有缓存的位置都要发生改变. 例如4台服务器已经不能满足我们的需求. 将缓存服务器添加到5台, 那么原本hash(a.png) % 4 = 2 的公式就变成了hash(a.png) % 5 = ？, 结果肯定不是2了. 这种情况带来的结果就是当服务器数量变动时, 所有缓存的位置都要发生变化. 换句话说, 当服务器数量发生变化时. 很多缓存是无法命中的. 会导致查询穿透到数据库. 导致缓存雪崩. 同样的, 假设4台缓存中突然有一台缓存服务器出现了故障. 无法进行缓存, 那么我们则需要将故障及其移除. 机器数量从4台变为3台, 也会出现上述情况. 一致性哈希一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希空间环如下：整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。 下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用ip地址哈希后在环空间的位置如下：接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。 例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 拓展性现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 Hash环的数据倾斜问题一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下：此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。 例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>分布式缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载系统]]></title>
    <url>%2F2019%2F05%2F05%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[类加载器作用是将class文件加载到JVM中.存放在元数据区. bootstrap classloader jvm自己实现的. 加载$JAVA_HOME/jre/lib extClassloader 也是jvm的一部分. 加载$JAVA_HOME/jre/lib/ext包 appClassloader 加载classpath路径的类 Class装载系统步骤 加载 连接 验证 准备 解析 初始化 条件Class只有在必须要使用的时候才会被装载. JVM不会无条件地装载Class类型. 一个类或接口在初次使用前. 必须要进行初始化. 使用是指主动使用. 情况分几种: 当创建一个类的实例时. 比如使用new关键字. 或者通过反射. 克隆. 反序列化. 当调用类的静态方法时. 当使用类或者接口的经典字段时(final常量除外). 当使用java.lang.reflect包中的方法反射类的方法时. 当初始化子类时. 要求先初始化父类 作为启动JVM, 含有main()方法的那个类. 加载类 加载类处于类装载的第一个阶段. 这个阶段.JVM需要完成 获取类的二进制数据流. 解析类的二进制数据流为方法区内的数据结构. 创建java.lang.Class类的实例. 获取类的二进制数据流. JVM可以通过多种途径产生或获得.可以通过文件系统读入一个class后缀的文件. 也可能读入JAR.ZIP等归档数据包,提取类文件.也可以将类的二进制数据存放在数据库中. 或者通过类似于HTTP之类的协议通过网络进行加载. 甚至是在运行时生成一段Class的二进制信息. 验证类当类加载到系统后. 就开始连接操作. 验证是连接操作的第一步. 目的是保证加载的字节码合法.合理并符合规范. 格式检查: 必须判断类的二进制数据是否符合格式要求和规范的. 比如. 是否以魔数0xCAFEBABE开头. 主版本和小版本号是否在当前Java虚拟机的支持范围内. 语义检查: JVM会进行字节码的语义检查. 比如是否所有的类都有父类存在. 是否一些被定义为final的方法或者类被重载或者继承了.非抽象类是否实现了所有抽象方法或者接口方法.是否存在不兼容的方法. 但凡在语义上不符合规范的. JVM也不会给与验证通过. 字节码验证: JVM还会进行字节码验证. 这个过程最为复杂.试图通过对字节流的分析.判断字节码是否可以被正确地执行. 比如. 在字节码的执行过程中. 是否会跳转到一条不存在的指令. 函数调用是否传递了正确类型的参数. 变量的赋值是不是给了正确的数据类型等. 符号引用验证: Class文件在常量池会通过字符串记录自己将要使用的其他类或者方法. 在验证阶段. JVM会检查这些类或者方法确实是存在的. 并且当前类有权限访问这些数据. 准备阶段当类验证通过后. JVM会进入准备阶段. 在这个阶段JVM会为这个类分配响应的内存空间. 并设置初始值. 如果类存在(final)常量字段. 那么常量字段会在准备阶段被附上正确的值. 这个赋值属于Java虚拟机的行为. 属于变量初始化.普通的静态变量初始化默认值. 解析类在准备阶段完成后. 解析阶段的工作就是将类.接口,字段和方法的符号引用转为直接引用. 符号引用就是一些字面量的引用. 和JVM的内部数据结构和内存布局无关. 比较容易理解的就是在Class类文件中. 通过常量池进行了大量的符号引用. 所谓解析就是将符号引用转为直接引用. 也就是得到类或者字段.方法在内存中的指针或者偏移量. 由于字符串在程序开发中有着重要的作用. 当在java代码中直接使用字符常量时.就会在类中出现CONSTANT_String. 它表示字符串常量. 并且会引用一个CONSTANT_UTF8的常量项. 在JVM内部运行时的常量池中. 会维护一张字符串拘留表, 它会保存所有出现过的字符串常量, 并且没有重复项. 因为该表中没有重复项, 所以任何字面相同的字符串的String.intern()方法返回总是相等的. 初始化类的初始化是类装载的最后一个阶段. 如果前面的步骤都没有问题. 表示类可以顺利装载到系统中. 此时. 类才会开始执行Java字节码. 初始化阶段的重要工作是执行类的初始化方法&lt;clinit&gt;, 方法&lt;clinit&gt;是编译器自动生成的. 它是由类静态成员的赋值语句以及static语句块合并产生的. 对于&lt;clinit&gt;函数调用. 也就是类的初始化. JVM会内部确保其多线程环境的安全性. 当多个线程试图初始化同一个类时. 只有一个线程可以进入&lt;clinit&gt;函数. 其他线程必须等待. 如果之前的线程成功加载了类. 则等待队列中的线程就没有机会在执行&lt;clinit&gt;函数了. 当需要使用这个类时. 虚拟机会直接返回给它已经准备好的信息. ClassLoaderClass的装载大体上可以分为加载类, 连接类, 初始化3个阶段. ClassLoader在Java中作用很重要. 工作在Class装载的加载阶段. 其主要作用是从系统外部获得Class二进制数据流. 认识ClassLoader它是Java的核心组件. 所有的Class都是由ClassLoader进行加载的. 负责通过各种方式将Class信息的二进制数据流读入系统. 然后交给JVM进行连接, 初始化等操作. 因此在整个装载阶段, 只能影响到类的加载. 而无法通过ClassLoader去改变类的链接和初始化行为. ClassLoader是抽象类. 它提供了一些重要的接口. 用于自定义Class的加载流程和加载方式. 主要方法如下: public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException; 给定一个类名. 加载一个类. 返回代表这个类的Class实例. 过个找不到类, 抛出异常. protected final Class&lt;?&gt; defineClass(byte[] b, int off, int len); 根据给定的字节码流b定义一个类, off和len参数表示实际Class信息在byte数组中的位置和长度. 其中byte数组b是ClassLoader从外部获取的. 这是受保护的方法. 只有在自定义ClassLoader子类可以使用. protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException; 查找类. 这是受保护的方法. 也是重载ClassLoader时. 重要的系统拓展点, 会在loadClass()时被调用. 用于自定义查找类的逻辑. protected final Class&lt;?&gt; findLoadedClass(String name); 查找已经加载的类. 是final方法. 无法被修改 在结构中, 还有一个重要的字段parent. 也是一个ClassLoader的实例. 这个字段所表示的ClassLoader也称为这个ClassLoader的双亲. 分类在标准的Java程序中. JVM会创建3类ClassLoader为整个应用服务. 分别是: BootStrap ClassLoader(启动类加载器), Extension ClassLoader(拓展类加载器), APPClassLoader(应用类加载器), 每一个应用程序还可以拥有自定义的ClassLoader, 拓展JVM获取Class数据的能力. 当系统需要使用一个类时, 在判断类是否已经被加载时, 会先从当前底层类加载器进行判断, 当系统需要加载一个类时. 会从顶层类开始加载. 依次向下尝试. 直到成功. 双亲委托模式ClassLoader在协同工作是. 默认会使用双亲委托模式. 即在类加载的时候. 系统会判断当前类是否已经被加载. 如果已经被加载. 就会直接返回可用的类, 否则就会尝试加载. 在尝试加载时. 会先请求双亲处理. 如果双亲处理失败. 则会自己加载. 弊端 检查类是否已经加载的委托过程是单项的. 这种方式虽然说从结构上说比较清晰. w. 但是同时会带来一个问题. 顶层的ClassLoader无法访问底层的ClassLoader所加载的类. 通常情况下, 启动类加载器中的类为系统核心类, 包含已给重要的系统接口, 而在应用类加载器中, 为应用类. 按照这种模式. 应用类访问系统类自然没有问题. 但是系统类访问应用类就会出现问题. 比如.在系统类中. 提供一个接口, 该接口需要在应用中得以实现. 改接口绑定工程方法. 用于创建改接口实例, 而接口和工厂方法都在启动类加载器中. 这时,就会出现该工厂方法无法创建由应用类加载器加载的应用实例的问题, 拥有这种问题的组件很多, 比如JDBC, XMLParser. 突破双亲委托线程上下文类加载器（Thread Context ClassLoader）。这个类加载器可以通过java.lang.Thread类的setContextClassLoader方法进行设置。如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过多的话，那这个类加载器默认即使应用程序类加载器。 tomcat类加载机制前面3个类加载和默认的一致，CommonClassLoader、CatalinaClassLoader、SharedClassLoader和WebappClassLoader则是Tomcat自己定义的类加载器，它们分别加载/common/、/server/、/shared/（在tomcat 6之后已经合并到根目录下的lib目录下）和/WebApp/WEB-INF/中的Java类库。其中WebApp类加载器和Jsp类加载器通常会存在多个实例，每一个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个Jsp类加载器。 commonLoader：Tomcat最基本的类加载器，加载路径中的class可以被Tomcat容器本身以及各个Webapp访问； catalinaLoader：Tomcat容器私有的类加载器，加载路径中的class对于Webapp不可见； sharedLoader：各个Webapp共享的类加载器，加载路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见； WebappClassLoader：各个Webapp私有的类加载器，加载路径中的class只对当前Webapp可见； 从图中的委派关系中可以看出： CommonClassLoader能加载的类都可以被Catalina ClassLoader和SharedClassLoader使用，从而实现了公有类库的共用，而CatalinaClassLoader和Shared ClassLoader自己能加载的类则与对方相互隔离。WebAppClassLoader可以使用SharedClassLoader加载到的类，但各个WebAppClassLoader实例之间相互隔离。而JasperLoader的加载范围仅仅是这个JSP文件所编译出来的那一个.Class文件，它出现的目的就是为了被丢弃：当Web容器检测到JSP文件被修改时，会替换掉目前的JasperLoader的实例，并通过再建立一个新的Jsp类加载器来实现JSP文件的HotSwap功能。 好了，至此，我们已经知道了tomcat为什么要这么设计，以及是如何设计的，那么，tomcat 违背了java 推荐的双亲委派模型了吗？答案是：违背了。 我们前面说过： 双亲委派模型要求除了顶层的启动类加载器之外，其余的类加载器都应当由自己的父类加载器加载。 很显然，tomcat 不是这样实现，tomcat 为了实现隔离性，没有遵守这个约定，每个webappClassLoader加载自己的目录下的class文件，不会传递给父类加载器。 我们扩展出一个问题：如果tomcat 的 Common ClassLoader 想加载 WebApp ClassLoader 中的类，该怎么办？ 我们可以使用线程上下文类加载器实现，使用线程上下文加载器，可以让父类加载器请求子类加载器去完成类加载的动作。]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集器]]></title>
    <url>%2F2019%2F04%2F19%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[运行时数据区域程序计数器线程私有 当前线程执行的字节码的行号指示器. 字节码解释器工作时就是通过改变这个计数器的值来选择下一条需要执行的字节码指令, 分支. 循环, 跳转, 异常处理. 线程恢复等 为了能够在CPU时间片轮转切换上下文之后顺利回到正确的执行位置. 每条线程都需要具有一个独立的程序计算器. 各个线程之间互不影响. Java虚拟机栈(-xss)线程私有 它的生命周期和线程相同. 虚拟机栈描述的是Java方法执行的内存模型: 每个方法在执行的同时都会创建一个栈帧用于存储局部变量表, 操作数栈. 动态链接. 方法出口等信息. 每个一个方法从调用直至执行完成的过程. 就对应着一个栈帧在虚拟机栈中入栈到出栈的过程. 经常提到的栈内存(Stack) 指的就是虚拟机栈. 或者是是虚拟机栈中局部变量表部分: 局部变量表存放了编译期可知的各种基本类型(boolean, byte, char, short, int, float, long, double), 对象引用(Reference类型, 它不等同于对象本身. 可能是一个执行对象原始地址的引用指针. 也可能是执行一个代表对象的句柄或者其他与此对象相关的位置) 和returnAddress类型(指向了一条字节码指令的地址) 手动狗头 粗略的认为一个Java进程的内存大小: 堆内存 + 线程数量 * 栈内存线程数量 = (最大地址空间 - jvm堆内存 - ReservedOsMemory系统保留内存)/ThreadStackSize(XSS) 栈上分配 如果一个对象的作用域只存在方法内. 那么就直接栈上分配. 好处是函数调用结束后自行摧毁. 而不需要垃圾回收期介入. 栈上分配的技术基础就是逃逸分析. 目的就是判断对象的作用域是否有可能逃逸出函数体. 本地方法栈线程私有的 为虚拟机使用到的Native方法服务. 也就是c/c++程序. 经常会碰到调用JNI方法的情况, 比如网络通信. 文件的底层操作. 甚至是String的intern等都是JNI方法. Java堆是虚拟机所管理的内存中最大的一块. 线程共享的内存区域. 此区域的唯一目的就是存放对象实例. 是垃圾回收器重点照顾区域. 基本可以划分为新生代和老年代. 新生代又分为e,s0.s1区域. s0和s1总有一个是空闲的. 这和新生代采用的回收算法有关系. 复制算法是找出存放的放入s0 方法区线程共享的内存区域. 存储已被虚拟机加载的类信息, 常量, 静态变量, 即时编译器编译后的代码等数据. 运行时常量池这是方法区的一部分. class文件中除了有类的版本. 字段. 方法. 接口等描述信息外. 还有一项信息是常量池. 用于存放编译期生成的各种字面量和符号引用. 这部分内容将在类加载后进入方法区的运行时常量池中存放. 直接内存对象已死了吗在堆里面存放着Java世界中几乎所有的对象实例. 垃圾收集器在对堆进行回收前, 第一件事就是要确定这些对象中那些还存活,哪些死去 引用计数算法引用计数算法的实现简单. 判定效率也很高. 在大部分情况下是不错的选择. 主流的Java虚拟机里面没有选用引用计数算法来管理内存. 每次引用计数器+1. 当计数器值为0时, 对象就不可能被使用了. 实现简单.缺点: 它很难解决对象之间相互循环引用的问题. 每次产生和消除的时候. 需要伴随加法和减法操作. 对系统性能有影响 可达性分析算法在主流商用程序语言的主流实现中, 都是称通过可达性分析来判定对象是否存活. 这个算法的基本思想就是通过一系列的称为”GC Roots”的对象作为起始点. 从这些节点开始向下搜索, 搜索所走过的路径称为引用链, 当一个对象到GC Roots没有任何引用链相连时, 则证明此对象是不可用的.所以他们将会被判定为是可回收的对象. 在JAVA语言中, 可作为GC Roots的对象包括下面几种: 虚拟机栈(栈帧中的本地变量表)中, 引用的对象. 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI(Native方法)引用的对象 引用的类型 强引用就是指在程序代码之中普遍存在的. 类似Object obj = new Object(), 这类的引用, 只要强引用还存在. GC永远不会回收掉被引用的对象 软引用是用来描述一些还有用但并不需要的对象. 对于软引用关联着的对象. 在系统将要发生内存溢出异常之前. 将会把这些对象列进回收范围之中进行第二次回收. SoftReference类来实现软引用. 弱引用也是用来描述非必需对象. 但是它的强度比软引用更弱一些. 被弱引用关联的对象只能生存到下一次垃圾收集发生之前. 当GC工作事. 无论当前内存是否足够. 都会回收掉只被弱引用关联的对象. 虚引用也称为幽灵引用或者幻影引用. 这是最弱的一种引用关系. 一个对象是否有虚引用的存在. 完全不会对其生存时间构成影响, 也无法通过虚引用来获取对象实例, 为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知. PhantomReference 垃圾收集算法标记-清除算法最基础的收集算法是标记-消除算法. 算法分为标记和清除两个阶段:首先标记出所有可达的对象. 在标记完成后统一回收所有为被标记的对象. 标记的过程就是可达性分析算法来标记的. 在清除阶段, 清除所有未被标记的对象. 主要有两个不足: 效率问题. 标记和清除两个过程的效率都不高; 另一个是空间问题. 标记清除之后会产生大量不连续的内存碎片. 空间碎片太多可能会导致以后程序运行过程中需要分配较大对象时.无法找到足够的连续内存而不得不提前触发另一次收集动作. 复制算法为了解决效率问题. 复制算法出现了. 它将可用内存按照容量划分为大小相等的两块. 每次只使用其中一块. 当这一块的内存用完了. 就将还存活着的对象复制到另一块上面. 然后再把已使用过的内存空间一次清理掉.这样使得每次都是对整个半区进行内存回收. 内存分配时也就不用考虑内存碎片等复杂情况. 只要移动堆顶指针. 按循序分配内存即可. 只是这种算法将内存缩小为原来的一半. 代价太高. 现在的商业虚拟机都采用这种收集算法来回收新生代. 标记-整理算法复制收集算法在对象存活率较高时就会进行比较多的复制操作. 效率将会变低. 根据老年代的特定. 提出了标记-整理算法. 过程依然和标记-清除算法一样. 但后续步骤不是直接对可回收对象进行清理, 而是而是在清理无用对象完成后让所有存活的对象都向一端移动，并更新引用其对象的指针。 好处 不会产生碎片 坏处 会伴随着大量的对象移动, 代价很高 分代收集算法当前商业虚拟机的垃圾收集都采用分代收集算法.这种算法并没什么新的思想, 只是根据对象存活周期的不同将内存划分为几块. 一般是把Java堆分为新生代和老年代. 新生代. 每次垃圾收集时都发现大批对象死去. 只有少量存活. 选用复制算法 老年代对象存活率高. 没有额外空间对它进行分分配担保. 就用标记-清理或者标记-整理算法来回收. 分区算法分代算法是按照对象的生命周期长短划分成两个部分. 分区算法将整个堆空间划分成连续的不同小区间.每个小区间都独立使用. 独立回收. 这种算法的好处就是可以控制一次回收多少个小区间. 算法实现枚举根节点可作为GC Roots的节点主要在全局性的引用与执行上下文中. 现在很多应用仅仅方法区就有数百兆. 可达性分析对执行时间的敏感还体现在GC上. 因为这项分析工作必须在一个能确保一致性的快照中进行. 这里一致性的意思是指在整个分析期间整个系统看起来就像被冻结在某个时间点上. 不可以出现分析过程中对象引用关系还在不断变化的情况. 该点不满足的话分析结果准确性就无法得到保证. 在hotspot的实现中, 是使用一组称为OopMap的数据结构来达到这个目的. 在类加载完成的时候. HotSpot就把对象内什么偏移量上是什么类型的数据计算出来. 在JIT编译过程中. 也会在特定的位置记录下栈和寄存器中那些位置是引用.这种 GC在扫描时就可以直接得知这些信息了 安全点在OopMap的协助下. HotSpot可以快速准确的完成GCRoots枚举. OopMap内容变化的指令非常多. 如果为每一条zhi行都生成对应的OopMap. 就需要大量的额外空间.GC的空间成本将会变得很高. 实际上. HotSpot也的确没有为每条指令都生成OopMap. 只是在特定的位置记录这些信息. 这些位置叫安全点, 即程序执行时并非在所有地方都能停下来开始GC, 只有在到达安全点时才能暂停. 安全点的选定基本上是以程序”是否具有让程序长时间执行的特征”为标准进行选定的. 长时间执行的最明显特征就是指令序列复用. 例如方法调用. 循环调准, 异常跳转. 所以具有这些功能的指令才会产生Safepoint. 对于Sefepoint. 如何在GC发生时让所有线程都跑到最近的安全点上在停顿下来. 两种方法: 抢先式中断. 不需要线程代码主动去配合. 在GC发生时. 首先把所有线程全部中断, 如果发现有线程中断的地方不在安全点上. 就恢复线程. 让它跑到安全点上. 几乎没有虚拟机实现抢先式 主动式中断. 当GC需要中断线程的时候. 不直接对线程操作. 仅仅简单地设置一个标志. 各个线程执行时主动去轮询这个标志. 发现中断标志位真就自己中断挂起. 轮询标志的地方和安全点是重合的. 另外在加上创建对象需要分配内存的地方. 安全区域Sefepoint机制保证了程序执行时. 在不太长的时间内就会遇到可进入GC的Safepoint. 但是. 程序不执行呢? 就是没有分配CPU时间.典型的例子就是现场处于Sleep状态或者Blocked状态. JVM也显然不太可能等待线程重新被分配CPU时间. 对于这种情况. 就需要安全区域来解决. 安全区域是指在一段代码之中. 引用关系不会发生变化. 在这个区域中的任意地方开始GC都是安全的. 在线程执行到Safe Region中代码时. 首先标识自己已经进入Safe Region. 当在这段时间里JVM要发起GC时. 就不用管标识自己为Safe Region状态的线程了. 在线程要离开Safe Region时. 它要加检查系统是否已经完成了根节点枚举. 如果完成了. 那线程就继续执行. 否则它就必须等到直到收到可以完成离开Safe Region的信号为止. 内存分配与回收策略垃圾收集器新老串行回收器(Serial) 新生代串行回收器. 单线程独占式进行垃圾回收,(意思就是在垃圾回收时. Java应用程序中的线程都要暂停, 等待垃圾回收完成.Stop-The-World) 老年代串行回收器. 标记整理算法. 串行独占. -XX:+UseSerialGC: 新生代. 老年代都使用串行回收器-XX:+UseParNewGC: 新生代使用ParNew回收器, 老年代使用串行收集器-XX:+UseParallelGC: 新生代使用Parallel回收器, 老年代使用串行收集器. 新生代ParNew回收器工作在新生代,简单的串行回收器多线程化, 回收策略, 算法都和新生代串行回收器一样.独占式的. 在收集过程中.应用程序会全部暂停. -XX:+UseParNewGC:新生代使用ParNew, 老年代使用串行回收器-XX:UseConcMarkSweepGC: 新生代使用ParNew回收器. 老年代使用CMS-XX:ParallelGCThreads 参数可以指定ParNew回收器工作时线程数量. 最好与CPU数量相当 新生代ParallelGC回收器这是一个多线程.独占式的收集器. 但是它非常关注系统的吞吐量. -XX:+UseParallelGC: 新生代使用ParallelGC回收器, 老年代使用串行回收器-XX:+UseParallelOldGC: 新生代使用ParallelGC回收器. 老年代使用ParallelOldGC回收器ParallelGC提供两个重要的参数用于控制系统的吞吐量-XX:MaxGCPauseMillis: 设置最大垃圾收集停顿时间, ParallelGC工作是会尽可能地把停顿时间控制在参数以内. 如果把这个值设置的很小, 虚拟机会使用一个很小的堆. 这导致GC频繁, 反而降低吞吐量/-XX:GCTimeRatie: 设置吞吐量大小. 0-100之间. 假设值为n, 系统将花费不超过1/(1+n)的时间用于垃圾收集. 默认情况下取99, 即不超过1/(1+99)=1%的时间用于垃圾回收此外.ParallelGC与ParNew另一个不同的情况是还支持一种自适应的GC调节策略,使用-XX:UseAdaptiveSizePolicy可以打开自适应GC策略.这种模式下.eden和survivior的比例.晋升老年代的对象年龄等参数会被自动调整.已达在堆大小.吞吐量和停顿时间之间的平衡点. 老年代ParallelOldGC回收器多线程收集器. 关注吞吐量. 工作在老年代. CMS回收器只要关注停顿时间的多线程并行回收的垃圾回收器. 使用标记清除算法. 工作步骤 初始标记 标记根对象 (独占的) 并发标记 标记所有对象 (非独占,和用户线程一起执行) 预清理 清理前准备以及控制停顿时间 (非独占,和用户线程一起执行) 重新标记 修正并发标记数据 (独占的) 并发清理 清理垃圾 (非独占,和用户线程一起执行) 并发重置 (非独占,和用户线程一起执行) 主要的参数 -XX:UseConcMarkSweepGC. 设置合理的工作线程数量-XX:CMSInitiatingOccupancyFraction 指定回收阈值. 默认值68. 即当老年代的空间使用率达到68%, 会执行一次CMS回收.CMS是基于标记清除算法的回收器.该算法将会造成大量的内存碎片. 离散的可用空间无法分配较大的对象.-XX:+UseCMSCompactAtFullCollection开关可以使CMS在垃圾收集完成后, 进行一次内存碎片整理.-XX:CMSFullGCsBeforeCompaction参数可以用于设定进行多少次CMS回收后. 进行一次内存压缩 G1回收器JDK1.7以后正式使用的全新垃圾回收器. 为了取代CMS. G1拥有独特的垃圾回收策略. 从分代上看. G1依然属于分代垃圾回收器, 分年轻代和老年代.依然有eden,Survivor区. 从堆结构上看. 它并不会要求整个eden区, 年轻代或者老年代都连续. 使用了分区算法. 特点如下: 并行性 可以由多个GC线程同时工作. 有效利用多核心计算能力 并发性 拥有与应用程序交替执行的能力. 部分工作和应用程序同时执行. 分代GC 它同时兼顾年轻代和老年代. 空间整理 在回收过程中. 会进行适当的对象移动. CMS是在若干次GC后 CMS必须进行一次碎片整理. G1是每次回收都会有效地复制对象. 减少空间碎片 可预见性 用于分区的原因. G1可以只选取部分进行内存回收. 缩小了回收的范围. 对于全局停顿也能得到很好的控制 G1内存划分和收集过程G1将堆进行分区, 划分为一个个的区域. 每次收集只收集几个区域. 来控制垃圾回收产生的一次停顿时间. 新生代GC 主要工作在eden区和survivor区. 并发标记周期 初始标记. 标记从根节点直接可达的对象. 这个阶段会伴随一次新生代GC, 它会产生全局停顿. 应用线程必须在这个阶段停止执行.根区域扫描 由于初始标记必然会伴随一次新生代GC, 初始标记后. eden被清空.并且将存活的目标移入Survivor区. 这个阶段. 将扫描由survivor区直接可达的老年代区域. 并标记这些直接可达的对象. 这个过程是可以和应用程序并发执行的. 但根区域扫描不能和新生代GC同时进行.(因为根区域扫描依赖survivor区对象. 而新生代GC会修改这个区域), 如果恰巧在此时需要新生代GC, GC就需要等待根区域扫描结束后才能进行. 如果发生这些情况. 这次新生代GC的时间就会延长.并发标记 并发标记会扫描并查找整个堆的存活对象. 并做好标记. 这是一个并发过程. 并且这个过程可以被一次新生代GC打断.重新标记 重新标记会产生应用程序停顿. 由于在并发标记过程中, 应用程序依然在运行. 因此标记结果可能需要修正. 所以在此对上一次的标记进行补充. 在G1中, 这个过程使用SATB算法完成. 即G1会在标记之初为存活对象创建一个快照. 这个快照有助于加速重新标记的速度.独占清理 这个阶段会引起停顿. 计算各个区域的存活对象和GC回收比例并进行排序. 识别可供混合回收的区域. 这个阶段. 还会更新记忆集. 该阶段给出了需要被混合回收的区域并进行了标记. 在混合回收阶段.需要这些信息并发清理阶段. 这里会识别并清理完全空闲的区域. 这是并发的清理. 不会引起停顿 混合回收 在并发标记周期. 虽然有部分对象被回收. 但总体来说比例是相当低的. 但在并发标记周期后. G1已经明确知道哪些区域含有比较多的垃圾对象. 在混合回收阶段. 就可以专门针对这些区域进行回收.当然. G1会优先回收垃圾比例较高的区域. 在这个阶段, 既会执行正常的年轻代GC. 又会选取一些被标记的老年代区域进行回收. 同时处理新生代和老年代. 如果需要. 可能会进行Full GC 并发收集由于让应用程序和GC线程交替工作. 总是不能完全避免在特别繁忙的场合会出现在回收过程中内存不足的情况. 在遇到这种情形时. G1也会转入一个FullGC进行回收. 内存分配对象优先在Eden分配大多数情况下. 对象在新生代Eden区中分配. 当Eden区没有足够空间进行分配时. 虚拟机将发起一次MinorGC. 大对象直接进入老年代大对象是指: 需要大量连续内存空间的Java对象. 最典型的大对象就是那种很长的字符串以及数组. -XX: pretenureSizeThreshold参数. 令大于这个设置值的对象执行在老年代分配. 这样做的目的是避免在Eden去以及两个Survivor区之间发生大量的内存复制. 长期存活的对象将进入老年代既然虚拟机采用了分代收集的思想来管理内存. 那么内存回收时就必须能识别那些对象应放在新生代. 那些放在老年代中. 虚拟机给每个对象定义一个对象年龄计数器. 如果对象在Eden出生并经过第一次MinorGC后然后存活. 并且能被Survivor容纳的话. 将被移动到Survivor空间中. Age+1. 对象在Survivor区中熬过一次MinorGC. Age+1. 当它的年龄增加到一定程度(默认15岁), 就会进入老年代. -XX: MaxTenuringThresHold 能设置晋升老年代的年龄阈值. 动态对象年龄判定为了更好的适应不同程序的内存情况. 虚拟机并不是永远地要求对象的年龄必须到达了MaxTenuringThresHold才能晋升老年代. 如果Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半. 年龄大于或等于该年龄的对象就可以直接进入老年代. 无须等到MaxTenuringThresHold中要求的年龄. 空间分配担保在发生MinorGC之前. 虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象总空间. 如果成立. 那么MinorGC是安全的. 如果不成立. 则虚拟机胡查看HandlePromotionFailure设置值是否允许担保失败. 如果允许, 那么会继续检查老年代最大可用连续空间十分大于历次晋升到老年代对象的平均大小. 如果大于. 将尝试着进行一次MinorGC. 尽管有风险. 如果小于.或者HandlePromotionFailure设置不允许冒险. 那这时也要改为进行一次FullGC.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS解析]]></title>
    <url>%2F2019%2F04%2F18%2FDNS%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP相关]]></title>
    <url>%2F2019%2F04%2F16%2FTCP%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[TCP服务提供一种面向连接的. 可靠的字节流服务. 面向连接意味着两个应用TCP的应用. 通常是一个客户端和一个服务端, 在彼此交换数据之前必须先建立一个TCP连接. 这一个过程与打电话很相似. 先拨号振铃, 等待对方说应答. 然后才说明是谁. TCP提供可靠性的方式 应用数据被分割成TCP认为最合适发送的数据块. 当TCP发出一个段后. 启动一个定时器. 等待目的全确认收这个报文段. 如果不能及时收到一个确认. 将重发这个报文段 当TCP收到发自TCP连接另一端的数据. 他将发送一个确认. 这个确认不是立即发送. 通常将推迟分之一秒. TCP将保持它首部和数据的检验和. 这是一个端到端的检验和. 目的是检测数据在传输过程中的任何变化. 如果收到段的检验和有差错. TCP讲丢弃这个报文段和不确认收到此报文段(希望发送端超时并重发) 既然TCP报文段作为IP数据报来传输. 而IP数据报的到达可能会失序. 因此TCP报文段的到达也可能会失序. 如果必要. TCP将对收到的数据进行重新排序. 将收到的数据已正确的顺序交给应用层. 既然IP数据报会发生重复. TCP的接收端必须丢弃重复数据. TCP还能提供流程控制. TCP链接的每一方都有固定大小的缓冲空间, TCP的接收端只允许另一端发送接收端缓冲区能接纳的数据. 这将防止较快的主机导致较慢的主机的缓存区溢出. TCP首部 每个TCP段都包含源端和目的端的端口号. 用于寻找发端和收端应用进程. 这两个值加上IP首部中的源端IP地址和目的端IP地址唯一确定一个TCP连接. 序号用来标识从TCP发端向TCP收端发送的数据字节流. 它标识在这个报文段中的的第一个数据字节, 如果将字节流看作在连个应用间的单向流动. 则TCP用序号对每个字节进行计数. 序号是32bit的无序号数. 序号到达2^32-1后又从0开始 当建立一个新的连接时. syn标志变1. 序号字段包含由这个主机选择的该连接的初始序号ISN. 该主机要发送数据的一个字节需要为这个ISN加1. 因为SYN标志消耗了一个序号. 既然每个传输的字节都被计数. 确认序号包含发送确认的一端所期望收到的下一个序号. 因此, 确认序号应当是上次已成功收到数据字节序号+1. 只有ACK标志位1时确认序号字段才有效 发送ACK无需任何代价. 因为32bit的确认序号字段和ACK标志一样. 总是TCP首部一部分. 一旦连接建立起来, 这个总是被设置. ACK标志也总是被设置为1 TCP为应用层提供双全工服务. 这意味数据能在两个方向上独立地进行传输, 连接的每一端必须保持每个方向上的传输数据序号. TCP的流量控制有连接的每一端通过声明窗口大小来提供. 窗口大小为字节数. 其实与确认序号字段指明的值. 这个值是接收端端正期望接收的字节, TCP连接的建立和终止 建立连接协议 主动开启者(通常称为客户端)发送一个SYN报文段, 并指明自己想要连接的端口号和它的客户端初始序列号(记为ISN(c)), 通常, 客户端还会借此发送一个或多个选项, 客户端发送的这个SYN报文段称做段1 服务器也发送自己的SYN报文段作为相应, 并包含了它的初始序列号(ISN(s)), 该段称作段2. 此外. 为了确认客户端的SYN, 服务器将其包含的ISN(c)+1后作为返回的ACK数值, 因此. 每发送一个SYN. 序列号就会自动+1. 这样如果出现丢失的情况, 该SYN段将会重传. 为了确认服务器的SYN, 客户端将ISN(s)+1后作为返回ACK. 这称之为段3 这三个报文段完成链接的建立. 这个过程也称为三次握手. 连接终止协议 连接的主动关闭者发送一个FIN段指明接受者希望看到的自己当前的序列号(K), FIN段还包含了一个ACK段用于确认对方最近一次发来的数据(L) 连接的被动关闭者将K+1作为相应的ACK值. 以表明它已经成功接收到主动关闭者发送的FIN, 此时. 上层的应用程序会被告知连接的另一端已经提出了关闭请求. 通常. 这将导致应用程序发起自己的关闭操作. 接着. 被动关闭者将身份转变为主动关闭者. 并发送自己的FIN, 该报文段的序列号为L. 为了完成连接的关闭. 最后发送的报文段还包含一个ACK用于确认上一个FIN. 值得注意的是. 如果出现FIN丢失的情况, 那么发送方将重新传输直到接收到一个ACK确认为止. 关闭一个TCP连接需要4个报文段. 收到一个FIN只意味着在这一方向上没有数据流动. 一个TCP链接在收到一个FIN后仍能发送数据. 而这对利用半关闭的应用来说是可能的.尽管在实际应用中只有很少的. TCP应用程序这样做. TCP的半关闭TCP提供了连接的一端在结束它的发送后还能接受来自另一端数据的能力. 客户端发送完了自己的数据. 向服务端发送FIN. 服务端发送FIN的ack. 完成客户端半关闭. 意思是: 我没有数据发送了. 但是可以接收数据. 当服务端发送完数据. 发送一个FIN. 客户端返回FIN的ack. 完成服务端的关闭. 这是这个链接就彻底关闭了. 同时打开两个应用程序同时彼此执行主动打开. 每一方必须发送一个SYN, 且这些SYN必须传递给对方. 这需要每一方使用一个对方熟知的端口作为本地端口. 这里双方互为客户端和服务端, 需要交换4个报文段. 比正常的三次握手多了一次 同时关闭通常一方发送一个FIN执行主动关闭. 双方都执行主动关闭也是有可能. TCP协议也允许这样的同时关闭 双方同时发送FIN, 并在收到FIN后. 发送ACK. 初始序列号 TCP报文段在经过网络路由后可能会存在延迟抵达与排序混乱的情况。为了解决这一问题,需要仔细选择初始序列号。 在发送用于建立连接的SYN之前,通信双方会选择一个初始序列号。初始序列号会随时间而改变,因此每一个连接都拥有不同的初始序列号。 [RFCO793]指出初始序列号可被视为一个32位的计数器。该计数器的数值每4微秒加10此举的目的在于为一个连接的报文段安排序列号,以防止出现与其他连接的序列号重叠的情况。尤其对于同一连接的两个不同实例而言,新的序列号也不能出现重叠的情况。 TCP选项 种类 长度 名称 参考 描述与目的 0 1 EOL [RFCO793] 选项列表结束 1 1 NOP [RFCO793] 无操作(用于填充) 2 4 MSS [RFCO793]. 最大报文段大小 3 3 WSOPT [RFCO1323] 窗日缩放因子(窗日左移量) 4 2 SACK-Pemitted [RFCO2018] 发送者支持SACK选项 5 可变 SACk [RFCO2018] SACK阻塞(接收到乱序数据) 8 10 TSOPT [RFco1323] 时间戳选项 28 4 UTO [RFCO5482] 用户超时(一段空闲时间后的终止) 29 可变 TCP-AO [RFCO5925] 认证选项(使用多种算法) 253 可变 Experimental [RFcO4727] 保留供实验所用 254 可变 Experimental [RFCO4727] 保留供实验所用 TCP超时与重传TCP在发送数据时会设置一个计时器,若至计时器超时仍未收到数据确认信息,则会引发相应的超时或基于计时器的重传操作,计时器超时称为重传超时(RTO)。另一种方式的重传称为快速重传,通常发生在没有延时的情况下。若TCP累积确认无法返回新的ACK,或者当ACK包含的选择确认信息(SACK)表明出现失序报文段时,快速重传会推断出现丢圃 包。通常来说,当发送端认为接收端可能出现数据丢失时,需要决定发送新(未发送过的)数据还是重传 设置重传超时TCP超时和重传的基础是怎样根据给定连接的RTT设置RTO. 若TCP先于RTT开始重传. 可能会在网络中引起不必要的重复数据.反之. 真个网络利用率会随之下降. TCP在收到数据后返回确认信息. 因此可在该信息中携带一个字节的数据来测量传输改确认信息所需的时间. 每个此类的测量结果称为RTT样本. TCP首先需要根据一段时间内的样本值建立好估计值. 第二步是基于估计值设置RTO. RTO设置得当是保证TCP性能的关键. 每个TCP连接的RTT均独立计算. 并且重传计时器会对任何占用序列号的在传数据计时(包含SYN和FIN). 基于计时器的重传一旦TCP发送端得到了基于时间变化的RTT测量值,就能据此设置RTO,发送报文段时应确保重传计时器设置合理。在设定计时器前,需记录被计时的报文段序列号,若及时收到了该报文段的ACR,那么计时器被取消。之后发送端发送一个新的数据包时,需设定一个新的计时器,并记录新的序列号。因此每一个TCP连接的发送端不断地设定和取消一个重传计时器;如果没有数据丢失,则不会出现计时器超时。 若在连接设定的RTO内, TCP没有收到被计时报文段的ACK,将会触发超时重传。TCP将超时重传视为相当重要的事件,当发生这种情况时,它通过降低当前数据发送率来对此进行快速响应。实现它有两种方法: 第一种方法是基于拥塞控制机制减小发送窗口大小; 另一种方法为每当一个重传报文段被再次重传时,则增大RTO的退避因子,即Kam算法的“第二部分”。特别是当同一报文段出现多次重传时, RTO值(暂时性地)乘上值y来形成新的超时退避值: RTO=yRTO 在通常环境下, y值为1. 随着多次重传, y呈加倍增长‥ 2, 4, 8,等等。通常y不能超过最大退避因子(Linux确保其RTO设置不能超过TCP_RTO_MAX,其默认值为120s)。一旦接收到相应的ACK, y会重置为1. 快速重传快速重传机制[RFc5681]基于接收端的反馈信息来引发重传,而非重传计时器的超时。因此与超时重传相比,快速重传能更加及时有效地修复丢包情况。典型的TCP同时实现了两者。在详细讨论快速重传前,首先需要了解当接收到失序报文段时, TCP需要立即生成确认信息(重复ACK),并且失序情况表明在后续数据到达前出现了丢段,即接收端缓存出现了空缺。发送端的工作即为尽快地、高效地填补该空缺。 当失序数据到达时,重复Ack应立即返回,不能延时发送。原因在于使发送端尽早得知有失序报文段,并告诉其空缺在哪。当采用SACK时,重复ACK通常也包含SACK信息,利用该信息可以获知多个空缺。 重复ACK到达发送端表明先前发送的某个分组已丢失. 重复ACK也可能在另一种情况下出现. 即当网络中出现失序分组时—-若接受端收到氮气期盼序列号的后续分组时, 当前期盼的包可能丢失. 也可能延时到达. 通常是无法得知是那种情况的. TCP等待一定数目的重复ACK(dupthresh). 来决定数据是否丢失并触发快速重传. 通常这个阈值为3. 快速重传算法可以概括如下: TCP发送端在观测到至少dupthresh个重复ACK后,即重传可能丢失的数据分组,而不必等到重传计时器超时。当然也可以同时发送新的数据。根据重复ACk推断的丢包通常与网络拥塞有关,因此伴随快速重传应触发拥塞控制机制。不采用SACK时,在接收到有效ACK前至多只能重传一个报文段。采用SACK,ACK可包含额外信息,使得发送端在每个RTT时间内可以填补多个空缺。 带选择确认的重传TCP接收端可提供SACK功能. 通过TCP头部的累积ACK号字段来描述其接收到的数据. ACK号与接收端缓存中的其他数据之间的间隔称为空缺. 序列号高于空缺的数据称为失序数据. 因为这些数据和之前接收的序列号不连续. SACK信息中包含 left edge: 不连续块的第一个报文段的序列号 right edge: 不连续块的最后一个报文段的序列号之后的序列号; TCP发送端的任务是通过重传丢失的数据来填补接收端缓存中的空缺. 但同时也尽可能不重传以正确接收到的数据. SACK接收端行为接收端在TCP连接期间收到SACK许可选项即可生成SACK.通常来说. 每当缓存中存在失序数据时 接收端就可生成SACK. 导致数据失序的原因可能是由于传输过程中丢失. 也可能是新数据先于旧数据到达. 第一个SACK块内包含的是最近接受到的(most recently received)报文段的序列号范围. 最近的一个块中包含的内容除了包含最新接收的序列号信息. 还需重复之前的SACK块. 这样做的目的是防止SACK丢失. SACK发送端行为尽管一个支持SACK的接收端可通过生成合适的SACK信息来充分利用SACK,但还不足以使该TCP连接充分利用SACK功能。在发送端也应提供SACK功能,并且合理地利用接收到的SACK块来进行丢失重传,该过程也称为选择性重传( selective retransmission)或选择性重发(selective repeat). SACK发送端记录接收到的累积ACK信息(像大多数TCP发送端一样),还需记录接收到的SACK信息,并利用该信息来避免重传正确接收的数据。 一种方法是当接收到相应序列号范围的ACK时,则在其重传缓存中标记该报文段的选择重传成功。 当SACK发送端执行重传时,通常是由于其收到了SACK或重复ACK,它可以选择发送新数据或重传旧数据, SACR信息提供接收端数据的序列号范围,因此发送端可据此推断需要重传的空缺数据。最简单的方法是使发送端首先填补接收端的空缺,然后再继续发送新数据[RFc3517] (若拥塞控制机制允许)。这也是最常用的方法. 伪超时与重传在很多情况下. 即使没有出现数据丢失也可能引发重传. 这种不必要的重传就是伪重传. 其主要造成的原因是伪超时. 即过早判定超时. 其他因素如包失序. 包重复. 或ACK丢失也能导致该现象. 在实际RTT显著增长, 超时当前RTO时. 可能出现伪超时. 重复SACK(DSACK)拓展在非SACK的TCP中, ACK只能想发送端告知最大的有序报文段. 采用SACK则可告知其他的失序报文段. 基本的SACK机制对接收端收到重复护具端时怎么运作没有规定. 这些重复数据可能是伪重传. 网络中的重复或其他原因造成的. 在SACK接收端采用DSACK (或称作D-SACK),即重复SACK[RFC2883],并结合通常的SACK发送端,可在第一个SACK块中告知接收端收到的重复报文段序列号. DSACK的主要目的是判断何时的重传是不必要的,并了解网络中的其他事项。因此发送端至少可以推断是否发生了包失序、ACk丢失、包重复或伪重传. 包失序和包重复失序区分丢包与失序不是一个很重要的问题。要解决它需要判断发送端是否已经等待了足够长的时间来填补接收端的空缺。幸运的是,互联网中严重的失序并不常见[JO3],因此将dupthresh设为相对较小值(如缺省值为3)就能处理绝大部分情况。即便如此,还是有很多研究致力于调整TCP行为来应对严重失序[LLYO7]。有些方法可动态调整dupthresh,如Linux的TCP实现. 重复 利用SACK特别是DSACK, 就可以简单的忽略这个问题. TCP数据流与窗口管理延时确认在很多情况下. TCP并不对每个到来的数据包都返回ACK, 利用TCP的累积ACK字段就能实现该功能, 累积确认可以允许TCP延迟一段时间发送ACK, 以便将ACK和相同方向上需要传的数据结合发送. 这种捎带传输的方法经常用于批量数据传输. 显然TCP不能任意时长地延迟ACK, 否则对方会误认为数据丢失而出现不必要的重传. 采用延时ACK方法会减少ACK传输数据. 可以一定程度地减轻网络负载. Nagle算法算法要求. 当一个TCP链接中有在传数据. 小的报文段(长度小于MISS)就不能发送. 直到所有的在传数据都收到ACK, 并且在收到ACK后. TCP需要收集这些小数据. 将其整合到一个报文段中发送. 这种方法迫使TCP遵守停等规程. 只有等接收到所有在传数据的ACK后才能继续发送. 算法的精妙之处在于实现了自时钟控制. ACK返回越快. 数据传输也越快. 流量控制与窗口管理TCP的滑动窗口协议有什么用依靠发送确认. 设置RTO. 超时重传机制. 保证TCP协议是可靠的. 但效率不太高.如果从发送方到接收方传递即使一个很小的分组都要用很长时间(推迟或延迟)的话(如一秒或两秒,对卫星链路来说并非不正常),考虑一下那会怎样。发送方可以注人一个分组到通信路径,然后停下来等待直到它收到ACk.这个协议因此被称为“停止和等待” 。假设没有分组在传输中丢失和无可挽回地损害,该协议的吞吐量性能(每单位时间发送在网络中的数据量)与M/R成正比, M是分组大小, R是往返时间(RTT)。如果有分组丢失和损害的话,情况甚至更糟糕: “吞吐质” (每单位时间传送的有用数据量)明显要比吞吐量要低。 对于不会损害和丢失太多分组的网络来说,低吞吐量的原因是网络经常没有处于繁忙状态。情况与使用装配流水线时不出一个完整产品就不准新的工作进人类似。流水线大部分时间是空闲的。我们进一步对比,很明显,如果我们允许同一时间有多个工作单元进人流水线,就可以做得更好。对网络通信来说也是一样的一如果我们允许多个分组进人网络,就可以使它“更繁忙”,从而得到更高的吞吐量。 很明显,允许多个分组同时进人网络使事情变得复杂。现在发送方必须不仅要决定什么时间注人一个分组到网络中,还要考虑注人多少个。并且必须要指出在等待ACK时,怎样维持计时器,同时还必须要保存每个还没确认的分组的一个副本以防需要重传。接收方需要有一个更复杂的ACK机制:可以区分哪些分组已经收到,哪些还没有。接收方可能需要一个更复杂的缓存(分组保存)机制一允许维护“次序杂乱”的分组(那些比预想要先到的分组更早到达的分组,因为丢包和次序重排的原因),除非简单地抛弃这些分组,而这样做是很没效率的。还有其他一些没有这么明显的问题。如果接收方的接收速率比发送方的发送速率要慢怎么办?如果发送方简单地以很高的速率发送很多分组,接收方可能会因处理或内存的限制而丢掉这些分组。中间的路由器也会有相同的间题。如果网络基础设施处理不了发送方和接收方想要使用的数据发送率怎么办? 为了解决这些问题. 引入了滑动窗口协议. 滑动窗口TCP连接的每一端都可收发数据. 连接的收发数据量是通过一组窗口接口来维护的. 每个TCP活动连接的两端都维护一个发送窗口结构和接收窗口结构. TCP以字节(而非包)为单位维护其窗口结构。已标号为2 - 11字节。由接收端通告的窗日称为提供窗口(oiferedwindow),包含4 - 9字节。接收端已成功确认包括第3字节在内的之前的数据,并通告了一个6字节大小的窗日。窗口大小字段相对ACK号有一个字节的偏移量。发送端计算其可用窗口,即它可以立即发送的数据量。可用窗口计算值为提供窗日大小减去在传(已发送但未得到确认)的数据值.变量SND.UNA和SND.WND分别记录窗日左边界和提供窗口值.SND.NXT则记录下次发送的数据序列号,因此可用窗日值等于(SND.UNA+ SND.WND - SND.NXT)。 随着时间的推移,当接收到返回的数据ACK,滑动窗口也随之右移。窗口两端的相对运动使得窗口增大或减小。可用三个术语来描述窗日左右边界的运动: 关闭(close),即窗日左边界右移。当已发送数据得到ACK确认时,窗日会减小0 打开(open),即窗口右边界右移,使得可发送数据量增大。当已确认数据得到处理,接收端可用缓存变大,窗日也随之变大0 收缩(shrink),即窗口右边界左移。主机需求RFC [RFCl122]并不支持这一做法,但TCP必须能处理这一问题. 每个TCP报文段都包含ACK号和窗口通告信息, TCP发送端可以据此调节窗口结构。窗口左边界不能左移,因为它控制的是已确认的ACK号,具有累积性,不能返回。当得到的ACK号增大而窗口大小保持不变时(通常如此),我们就说窗口向前“滑动”。若随着ACK号增大窗日却减小,则左右边界距离减小。当左右边界相等时,称之为零窗日。此时发送端不能再发送新数据。这种情况下, TCP发送端开始探测(probe)对方窗口,伺机增大提供窗口。 接收端也维护一个窗口结构. 但比发送端窗口简单. 该窗口结构记录了已接收并确认的数据. 已经它能够接收的最大序列号. 该窗口可以保证其接收数据的正确性. 特别是. 接收端希望避免存储重复的已接收和确认的数据. 以及避免存储不应该接收的数据(超过发送方右窗口便捷的数据)下图描述了接收窗口结构 与发送端窗口一样,该窗口结构也包含一个左边界和右边界,但窗口内的字节(图中的4 - 9字节)并没有区分。对接收端来说,到达序列号小于左窗日边界(称为RCV.NXT),被认为是重复数据而丢弃,超过右边界(RCV.WND + RCV.NXT)的则超出处理范围,也被丢弃。注意到由于TCP的累积ACK结构,只有当到达数据序列号等于左边界时,数据才不会被丢弃,窗口才能向前滑动。对选择确认TCP来说,使用SACK选项,窗口内的其他报文段也可以被接收确认,但只有在接收到等于左边界的序列号数据时,窗口才能前移. 零窗口与TCP持续计时器TCP是通过接收端的通告窗口来实现流量控制的。通告窗口指示了接收端可接收的数据量。当窗口值变为0时,可以有效阻止发送端继续发送,直到窗口大小恢复为非零值。当接收端重新获得可用空间时,会给发送端传输一个窗口更新(window update),告知其可继续发送数据。这样的窗口更新通常都不包含数据(为“纯ACK” ),不能保证其传输的可靠性。 因此TCP必须有相应措施能处理这类丢包。如果一个包含窗口更新的ACK丢失,通信双方就会一直处于等待状态.接收方等待接收数据(已将窗口设为非零值),发送方等待收到窗口更新告知其可继续发送。为防止这种死锁的发生,发送端会采用一个持续计时器间歇性地查询接收端,看其窗口是否已增长。持续计时器会触发窗口探测(window probe)的传输,强制要求接收端返回ACK (其中包含了窗口大小字段)。主机需求RFC[RFCl122]建议在一个RTO之后发送第一个窗口探测,随后以指数时间间隔发送. TCP阻塞控制为了防止网络因为大规模的通信负载而瘫痪. 其基本方法就是当有理由认为网络即将进入阻塞状态时减缓TCP传输, 难点在于怎样准确的判断何时需要减缓且如何减缓TCP传输.以及何时恢复其原有的速度. TCP的流量控制机制完成了对发送速率的调节. 它是基于ACK数据包中的通告窗口大小字段来实现的. 避免接收方缓存溢出. 拥塞检测针对丢包情况, TCP采取的首要机制是重传.包括超时重传和快速重传. 但当网络处于阻塞崩溃状态时. 超时重传就是火上浇油. 在发送端进入一个窗口控制变量cwnd, 接收端通知窗口awnd, 发送端实际可用窗口W. W=min(cwnd,awnd)还没有收到ACK回复的数据量不能多于W(以包或字节为单位). 这是合乎逻辑的. 但实际情况并不如此. 因为网络和接收状况会随实际变化. 相应地awnd和cwnd的数组也会随之改变. TCP发送方无法直接获得cwnd的准确值. 因此W, cwnd, awnd的值都要根据经验设定并需动态调节. 我们希望W的值接近最佳窗口大小. W反应网络中可存储待发送数据量的大小. 如何确定W的值也就是BDP是难点. 经典的算法在新TCP建立之初. 还无法获知可用的传输资源. cwnd的初始值无法确定. TCP通过与接收端交换一个数据包就能获得awnd值. 获得cwnd的最佳值的唯一方法是以越来越快的速率不断发送数据. 直到出现丢包未止. 这时考虑立即以可用的最大速度发送或者慢速启动发送. 由于多个TCP连接共享一个网络传输. 以全速启动会影响其他连接的传输性能, 所以通常会有特定的算法来避免过快启动. 直至稳定传输后才会运行其他算法 慢启动当一个新的TCP连接建立或检测到由重传超时(RTO)导致的丢包时. 需要执行慢启动. TCP发送端长时间处于空闲状态也可能调用慢启动算法. 目的是使TCP在用阻塞避免搜寻更多可用宽带之前得到cwnd值, 以及帮助TCP建立ACK时钟, 通常TCP在建立新连接时执行慢启动. 直至有丢包. 执行拥塞算法进入稳定状态 TCP以发送一定数目的数据段开始慢启动. 称为初始窗口IW. IW的初始值为一个SMSS(发送方的最大段大小). 在没有出现丢包的情况且每个数据包都用相应的ACK. 第一个数据段的ACK到达. 继续发送一个新的数据段, 每收到一个好的ACK(大于之前的ACK)响应. 慢启动算法以min(N,SMSS)来增加cwnd值. 这里的N是值未经确定的传输数据中能通过这一好的ACK确认的字节数. 增长公式为w=2的k次方. 当检测到网络瘫痪.cwnd将大幅度减少(减至原值一半). 这是TCP右慢启动阶段进入阻塞避免阶段的转折点.与cwnd和慢启动阈值相关. 当发生ACK延时, cwnd仍以指数增长. 但增幅较小. 阻塞避免在慢启动阶段. cwnd的值快速增长. 一旦达到阈值(ssthresh). TCP会进入避免阻塞阶段. swnd每次的增长值近似于成功传输的数据段大小. 这种随时间线性增长方式与慢启动指数增长相比要缓慢很多. 每接收一个新的ACK, cwnd会更新为:cwnd(t-1) = cwnd(t)+SMSS*SMSS/cwnd(t) 当发生ACK延时. cwnd也会增长. 但增幅很小. 慢启动和阻塞避免的选择问题. 就是cwnd和ssthresh的关系问题. cwnd &lt; ssthresh 启用慢启动 cwnd &gt; ssthresh 执行阻塞避免; 两者相等. 任何一种都行. ssthresh也不是固定的. 这个值的初始值可以任意设置. 这会使得TCP总是以慢启动状态开始传输. 当有重传情况发生时. 无论是超时重传还是快速重传. ssthresh会改变. 值将减小至当前窗口大小的一半. 但是不会小于2*SMSS.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图一]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%9B%BE%E4%B8%80%2F</url>
    <content type="text"><![CDATA[术语表 图是有一组顶点和一组能够将两个顶点相连的边组成的. 0至V-1来表示一张含有V个顶点的图中的各个顶点. 例如v和w是连个顶点. v-w和w-v是两条边 自环 即一条连接一个顶点和其自己的边 平行边 连接同一对顶点的两条边 多重图 含有平行边的图. 简单图. 不含有平行边和自环的图 相邻: 当两个顶点通过一条边相连时, 称之为相邻 并称这条边 依附 于这两个顶点 度数 依附于该顶点的边的总数 路径 由边顺序连接的一系列顶点. 简单路径是一条没有重复顶点的路径. 环是一条至少含有一条边且和终点相同的路径. 简单环是一条不含有重复顶点和边的环. 路径或者环的长度为其中包含的边数 连通的. 当两个顶点之间存在一条连接双方的路径时. 称一个顶点和另一个顶点是连通的 连通图 从任意一个顶点都存在一条路径到达另一个任意顶点. 称这幅图是连通图 一副非连通的图有若干连通的部分组成. 他们都是其极大连通图. 图的密度是指已经连接的顶点对占所有可能被连通的顶点对的比例. 无向图无向图的api表示 public class Graph Graph(int v) 创建一个含有V个顶点但不含有边的图 int V() 定点数 int E() 边数 void adEdge(int v, int w) 向图中添加一条边v-w Iterable adj(int v) 和v相邻的所有顶点 String toString() 对象的字符串表示 图的几种表示法要求他必须为可能在应用中碰到的各种类型的图预留出足够的空间 Graph的实例方法实现一定要快. 他们是开发处理图的各种用例的基础 邻接矩阵. 可以使用一个V乘V的布尔矩阵. 当顶点v和顶点w之间有相链接的边时. 定义v行w列的元素值为true, 否则为false. 所需空间太大 边的数组. 可以使用Edge类. 它含有两个int实例变量. adj()实现需要遍历整个数组 邻接表数组 可以使用一个以顶点为索引的列表数组. 其中的每个元素都是和该顶点相邻的顶点列表, 这种表示法的特点是: 使用的空间和V+E成正比. 添加一条边所需的时间为常数, 遍历顶点v的所有相邻顶点所需的时间和v的度数成正比. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 无向图(邻接表) * * @author Darcy * Created By Darcy on 2018/8/2 下午2:34 */public class Graph &#123; /** * 顶点数目 */ private final int V; /** * 边的数目 */ private int E; private Bag&lt;Integer&gt;[] adj; public Graph(int V) &#123; this.V = V; this.E = 0; adj = new Bag[V]; for (int v = 0; v &lt; V; v++) &#123; adj[v] = new Bag&lt;&gt;(); &#125; &#125; public Graph(In in) &#123; this(in.readInt()); int E = in.readInt(); for (int i = 0; i &lt; E; i++) &#123; int v = in.readInt(); int w = in.readInt(); addEdge(v, w); &#125; &#125; public int V() &#123; return V; &#125; public int E() &#123; return E; &#125; /** * 添加边 * * @param v 顶点 * @param w 顶点 */ public void addEdge(int v, int w) &#123; adj[v].add(w); adj[w].add(v); E++; &#125; /** * v相邻的所有顶点 * * @param v 定点 * @return 迭代器 */ public Iterable&lt;Integer&gt; adj(int v) &#123; return adj[v]; &#125;&#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[平衡查找树]]></title>
    <url>%2F2019%2F03%2F27%2F%E5%B9%B3%E8%A1%A1%E6%9F%A5%E6%89%BE%E6%A0%91%2F</url>
    <content type="text"><![CDATA[二叉查找树的弊端在于 要求构造树的键必须是随机的. 我们希望二叉查找树无论怎么构造他. 他的运行时间都是对数级别的.在一课含有N个节点的树中. 希望树高为lgN, 这样能保证所有查找都能在lgN次比较内结束. 就和二分查找一样. 不幸的是. 在动态插入中保证树的完美平衡代价太高了. 2-3查找树 2- 节点, 含有一个键和两条链接. 左链接指向的2-3树中的键都小于改节点. 右链接指向的2-3树中的键都大于改节点. 3- 节点, 含有二个键和三条链接. 左链接指向的2-3树中的键都小于该节点, 中链接指向的2-3树中的键都位于该节点的连个键之间. 右链接指向的2-3树中的键都大于该节点 查找要判断一个键是否存在树中, 先将它和根节点中的键进行比较. 如果他和其中任意一个相等. 就命中. 否则就根据比较结果找到指向相应的区间的链接. 并在其指向的子树中递归地继续查找. 如果这是个空连接. 为命中. 插入2- 节点中插入新建如果未命中的查找结束语一个2- 节点. 直接把2- 节点替换为一个3- 节点, 将要插入的键保存在其中即可, 如果未命中的查找结束于一个3- 节点. 3- 节点插入新建假设需要向一个颗只含有一个3- 节点的树中插入一个新建. 为了插入这个建. 先临时将新键存入改节点中. 使之成为一个4- 节点. 它很自然地拓展了以前的节点并含有3个键和4条连接. 创建一个4- 节点很方便, 也很容易将其装换为一个由3个2- 节点组成的2-3树. 其中一个节点含有中键.一个节点含有三个键中的最小者, 一个节点含有3个键中的最大者. 这颗树即是一颗含有3个节点的二叉查找树. 同时也是一颗完美平衡的2-3树. 见图1: 向一个父节点2-的3-节点插入新键构造一个4-节点并将其分解. 但此时我们不会为中键创建一个新节点, 而是将其移动至原来的父节点中. 见图2: 向一个父节点为3-的节点的3-节点插入新键构建一个4-节点, 然后将它的中键插入它的父节点中.父节点也成为4-节点, 然后在这个节点上进行相同的变换. 即分解这个父节点并将它的中键插入到它的父节点中去. 见图3: ![](/images/2-3树插入.jpg) 性质和标准的二叉查找树由上向下生长不同. 2-3树的生长是由下向上的. 在二叉查找树中. 按照升序插入10个建会得到高度为9的一颗最差的树. 如果使用2-3树, 树的高度是2. 命题 在一颗大小为N的2-3树中, 查找和插入操作访问的节点必然不超过lgN个 2-3树和二叉查找树大不相同. 可以确定的是即便是在最坏的情况下2-3树任有较好的性能. 每个操作中处理每个节点的时间都不会超过一个较小的常熟. 且这两个操作都会访问一条路径上的节点, 所以任何查找或者插入的成本都肯定不会超过对数级别. 例如: 含有10亿个节点的一颗2-3树的高度仅在19-30直接.最多只需要访问30个节点就能够在10亿个键中进行任意查找和插入操作. 这个真正的实现差距很大. 尽管可以用不同的数据类型表示2-和3-并写出变换所需的代码. 需要处理的情况实在太多了. 需要维护两种不同类型的节点, 实现这些不仅需要大量的代码. 而却所产生的额外开销可能会使算法比标准二叉查找树更慢. 平衡一棵树的初衷是为了消除最坏情况, 希望这种保障所需的代码越少越好. 红黑二叉查找树2-3的算法不难理解. 但是实现起来太难了. 红黑二叉查找树结构简单. 代码量不大. 替换3- 节点基本思想就是用标准的二叉查找树和一些额外的信息来表示2-3树. 将树中链接分为两种: 洪链接将两个2-节点连起来构成一个3-节点. 黑链接则是2-3树中的普通链接 这种表法的优点就是 无需修改就可以直接使用标准二叉查找树的get()方法. 定义 红链接均为左链接 没有任何一个节点同时和两条红链接相连. 该树是完美黑色平衡的. 即任意空链接到根节点的路径上的黑链接数量相等 颜色表示因为每个节点都只会有一条指向自己的链接. 将链接的颜色保存在表示节点的Node数据类型的布尔变量color中, 如果指向它的链接是红色的, 该变量为true, 黑色则为false, 约定空链接为黑色. 旋转在实现一些操作时,会出现红色右链接或者两条连续的红链接. 但在操作完成前这些情况都会被小心地旋转并修复. 旋转操作回改变红链接的指向. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * * 左旋转 * * | | * h -&gt; ( E ) ( S ) &lt;- x * / \\ // \ * (小于E) ( S ) &lt;- x -----&gt; h-&gt; ( E ) (大于S) * / \ / \ * (介于E和 (大于S) (小于E) (E和S之间) * S之间) * @param h 目标节点 * @return Node 节点 */private Node rotateLeft(Node h) &#123; Node x = h.right; h.right = x.left; x.left = h; x.color = x.left.color; x.left.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x;&#125;/** * * 右旋转 * * | | * ( S ) &lt;- h x -&gt; ( E ) * // \ / \\ * x-&gt; ( E ) (大于S) -----&gt; (小于E) ( S ) &lt;- h * / \ / \ * (小于E) (E和S之间) (介于E和 (大于S) * S之间) * @param h 目标节点 * @return Node 节点 */private Node rotateRight(Node h) &#123; Node x = h.left; h.left = x.right; x.right = h; x.color = x.right.color; x.right.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x;&#125; 向单个2- 节点中插入新建一颗只含有一个键的红黑树只含有一个2- 节点.向一个2-节点插入新节点, 如果新建小于老的. 直接插入红色节点即可. 如果新键大于老的. 插入红色节点后, 需要root = rotateLeft(root); 来将其旋转为红色左链接并修复根节点的链接. 插入操作才算完成 向树底部的2- 节点插入新键向和标准二叉查找树的方式在树的底部插入新键, 如果父节点是2- 节点, 那么上边的方法就适用. 向一颗双键树(即3- 节点)中插入新键可以分为3种情况, 小于树中的两个键. 两者之间. 大于树中的两个键 新键大于原树中的连个键. 因此他被链接到3-节点的右链接, 此事树是平衡的. 根节点为中间节点, 它有两条红色链接分别和较小和较大的节点相连. 我们需要将两条红色链接都变成黑色. 就可以得到一颗由三个节点组成的. 高度为2的平衡树. 新键小于原树中的两个键,.它会被链接到最左边的空链接. 这样就产生了两条连续的红链接. 这样只需要将上层的红链接右旋就得到了第一种情况. 如果新键在两个老键之间. 这又会产生两条连续的红链接. 一条红色的左链接连接着一条红色的右链接. 此时需要将下层的右红色链接左旋即可得到第二种情况. 总的来说 通过0次 1次 2次选择以及颜色变化就可以得到期望的结果. 颜色转换12345private void flipColors(Node h) &#123; h.color = !h.color; h.left.color = !h.left.color; h.right.color = !h.right.color; &#125; 完整实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677/** * @author Darcy * Created By Darcy on 2019-03-27 18:59 */public class RedBlackBST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private static final boolean RED = true; private static final boolean BLACK = false; private Node root; /** * h * |/_ * h.left.color = RED ( E ) h.right.color = BLACK * _\| // \ |/_ * ( C ) ( J ) * / \ // \ * ( A ) ( D ) ( G ) * / \ / \ / \ * // 红色节点 / 黑色节点 */ private class Node &#123; /** * 键 */ private Key key; /** * 值 */ private Value val; /** * 左右链接 */ private Node left, right; /** * 由其父节点指向它的链接颜色 */ private boolean color; /** * 这个子树中的节点总数 */ private int size; public Node(Key key, Value val, boolean color, int size) &#123; this.key = key; this.val = val; this.color = color; this.size = size; &#125; &#125; public RedBlackBST() &#123; &#125; private boolean isRed(Node x) &#123; if (x == null) &#123; return false; &#125; return x.color == RED; &#125; private int size(Node x) &#123; if (x == null) &#123; return 0; &#125; return x.size; &#125; public int size() &#123; return size(root); &#125; public boolean isEmpty() &#123; return root == null; &#125; public Value get(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to get() is null&quot;); &#125; return get(root, key); &#125; private Value get(Node x, Key key) &#123; while (x != null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) &#123; x = x.left; &#125; else if (cmp &gt; 0) &#123; x = x.right; &#125; else &#123; return x.val; &#125; &#125; return null; &#125; public boolean contains(Key key) &#123; return get(key) != null; &#125; public void put(Key key, Value val) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;first argument to put() is null&quot;); &#125; if (val == null) &#123; delete(key); return; &#125; root = put(root, key, val); root.color = BLACK; &#125; private Node put(Node h, Key key, Value val) &#123; if (h == null) &#123; return new Node(key, val, RED, 1); &#125; int cmp = key.compareTo(h.key); if (cmp &lt; 0) &#123; h.left = put(h.left, key, val); &#125; else if (cmp &gt; 0) &#123; h.right = put(h.right, key, val); &#125; else &#123; h.val = val; &#125; if (isRed(h.right) &amp;&amp; !isRed(h.left)) &#123; h = rotateLeft(h); &#125; if (isRed(h.left) &amp;&amp; isRed(h.left.left)) &#123; h = rotateRight(h); &#125; if (isRed(h.left) &amp;&amp; isRed(h.right)) &#123; flipColors(h); &#125; h.size = size(h.left) + size(h.right) + 1; return h; &#125; public void deleteMin() &#123; if (isEmpty()) &#123; throw new NoSuchElementException(&quot;BST underflow&quot;); &#125; if (!isRed(root.left) &amp;&amp; !isRed(root.right)) &#123; root.color = RED; &#125; root = deleteMin(root); if (!isEmpty()) &#123; root.color = BLACK; &#125; &#125; private Node deleteMin(Node h) &#123; if (h.left == null) &#123; return null; &#125; if (!isRed(h.left) &amp;&amp; !isRed(h.left.left)) &#123; h = moveRedLeft(h); &#125; h.left = deleteMin(h.left); return balance(h); &#125; public void deleteMax() &#123; if (isEmpty()) &#123; throw new NoSuchElementException(&quot;BST underflow&quot;); &#125; if (!isRed(root.left) &amp;&amp; !isRed(root.right)) &#123; root.color = RED; &#125; root = deleteMax(root); if (!isEmpty()) &#123; root.color = BLACK; &#125; &#125; private Node deleteMax(Node h) &#123; if (isRed(h.left)) &#123; h = rotateRight(h); &#125; if (h.right == null) &#123; return null; &#125; if (!isRed(h.right) &amp;&amp; !isRed(h.right.left)) &#123; h = moveRedRight(h); &#125; h.right = deleteMax(h.right); return balance(h); &#125; public void delete(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to delete() is null&quot;); &#125; if (!contains(key)) &#123; return; &#125; if (!isRed(root.left) &amp;&amp; !isRed(root.right)) &#123; root.color = RED; &#125; root = delete(root, key); if (!isEmpty()) &#123; root.color = BLACK; &#125; &#125; private Node delete(Node h, Key key) &#123; if (key.compareTo(h.key) &lt; 0) &#123; if (!isRed(h.left) &amp;&amp; !isRed(h.left.left)) &#123; h = moveRedLeft(h); &#125; h.left = delete(h.left, key); &#125; else &#123; if (isRed(h.left)) &#123; h = rotateRight(h); &#125; if (key.compareTo(h.key) == 0 &amp;&amp; (h.right == null)) &#123; return null; &#125; if (!isRed(h.right) &amp;&amp; !isRed(h.right.left)) &#123; h = moveRedRight(h); &#125; if (key.compareTo(h.key) == 0) &#123; Node x = min(h.right); h.key = x.key; h.val = x.val; // h.val = get(h.right, min(h.right).key); // h.key = min(h.right).key; h.right = deleteMin(h.right); &#125; else &#123; h.right = delete(h.right, key); &#125; &#125; return balance(h); &#125; /** * * 左旋转 * * | | * h -&gt; ( E ) ( S ) &lt;- x * / \\ // \ * (小于E) ( S ) &lt;- x -----&gt; h-&gt; ( E ) (大于S) * / \ / \ * (介于E和 (大于S) (小于E) (E和S之间) * S之间) * @param h 目标节点 * @return Node 节点 */ private Node rotateLeft(Node h) &#123; Node x = h.right; h.right = x.left; x.left = h; x.color = x.left.color; x.left.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x; &#125; /** * * 右旋转 * * | | * ( S ) &lt;- h x -&gt; ( E ) * // \ / \\ * x-&gt; ( E ) (大于S) -----&gt; (小于E) ( S ) &lt;- h * / \ / \ * (小于E) (E和S之间) (介于E和 (大于S) * S之间) * @param h 目标节点 * @return Node 节点 */ private Node rotateRight(Node h) &#123; Node x = h.left; h.left = x.right; x.right = h; x.color = x.right.color; x.right.color = RED; x.size = h.size; h.size = size(h.left) + size(h.right) + 1; return x; &#125; private void flipColors(Node h) &#123; h.color = !h.color; h.left.color = !h.left.color; h.right.color = !h.right.color; &#125; private Node moveRedLeft(Node h) &#123; flipColors(h); if (isRed(h.right.left)) &#123; h.right = rotateRight(h.right); h = rotateLeft(h); flipColors(h); &#125; return h; &#125; private Node moveRedRight(Node h) &#123; flipColors(h); if (isRed(h.left.left)) &#123; h = rotateRight(h); flipColors(h); &#125; return h; &#125; private Node balance(Node h) &#123; if (isRed(h.right)) &#123; h = rotateLeft(h); &#125; if (isRed(h.left) &amp;&amp; isRed(h.left.left)) &#123; h = rotateRight(h); &#125; if (isRed(h.left) &amp;&amp; isRed(h.right)) &#123; flipColors(h); &#125; h.size = size(h.left) + size(h.right) + 1; return h; &#125; public int height() &#123; return height(root); &#125; private int height(Node x) &#123; if (x == null) &#123; return -1; &#125; return 1 + Math.max(height(x.left), height(x.right)); &#125; public Key min() &#123; if (isEmpty()) &#123; throw new NoSuchElementException(&quot;calls min() with empty symbol table&quot;); &#125; return min(root).key; &#125; private Node min(Node x) &#123; if (x.left == null) &#123; return x; &#125; else &#123; return min(x.left); &#125; &#125; public Key max() &#123; if (isEmpty()) &#123; throw new NoSuchElementException(&quot;calls max() with empty symbol table&quot;); &#125; return max(root).key; &#125; private Node max(Node x) &#123; // assert x != null; if (x.right == null) &#123; return x; &#125; else &#123; return max(x.right); &#125; &#125; public Key floor(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to floor() is null&quot;); &#125; if (isEmpty()) &#123; throw new NoSuchElementException(&quot;calls floor() with empty symbol table&quot;); &#125; Node x = floor(root, key); if (x == null) &#123; return null; &#125; else &#123; return x.key; &#125; &#125; private Node floor(Node x, Key key) &#123; if (x == null) &#123; return null; &#125; int cmp = key.compareTo(x.key); if (cmp == 0) &#123; return x; &#125; if (cmp &lt; 0) &#123; return floor(x.left, key); &#125; Node t = floor(x.right, key); if (t != null) &#123; return t; &#125; else &#123; return x; &#125; &#125; public Key ceiling(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to ceiling() is null&quot;); &#125; if (isEmpty()) &#123; throw new NoSuchElementException(&quot;calls ceiling() with empty symbol table&quot;); &#125; Node x = ceiling(root, key); if (x == null) &#123; return null; &#125; else &#123; return x.key; &#125; &#125; private Node ceiling(Node x, Key key) &#123; if (x == null) &#123; return null; &#125; int cmp = key.compareTo(x.key); if (cmp == 0) &#123; return x; &#125; if (cmp &gt; 0) &#123; return ceiling(x.right, key); &#125; Node t = ceiling(x.left, key); if (t != null) &#123; return t; &#125; else &#123; return x; &#125; &#125; public Key select(int k) &#123; if (k &lt; 0 || k &gt;= size()) &#123; throw new IllegalArgumentException(&quot;argument to select() is invalid: &quot; + k); &#125; Node x = select(root, k); return x.key; &#125; private Node select(Node x, int k) &#123; // assert x != null; // assert k &gt;= 0 &amp;&amp; k &lt; size(x); int t = size(x.left); if (t &gt; k) &#123; return select(x.left, k); &#125; else if (t &lt; k) &#123; return select(x.right, k - t - 1); &#125; else &#123; return x; &#125; &#125; public int rank(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to rank() is null&quot;); &#125; return rank(key, root); &#125; private int rank(Key key, Node x) &#123; if (x == null) &#123; return 0; &#125; int cmp = key.compareTo(x.key); if (cmp &lt; 0) &#123; return rank(key, x.left); &#125; else if (cmp &gt; 0) &#123; return 1 + size(x.left) + rank(key, x.right); &#125; else &#123; return size(x.left); &#125; &#125; public Iterable&lt;Key&gt; keys() &#123; if (isEmpty()) &#123; return new Queue&lt;Key&gt;(); &#125; return keys(min(), max()); &#125; public Iterable&lt;Key&gt; keys(Key lo, Key hi) &#123; if (lo == null) &#123; throw new IllegalArgumentException(&quot;first argument to keys() is null&quot;); &#125; if (hi == null) &#123; throw new IllegalArgumentException(&quot;second argument to keys() is null&quot;); &#125; Queue&lt;Key&gt; queue = new Queue&lt;Key&gt;(); keys(root, queue, lo, hi); return queue; &#125; private void keys(Node x, Queue&lt;Key&gt; queue, Key lo, Key hi) &#123; if (x == null) &#123; return; &#125; int cmplo = lo.compareTo(x.key); int cmphi = hi.compareTo(x.key); if (cmplo &lt; 0) &#123; keys(x.left, queue, lo, hi); &#125; if (cmplo &lt;= 0 &amp;&amp; cmphi &gt;= 0) &#123; queue.enqueue(x.key); &#125; if (cmphi &gt; 0) &#123; keys(x.right, queue, lo, hi); &#125; &#125; public int size(Key lo, Key hi) &#123; if (lo == null) &#123; throw new IllegalArgumentException(&quot;first argument to size() is null&quot;); &#125; if (hi == null) &#123; throw new IllegalArgumentException(&quot;second argument to size() is null&quot;); &#125; if (lo.compareTo(hi) &gt; 0) &#123; return 0; &#125; if (contains(hi)) &#123; return rank(hi) - rank(lo) + 1; &#125; else &#123; return rank(hi) - rank(lo); &#125; &#125; private boolean check() &#123; if (!isBST()) &#123; StdOut.println(&quot;Not in symmetric order&quot;); &#125; if (!isSizeConsistent()) &#123; StdOut.println(&quot;Subtree counts not consistent&quot;); &#125; if (!isRankConsistent()) &#123; StdOut.println(&quot;Ranks not consistent&quot;); &#125; if (!is23()) &#123; StdOut.println(&quot;Not a 2-3 tree&quot;); &#125; if (!isBalanced()) &#123; StdOut.println(&quot;Not balanced&quot;); &#125; return isBST() &amp;&amp; isSizeConsistent() &amp;&amp; isRankConsistent() &amp;&amp; is23() &amp;&amp; isBalanced(); &#125; private boolean isBST() &#123; return isBST(root, null, null); &#125; private boolean isBST(Node x, Key min, Key max) &#123; if (x == null) &#123; return true; &#125; if (min != null &amp;&amp; x.key.compareTo(min) &lt;= 0) &#123; return false; &#125; if (max != null &amp;&amp; x.key.compareTo(max) &gt;= 0) &#123; return false; &#125; return isBST(x.left, min, x.key) &amp;&amp; isBST(x.right, x.key, max); &#125; private boolean isSizeConsistent() &#123; return isSizeConsistent(root); &#125; private boolean isSizeConsistent(Node x) &#123; if (x == null) &#123; return true; &#125; if (x.size != size(x.left) + size(x.right) + 1) &#123; return false; &#125; return isSizeConsistent(x.left) &amp;&amp; isSizeConsistent(x.right); &#125; private boolean isRankConsistent() &#123; for (int i = 0; i &lt; size(); i++) &#123; if (i != rank(select(i))) return false; &#125; for (Key key : keys()) &#123; if (key.compareTo(select(rank(key))) != 0) &#123; return false; &#125; &#125; return true; &#125; private boolean is23() &#123; return is23(root); &#125; private boolean is23(Node x) &#123; if (x == null) &#123; return true; &#125; if (isRed(x.right)) &#123; return false; &#125; if (x != root &amp;&amp; isRed(x) &amp;&amp; isRed(x.left)) &#123; return false; &#125; return is23(x.left) &amp;&amp; is23(x.right); &#125; private boolean isBalanced() &#123; int black = 0; Node x = root; while (x != null) &#123; if (!isRed(x)) &#123; black++; &#125; x = x.left; &#125; return isBalanced(root, black); &#125; private boolean isBalanced(Node x, int black) &#123; if (x == null) &#123; return black == 0; &#125; if (!isRed(x)) &#123; black--; &#125; return isBalanced(x.left, black) &amp;&amp; isBalanced(x.right, black); &#125; public static void main(String[] args) &#123; RedBlackBST&lt;String, Integer&gt; st = new RedBlackBST&lt;&gt;(); for (int i = 0; !StdIn.isEmpty(); i++) &#123; String key = StdIn.readString(); st.put(key, i); &#125; for (String s : st.keys()) &#123; StdOut.println(s + &quot; &quot; + st.get(s)); &#125; StdOut.println(); &#125;&#125; 性质所有基于红黑树的符号表实现都能保证操作的运行时间为对数级别(范围查找除外, 它所需的额外时间和返回的键的数量成正比)]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉查找树]]></title>
    <url>%2F2019%2F03%2F26%2F%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91%2F</url>
    <content type="text"><![CDATA[和链表一样, 嵌套定义了一个私有类来表示二叉查找树上的一个节点, 每个节点都含有一个键,一个值,一个左链接,一个右链接和一个节点计数器.左链接指向一颗小于该节点的所有键组成的二叉查找树.右链接指向一颗由大于该节点的所有键组成的二叉查找树,变量N给出了以该节点为根的子树的节点总数. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269/** * @author Darcy * Created By Darcy on 2019-03-18 16:42 */public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; /** * 二叉查找树的根节点 */ private Node root; /** * 内嵌的节点类 */ private class Node &#123; /** * 键 */ private Key key; /** * 值 */ private Value value; /** * left 左 * right 右 */ private Node left, right; /** * 以该节点为根的子树中的节点总数 */ private int N; public Node(Key key, Value value, int N) &#123; this.key = key; this.value = value; this.N = N; &#125; &#125; private int size(Node x) &#123; if (x == null) &#123; return 0; &#125; else &#123; return x.N; &#125; &#125; public int size() &#123; return size(root); &#125; private Value get(Node x, Key key) &#123; if (x == null) &#123; return null; &#125; int cmp = key.compareTo(x.key); if (cmp &gt; 0) &#123; return get(x.right, key); &#125; else if (cmp &lt; 0) &#123; return get(x.left, key); &#125; else &#123; return x.value; &#125; &#125; public Value get(Key key) &#123; return get(root, key); &#125; private Node put(Node x, Key key, Value value) &#123; if (x == null) &#123; return new Node(key, value, 1); &#125; int cmp = key.compareTo(x.key); if (cmp &gt; 0) &#123; x.right = put(x.right, key, value); &#125; else if (cmp &lt; 0) &#123; x.left = put(x.left, key, value); &#125; else &#123; x.value = value; &#125; x.N = size(x.left) + size(x.right) + 1; return x; &#125; public void put(Key key, Value value) &#123; root = put(root, key, value); &#125; private Node min(Node x) &#123; if (x.left == null) &#123; return x; &#125; return min(x.left); &#125; public Key min() &#123; return min(root).key; &#125; private Node max(Node x) &#123; if (x.right == null) &#123; return x; &#125; return min(x.right); &#125; public Key max() &#123; return max(root).key; &#125; private Node floor(Node x, Key key) &#123; if (x == null) &#123; return null; &#125; int cmp = key.compareTo(x.key); if (cmp == 0) &#123; return x; &#125; if (cmp &lt; 0) &#123; return floor(x.left, key); &#125; Node t = floor(x.right, key); if (t != null) &#123; return t; &#125; else &#123; return x; &#125; &#125; public Key floor(Key key) &#123; Node x = floor(root, key); if (x == null) &#123; return null; &#125; return x.key; &#125; private Node select(Node x, int k) &#123; if (x == null) &#123; return null; &#125; int t = size(x.left); if (t &gt; k) &#123; return select(x.left, k); &#125; else if (t &lt; k) &#123; return select(x.right, k - t - 1); &#125; else &#123; return x; &#125; &#125; public Key select(int k) &#123; return select(root, k).key; &#125; private int rank(Key key, Node x) &#123; if (x == null) &#123; return 0; &#125; int cmp = key.compareTo(x.key); if (cmp &lt; 0) &#123; return rank(key, x.left); &#125; else if (cmp &gt; 0) &#123; return 1 + size(x.left) + rank(key, x.right); &#125; else &#123; return size(x.left); &#125; &#125; public int rank(Key key) &#123; return rank(key, root); &#125; private Node deleteMin(Node x) &#123; if (x.left == null) &#123; return x.right; &#125; x.left = deleteMin(x.left); x.N = size(x.left) + size(x.right) + 1; return x; &#125; public void deleteMin() &#123; root = deleteMin(root); &#125; private Node delete(Node x, Key key) &#123; if (x == null) &#123; return null; &#125; int cmp = key.compareTo(x.key); /*根据二叉树性质查找key*/ if (cmp &gt; 0) &#123; return delete(x.right, key); &#125; else if (cmp &lt; 0) &#123; return delete(x.left, key); &#125; else &#123; /*找到要删除的节点 x*/ /*左子树为null, 返回右子树, x就为null. 会自己被回收*/ if (x.left == null) &#123; return x.right; &#125; /**/ if (x.right == null) &#123; return x.left; &#125; /*要删除的x左右子树都不为null 的情况, 将x保存为t*/ Node t = x; /*找到t右子树最小的node. 赋值给x*/ x = min(t.right); x.right = deleteMin(t.right); x.left = t.left; &#125; /*重新计算x的节点数量*/ x.N = size(x.left) + size(x.right) + 1; return x; &#125; public void delete(Key key) &#123; root = delete(root, key); &#125; public Iterable&lt;Key&gt; keys() &#123; return keys(min(), max()); &#125; public Iterable&lt;Key&gt; keys(Key lo, Key hi) &#123; if (lo == null) &#123; throw new IllegalArgumentException("first argument to keys() is null"); &#125; if (hi == null) &#123; throw new IllegalArgumentException("second argument to keys() is null"); &#125; Queue&lt;Key&gt; queue = new Queue&lt;&gt;(); keys(root, queue, lo, hi); return queue; &#125; private void keys(Node x, Queue&lt;Key&gt; queue, Key lo, Key hi) &#123; if (x == null) &#123; return; &#125; int cmplo = lo.compareTo(x.key); int cmphi = hi.compareTo(x.key); if (cmplo &lt; 0) &#123; keys(x.left, queue, lo, hi); &#125; if (cmplo &lt;= 0 &amp;&amp; cmphi &gt;= 0) &#123; queue.enqueue(x.key); &#125; if (cmphi &gt; 0) &#123; keys(x.right, queue, lo, hi); &#125; &#125;&#125; 插入实现逻辑和递归查找非常相似, 如果树是空的. 就返回一个含有该键值对的新节点, 如果被查找的键小于根节点的键, 继续在做子树中插入该键, 否则在右子树中插入该键. 最大值和最小值如果根节点的左链接为空. 那么一颗二叉查找树最小值就是根节点; 如果左节点非空. 那么树中的最小键就是左子树的最小键 最大键也是类似的. 只不过去查找右子树. 向上取整和向下取整如果给定的键key小于二叉查找树的根节点的键. 那么小于等于key的最大键floor(key)一定在根节点的左子树上; 如果给定的键key大于二叉查找树的根节点 那么只有当根节点右子树中存在小于等于key的节点时, 小于等于key的最大键才会出现右子树中, 否则根节点就是小于等于key的最大键.ceiling() 正好相反. 选择操作假如我们想找到排名为k的键, 那么左子树中的节点数t大于k,那么我们就继续在左子树中查询排名为k的键, 如果t等于k, 我们就返回根节点中的键.如果t小于k, 我们就在右子树中查找排名为(t-k-1)的键. 排名rank()和select()是逆方法, 它会返回给定键的排名. 它的实现和select()类似. 如果给定的键和根节点的键相等. 我们返回左子树中的节点总和t; 如果给定的键下于根节点. 我们会返回该键在左子树中的排名. 如果给定的键大于根节点, 我们返回t+1加上它的右子树中的排名. 删除最小键和最大键不断深入根节点的左子树中直到遇见一个空链接. 然后将指向该节点的链接指向该节点的右子树即可.此时已经没有任何链接指向要删除的节点, 他会被垃圾收集器清理掉. 删除操作 将指向即将被删除的节点的链接保存为t 将x指向它的后继节点min(t.right) 将x的右链接(原本指向一颗所有节点都大于x.key的二叉查找树) 指向deleteMin(t.right), 也就是在删除后所有节点任然都大于x.key的子二叉查找树. 将x的左链接(本为空)设为t.left(其下所有的键都小于被删除的节点和它的后继节点) 优缺点提供了高效的rank() select() delete()以及范围查找等操作, 但这些都要求随机键构造的二叉查找树. 如果是有序键构造的二叉查找树和数组没区别.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[符号表]]></title>
    <url>%2F2019%2F03%2F25%2F%E7%AC%A6%E5%8F%B7%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[符号表符号表的主要目的就是将一个键和一个值联系起来. 典型的符号表应用: 应用 查找目的 键 值 字典 找出单词的释义 单词 释义 图书索引 找出相关的页码 术语 一串页码 文件共享 找出歌曲的下载地址 歌曲名 计算机ID 账户管理 处理交易 账户号码 交易详情 网络搜索 找出相关网页 关键字 网页名称 编译器 找出符号的类型和值 变量名 类型和值 API符号表是一种典型的抽象数据结构. 代表了一组定义清晰的值以及相应的操作, 使得我们能够将类型的实现和使用区分开. public class ST&lt;Key,Value&gt; ST() 创建一张符号表 void put(Key key, Value val) 将键值对存入表中, 若值为空则将键key从表中删除 Value get(Key key) 获取键Key对象的值, 若键key不存在则返回null void delete(Key key) 从表中删除key及相应的值 boolean contains(Key key) 键key在表中是否有对应的值 boolean isEmpty() 表是否为空 int size() 表中键值对的数量 Iterable keys() 表中所有键的集合 约定 每个键值对应着一个值 不允许出现重复的键 当用例代码向表中存入的键值对和表中已有的键冲突. 新值会代替旧值 键不能为null. 值允许为null. 有两个好处(1) 可以用get方法是否返回null测试给定的键是否存在符号表中, 2) 可以将null作为put()方法的第二个参数存入表中来实现删除 删除操作 1) 延时删除. 也就是将键对呀的值设置为null. 2) 立即删除 有序符号表 public class ST&lt;Key,Value&gt; ST() 创建一张符号表 void put(Key key, Value val) 将键值对存入表中, 若值为空则将键key从表中删除 Value get(Key key) 获取键Key对象的值, 若键key不存在则返回null void delete(Key key) 从表中删除key及相应的值 boolean contains(Key key) 键key在表中是否有对应的值 boolean isEmpty() 表是否为空 int size() 表中键值对的数量 Key min() 最小的键 Key max() 最大的键 Key floor(Key key) 小于等于key的最大值 Key ceiling(Key key) 大于等于key的最小值 int rank(Key key) 小于key的键的数量 Key select(int k) 排名为k的键 void deleteMin() 删除最小的键 void deleteMax() 删除最大的键 int size(Key lo, Key hi) [lo….hi]之间键的数量 Iterable keys(Key lo, Key hi) [lo….hi]之间键的所有键, 已排序 Iterable keys() 表中所有键的集合, 已排序 顺序查找(无序链表)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111/** * 基于无序链表(顺序查找) * 基于链表的实现以及顺序查找是非常低效的 * * @author Darcy * Created By Darcy on 2019-03-12 15:32 */public class SequentialSearchST&lt;K, V&gt; &#123; public SequentialSearchST() &#123; &#125; private class Node &#123; K key; V value; Node next; public Node(K key, V value, Node next) &#123; this.key = key; this.value = value; this.next = next; &#125; &#125; private Node first; private int N; /** * 通过key查询value. 没有返回null * * @param key key * @return value */ public V get(K key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to get() is null&quot;); &#125; for (Node x = first; x != null; x = x.next) &#123; if (key.equals(x.key)) &#123; return x.value; &#125; &#125; return null; &#125; /** * 关联key-value * key已经存在替换value 不存在插入表头 * * @param key key * @param value value */ public void put(K key, V value) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;first argument to put() is null&quot;); &#125; if (value == null) &#123; delete(key); return; &#125; for (Node x = first; x != null; x = x.next) &#123; if (key.equals(x.key)) &#123; x.value = value; return; &#125; &#125; first = new Node(key, value, first); N++; &#125; public int size() &#123; return N; &#125; public void delete(K key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to delete() is null&quot;); &#125; first = delete(first, key); &#125; /** * 递归确定x是否是要删除的节点 * true: first = x.next * false: 继续递归下一个节点(x.next) * * @param x 当前节点 * @param key key * @return 链表头 */ private Node delete(Node x, K key) &#123; if (x == null) &#123; return null; &#125; if (key.equals(x.key)) &#123; N--; return x.next; &#125; x.next = delete(x.next, key); return x; &#125; public Iterable&lt;K&gt; keys() &#123; Queue&lt;K&gt; queue = new Queue&lt;&gt;(); for (Node x = first; x != null; x = x.next) &#123; queue.enqueue(x.key); &#125; return queue; &#125;&#125; 基于链表的实现以及顺序查找是非常低效的. 有序数组中二分查找123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174public class BinarySearchST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; &#123; private Key[] keys; private Value[] values; private int N; public BinarySearchST(int capacity) &#123; keys = (Key[]) new Comparable[capacity]; values = (Value[]) new Comparable[capacity]; &#125; public int size() &#123; return N; &#125; public Value get(Key key) &#123; if (isEmpty()) &#123; return null; &#125; int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) &#123; return values[i]; &#125; else &#123; return null; &#125; &#125; public void put(Key key, Value value) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;first argument to put() is null&quot;); &#125; if (value == null) &#123; delete(key); return; &#125; int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) &#123; values[i] = value; return; &#125; if (N == keys.length) &#123; resize(2 * keys.length); &#125; for (int j = N; j &gt; i; j--) &#123; keys[j] = keys[j - 1]; values[j] = values[j - 1]; &#125; keys[i] = key; values[i] = value; N++; &#125; public int rank(Key key) &#123; int lo = 0; int hi = N - 1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) &#123; hi = mid - 1; &#125; else if (mid &gt; 0) &#123; lo = mid + 1; &#125; else &#123; return mid; &#125; &#125; return lo; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public Key min() &#123; return keys[0]; &#125; public Key max() &#123; return keys[N - 1]; &#125; public Key select(int k) &#123; return keys[k]; &#125; public Key ceiling(Key key) &#123; int i = rank(key); return keys[i]; &#125; public Key floor(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to floor() is null&quot;); &#125; int i = rank(key); if (i &lt; N &amp;&amp; key.compareTo(keys[i]) == 0) &#123; return keys[i]; &#125; if (i == 0) &#123; return null; &#125; else &#123; return keys[i - 1]; &#125; &#125; public void delete(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to delete() is null&quot;); &#125; if (isEmpty()) &#123; return; &#125; int i = rank(key); if (i == N || keys[i].compareTo(key) != 0) &#123; return; &#125; for (int j = i; j &lt; N - 1; j++) &#123; keys[j] = keys[j + 1]; values[j] = values[j + 1]; &#125; N--; keys[N] = null; values[N] = null; if (N &gt; 0 &amp;&amp; N == keys.length / 4) &#123; resize(keys.length / 2); &#125; &#125; private void resize(int capacity) &#123; Key[] tempk = (Key[]) new Comparable[capacity]; Value[] tempv = (Value[]) new Object[capacity]; for (int i = 0; i &lt; N; i++) &#123; tempk[i] = keys[i]; tempv[i] = values[i]; &#125; values = tempv; keys = tempk; &#125; public boolean contains(Key key) &#123; if (key == null) &#123; throw new IllegalArgumentException(&quot;argument to contains() is null&quot;); &#125; return get(key) != null; &#125; public Iterable&lt;Key&gt; keys(Key lo, Key hi) &#123; if (lo == null) &#123; throw new IllegalArgumentException(&quot;first argument to keys() is null&quot;); &#125; if (hi == null) &#123; throw new IllegalArgumentException(&quot;second argument to keys() is null&quot;); &#125; Queue&lt;Key&gt; queue = new Queue&lt;Key&gt;(); if (lo.compareTo(hi) &gt; 0) &#123; return queue; &#125; for (int i = rank(lo); i &lt; rank(hi); i++) &#123; queue.enqueue(keys[i]); &#125; if (contains(hi)) &#123; queue.enqueue(keys[rank(hi)]); &#125; return queue; &#125;&#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小米面试题:一副从1到n的牌..]]></title>
    <url>%2F2018%2F07%2F31%2F%E5%B0%8F%E7%B1%B3%E9%9D%A2%E8%AF%95%E9%A2%98-%E4%B8%80%E5%89%AF%E4%BB%8E1%E5%88%B0n%E7%9A%84%E7%89%8C%2F</url>
    <content type="text"><![CDATA[最近在网上看到一个有意思的面试题. 一副从1到n的牌，每次从牌堆顶取一张放桌子上，再取一张放牌堆底，直到手机没牌，最后桌子上的牌是从1到n有序，设计程序，输入n，输出牌堆的顺序数组 微软的大神给一个解题思路.搜索了一下网上的答案,发现没有找到正确的答案.大多数答案在n=奇数的时候正确.在n=偶数的时候是错误的. 我把这道题看成是一个,给出有序集合例如:{1,2,3,4,5,6},求解原始集合{1,4,2,6,3,5}的过程. 我用最笨的办法拿带数字小纸片演练了n={1…10}的所有情况. 最后发现了一个小规律. index从0开始, 原始集合的所有偶数位置是有序的. 区别在于奇数位置的顺序 例如6, 那么6以内的偶数index是 0,2,4.就直接对应 1,2,3. 剩下的index奇数为 1,3,5.和数组 4,5,6的对应关系. 也分两种情况: 当n=偶数时, 第一个奇数index直接拿出来用. 然后在放队尾.如此往复 当n=奇数时, 第一个奇数index要放入队尾, 然后取出用. 如此往复 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 例如n=6 &#123;1,2,3,4,5,6&#125; * * @param n 初始化n的有序集合 * @return 有序集合 */ private static int[] initA(int n) &#123; int[] init = new int[n]; for (int i = 0; i &lt; n; i++) &#123; init[i] = i + 1; &#125; return init; &#125; /** * 例如n=6 &#123;1,2,3,4,5,6&#125; * * @param n 目标集合个数 * @return 原始集合 &#123;1,4,2,6,3,5&#125; * @throws InterruptedException 异常 */ public static int[] test(int n) throws InterruptedException &#123; List&lt;Integer&gt; a = new ArrayList&lt;&gt;(); int[] init = initA(n); BlockingQueue&lt;Integer&gt; uu = new ArrayBlockingQueue&lt;&gt;(n); for (int i = 0; i &lt; n; i++) &#123; if (i % 2 == 0) &#123; a.add(i); &#125; else &#123; uu.add(i); &#125; &#125; while (!uu.isEmpty()) &#123; if (uu.size() == 1) &#123; a.add(uu.take()); &#125; else &#123; if (init.length % 2 == 0) &#123; a.add(uu.take()); uu.add(uu.take()); &#125; else &#123; uu.add(uu.take()); a.add(uu.take()); &#125; &#125; &#125; return print(a, init); &#125; /** * 例如n=6 a=&#123;0,2,4,1,5,3&#125; init=&#123;1,2,3,4,5,6&#125; * * @param a 原始集合的index序列 * @param init 有序集合 * @return 原始集合 */ private static int[] print(List&lt;Integer&gt; a, int[] init) &#123; int[] f = new int[a.size()]; for (int i = 0; i &lt; a.size(); i++) &#123; f[a.get(i)] = init[i]; &#125; return f; &#125; public static void main(String[] args) throws InterruptedException &#123; int[] print = Test.test(6); for (int a : print) &#123; System.out.print(a + &quot; &quot;); &#125; &#125; 如果有错误希望邮件给我指出.不胜感激,谢谢.如果有大神有更好的解题代码.希望通过邮件联系我.谢谢.]]></content>
      <categories>
        <category>exercise</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TreeMap和红黑树]]></title>
    <url>%2F2018%2F07%2F27%2FTreeMap%E5%92%8C%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[介绍这篇文章会解析TreeMap的源码.顺便试着说说红黑树 Java TreeMap实现了SortedMap接口，也就是说会按照key的大小顺序对Map中的元素进行排序，key大小的评判可以通过其本身的自然顺序（natural ordering），也可以通过构造时传入的比较器（Comparator）。 TreeMap底层通过红黑树（Red-Black tree）实现，也就意味着containsKey(), get(), put(), remove()都有着log(n)的时间复杂度。 红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一陪。具体来说，红黑树是满足如下条件的二叉查找树（binary search tree）： 每个节点要么是红色，要么是黑色。 根节点必须是黑色 红色节点不能连续（也即是，红色节点的孩子和父亲都不能是红色）。 对于每个节点，从该点至null（树尾端）的任何路径，都含有相同个数的黑色节点。 预备知识树的旋转如果了解过 AVL树 的同学,对于树的旋转应该不会陌生. 另外红黑树不会出现双旋转的情况, 所以简单的单旋转就可以. 但是和AVL树不同的是红黑树还需要颜色调整 左旋左旋就是X的右子树Y,绕着X逆时针旋转.使得Y成为X的父亲.Y的左节点顺势成为X的右节点. 二叉树性质不变 123456789101112131415161718/** From CLR */ private void rotateLeft(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; r = p.right; p.right = r.left; if (r.left != null) r.left.parent = p; r.parent = p.parent; if (p.parent == null) root = r; else if (p.parent.left == p) p.parent.left = r; else p.parent.right = r; r.left = p; p.parent = r; &#125; &#125; 右旋右旋就是Y的左子树X,绕着Y顺时针旋转.使得X成为Y的父亲.X的右节点顺势成为Y的左节点. 二叉树性质不变 123456789101112131415private void rotateRight(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; l = p.left; p.left = l.right; if (l.right != null) l.right.parent = p; l.parent = p.parent; if (p.parent == null) root = l; else if (p.parent.right == p) p.parent.right = l; else p.parent.left = l; l.right = p; p.parent = l; &#125; &#125; 具体方法get()根据二叉查找树的性质可知.比当前节点小的 在左子树,比当前节点大的 在右子树. 一直循环直到相等(找到)或者p=null(不存在的key) 123456789101112131415161718192021222324252627282930313233343536373839final Entry&lt;K,V&gt; getEntry(Object key) &#123; // 使用自定义的比较器 查找 if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; //自然循序 Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null; &#125; final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) &#123; @SuppressWarnings("unchecked") K k = (K) key; Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = cpr.compare(k, p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; &#125; return null; &#125; put()首先需要确定数据该插入的位置. 如果插入之后破坏了红黑树的约束，还需要进行调整（旋转，改变某些节点的颜色）。 情况 4,5,6.和1,2,3是对称. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; //如果树是空的.key就是根节点 if (t == null) &#123; compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // 用户自己自定义的比较器查找 Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // 使用自然顺序查找 else &#123; if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent);//创建并插入新的entry if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e);//调整 size++; modCount++; return null; &#125; /** From CLR */ private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); // 情况1 if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; else &#123; // 情况2 if (x == rightOf(parentOf(x))) &#123; x = parentOf(x); rotateLeft(x); &#125; // 情况3 setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateRight(parentOf(parentOf(x))); &#125; &#125; else &#123; Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); // 情况4 if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; else &#123; // 情况5 if (x == leftOf(parentOf(x))) &#123; x = parentOf(x); rotateRight(x); &#125; // 情况6 setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateLeft(parentOf(parentOf(x))); &#125; &#125; &#125; root.color = BLACK; &#125; 寻找后继节点后继节点: 对于一棵二叉查找树，给定节点t，其后继就是,大于t中最小的元素. 方法如下: t的右子树不为null, 那么后继节点就是右子树中最小的元素 t的右子树为null, 找t的祖先.找到一种情况是当前节点是它的父亲节点的左孩子的时候，那么这个父亲节点就是我原始节点的后继节点 123456789101112131415161718static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123; if (t == null) return null; else if (t.right != null) &#123; Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; &#125; else &#123; Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; while (p != null &amp;&amp; ch == p.right) &#123; ch = p; p = p.parent; &#125; return p; &#125; &#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法相关总结和梳理二]]></title>
    <url>%2F2018%2F07%2F24%2F%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%92%8C%E6%A2%B3%E7%90%86%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[排序归并排序优点:能够保证将任意长度为N的数组排序所需时间和NlogN成正比. 缺点: 所需的额外空间和N成正比 这个算法的基本操作是合并两个有序数组.因为这两个表是有序的,所以若将输出放到第三个表中,则该算法可以通过对输入数据一趟排序来完成. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/*额外的空间*/private static Comparable[] aux;/** * 归并排序算法(自顶向下的) * * @param a 需要排序的算法 */ public void sort(Comparable&lt;T&gt;[] a) &#123; aux = new Comparable[a.length]; sort(a, 0, a.length - 1); &#125; private void merge(Comparable[] a, int lo, int mid, int hi) &#123; int i = lo; int j = mid + 1; /*将a数组 复制到aux数组中.*/ for (int k = lo; k &lt;= hi; k++) &#123; aux[k] = a[k]; &#125; for (int k = lo; k &lt;= hi; k++) &#123;y /*左半边用尽, 取右半边*/ if (i &gt; mid) &#123; a[k] = aux[j++]; /*右半边用尽, 取左半边*/ &#125; else if (j &gt; hi) &#123; a[k] = aux[i++]; /*右半边的当前元素小于左半边的当前元素 取右半边的元素*/ &#125; else if (less(aux[j], aux[i])) &#123; a[k] = aux[j++]; /*右半边的当前元素大于等于左半边的当前元素, 取左半边的元素*/ &#125; else &#123; a[k] = aux[i++]; &#125; &#125; &#125; private void sort(Comparable[] a, int lo, int hi) &#123; if (lo &lt;= hi) &#123; return; &#125; int mid = lo + (hi - lo) / 2; /*将左半边排序*/ sort(a, lo, mid); /*将右半边排序*/ sort(a, mid + 1, hi); /*归并结果*/ merge(a, lo, mid, hi); &#125; 快速排序快速排序是一种分治的排序算法.它将一个数组分成两个子数组.将两部分独立地排序.快速排序和归并排序是互补的. 归并排序将数组分成两个子数组分别排序.并将有序的子数组归并以将整个数组排序. 快速排序将数组排序的方式则是当两个子数组都有序时整个数组也就自然有序了. 快速排序的的关键点 切分 对于某个j,a[j]已经排定 a[lo]到a[j-1]中所有元素都不大于a[j] a[j+1]到a[hi]中的所有元素都不小于a[j] 先随意地取a[lo]作为切分元素.即那个将会被排定的元素,然后我们从数组的左端开始向右扫描直到找到一个大于等于它的元素.再从数组的右端开始向左扫描直到找到一个小于等他它的元素.交换它们的位置.如此继续.我们就可以保证左指针i的左侧元素都不大于切分元素,右指针j的右侧元素都不小于切分元素.当两个指针相遇,我们只需要将切分元素a[lo]和左子数组最右侧的元素(a[i])交换然后返回j即可. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) &#123; return; &#125; int j = partition(a, lo, hi); sort(a, lo, j - 1); sort(a, j + 1, hi); assert isSorted(a, lo, hi);&#125; /** * 切分数组 * 切分数组 a[lo..hi] 要达成 a[lo..j-1] &lt;= a[j] &lt;= a[j+1..hi] */ private static int partition(Comparable[] a, int lo, int hi) &#123; /*扫描左右的指针*/ int i = lo; int j = hi + 1; /*切分的元素*/ Comparable v = a[lo]; while (true) &#123; /*找到切分元素v小的i索引*/ while (less(a[++i], v)) &#123; if (i == hi) &#123; break; &#125; &#125; /*找到比切分元素v大的索引j*/ while (less(v, a[--j])) &#123; if (j == lo) &#123; break; &#125; &#125; /*检测i和j 防止交叉*/ if (i &gt;= j) &#123; break; &#125; /*交换i,j的位置, 实现 小元素在v的左边, 大元素在v的右边 大小是相对v的*/ exch(a, i, j); &#125; /*最后交换切分元素v和j的位置*/ exch(a, lo, j); /*a[lo .. j-1] &lt;= a[j] &lt;= a[j+1 .. hi] 完成*/ return j; &#125; 优点: 切分方法的内循环会用递增的索引将数组元素和一个定值比较, 这是很简洁的, 很难找出排序算法中还有比更短小的内循环了. 速度优势在于他的比较次数很少. 最好的情况是每次都是正好能将数组对半分. 缺点:最差的情况是 切分不平衡时, 例如 第一次从最小的元素切分. 第二次从第二小的元素切分. 从此这般,每次调用只会移除一个元素. 我们要在快速排序前将数组随机排序的主要原因就是避免这种情况. 总的来说, 对于大小为N的数组. 标准的快速排序的运行时间在1.39NlgN的某个常数因子的范围之内. 归并排序也能做到这一点. 但是快速排序一般会更快. 因为他移动更少. 改进切换到插入排序 对于小数组, 快速排序比插入排序慢. 因为递归, 快速排序的sort()方法在小数组中也会调用自己. 因此,在排序小数组时应该切换到插入排序,将 1if (hi &lt;= lo) return; 替换成 1if(hi &lt;= lo + M) &#123; Insertion.sort(a, lo, hi); return;&#125; M 的最佳值和系统相关的, 但是5~15直接的任意值在大多数情况下都能令人满意. 三取样切分一个想法是将数组切分为三部分.分别对应小于,等于和大于切分元素的数组元素.它从左到右遍历数组一次.维护一个指针lt使得a[lo..lt-1]中的元素都小于v,一个指针gt使得a[gt+1..hi]中元素都大于v,一个指针i使得a[lt..i-1]中的元素都等于v,a[i..gt]中的元素还未确定.开始i和lo相等.我们使用Comparable接口对a[i]进行三向比较来直接处理以下情况: a[i]小于v, 将a[lt]和a[i]交换.将lt和i加1 a[i]大于v, 将a[gt]和a[i]交换,将gt减1 a[i]等于v, 将i加1 1234567891011121314151617181920212223242526272829public static void sort(Comparable[] a) &#123; StdRandom.shuffle(a); sort(a, 0, a.length - 1); assert isSorted(a); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) &#123; return; &#125; int lt = lo, gt = hi; Comparable v = a[lo]; int i = lo + 1; while (i &lt;= gt) &#123; int cmp = a[i].compareTo(v); if (cmp &lt; 0) &#123; exch(a, lt++, i++); &#125; else if (cmp &gt; 0) &#123; exch(a, i, gt--); &#125; else &#123; i++; &#125; &#125; // a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]. sort(a, lo, lt - 1); sort(a, gt + 1, hi); assert isSorted(a, lo, hi); &#125; 对于包含大量重复元素的数组, 它将排序时间从线性对数级降到了线性级别. 这和元素的排列顺序没有关系. 因为算法会在排序之前将其打乱避免最坏的情况. 这种对重复元素的适应性使得三向切分的快速排序成为了排序库函数的最佳算法选择.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法相关总结和梳理一]]></title>
    <url>%2F2018%2F07%2F20%2F%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%92%8C%E6%A2%B3%E7%90%86%E4%B8%80%2F</url>
    <content type="text"><![CDATA[散列 理想的散列表数据结构只不过是包含一些项的具有固定大小数组,通常查找是对项的的某个部分进行的.这部分就叫做关键字(Key). 通过散列函数算出目标数组中的索引.会出现相同索引的情况.这种情况叫冲突 解决冲突的方案拉链法. 就是将散列到同一个值得所有元素保留到一个表里.JDK标准库就是这么实现的.查找分两步.首先根据散列值找到对应的链表,然后沿着链表顺序查找相应的键. 开放地址法 最简单的方案是 线性探测法 , 当发生碰撞时,我们直接检查散列表中下一个位置(索引+1).这样的线性探测可能产生三种情况 命中. 该位置的键和被查找的键相同 未命中. 键为空 继续查找. 该位置的键和被查找的键不同 优先队列(堆)模型 insert(插入) 插入队列 deleteMin(删除最小者) 它的工作是找出.返回并删除优先队列中的最小元素.二叉堆 堆是一个被完全填满的二叉树,有可能的例外是底层.底层的元素从左到右填入,这样的树称为完全二叉树.因为完全二叉树这么有规律.所以它可以用一个数组表示而不需要使用链. 对于数组中任一位置i上的元素.其左儿子在位置2i上,右儿子在左儿子后的单元2i+1中.它的父亲则在位置i/2上. 堆序性质 由于我们想要快速找出最小元素.因此最小元素在根上. 基本操作 insert 我们将元素插入数组末尾,如果X可以放在这而并不破坏堆的序,那么插入完成,否则,我们将该位置的值和父节点的值互换.这样X就向上冒了一步.继续该过程指导X不破坏堆有序为止. deleteMin 找出最小元素容易.困难之处在于删除它.当删除最小元素后.根节点就出现了空穴.然后我们将堆的最后一个元素X,试图插入空穴.如果不破坏堆有序.那么完成.基本不大可能完成.因此我们将空穴的儿子节点中较小的元素移入空穴.这样我们将空穴向下推了一层.重复该步骤直到X可以被放入空穴.我们管这一个策略叫 下滤 buildHeap 有时候二叉堆是有一些项的初始集合构造而得的. 做法是将N项以任意顺序放入树中,保持结构特性.然后在让每个父节点下滤.任意一个元素的父节点都是i/2; d-堆二叉堆是很简单的.以至于他们几乎总是用在需要优先队列的时候.d-堆是二叉堆的简单推广.它就像一个二叉堆.只是所有的节点都有d个儿子.因此二叉堆就是2-堆, d-堆要比二叉堆要浅得多.所以insert时间会很快.但是deleteMin操作费时得多,因为虽然树浅了.但是d个儿子中的最小者是必须要找出的. 当优先队列太大而不能完全装入主存的时候.d-堆是很有用的.这种情况下.d-堆能够以与B树大致相同的方式发挥作用. 除了不能实施find外.堆实现的最明显的缺点是:将两个堆合并成一个堆是困难的操作. 左式堆左式堆像二叉堆那样也具有结构性和有序性. 左式堆性质 X的零路径长npl(x)定义为从X到一个不具有两个儿子的节点的最短路径的长. 因此具有0个儿子或者一个儿子的节点的npl为0.而npl(null)=-1. 对于堆中的每一个节点X,左儿子的npl至少与右儿子的npl相等. 合并123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * 合并rhs到优先队列内 * * @param rhs 另外的左式堆 */ public void merge(LeftistHeap&lt;AnyType&gt; rhs) &#123; /*自己不能合并自己*/ if (this == rhs) &#123; return; &#125; root = merge(root, rhs.root); rhs.root = null; &#125; /** * 内部方法合并两个根 * 处理异常情况,并且调用merge1 */ private LeftistNode&lt;AnyType&gt; merge(LeftistNode&lt;AnyType&gt; h1, LeftistNode&lt;AnyType&gt; h2) &#123; if (h1 == null) &#123; return h2; &#125; if (h2 == null) &#123; return h1; &#125; /*将较大根的堆和较小根的右子树合并*/ if (h1.element.compareTo(h2.element) &lt; 0) &#123; return merge1(h1, h2); &#125; else &#123; return merge1(h2, h1); &#125; &#125; /** * 合并两个堆的内部方法 * h1是含有较小根的堆 */ private LeftistNode&lt;AnyType&gt; merge1(LeftistNode&lt;AnyType&gt; h1, LeftistNode&lt;AnyType&gt; h2) &#123; /*较小的h1 是单个节点*/ if (h1.left == null) &#123; h1.left = h2; &#125; else &#123; /*将较大根h2合并到较小根的h1的右子树上*/ h1.right = merge(h1.right, h2); /*如果h1左子树的npl小于右子树的npl*/ if (h1.left.npl &lt; h1.right.npl) &#123; swapChildren(h1); &#125; /*任意一个节点npl都等于它右儿子节点的npl+1*/ h1.npl = h1.right.npl + 1; &#125; return h1; &#125; /** * 交换左右子树 */ private static &lt;AnyType&gt; void swapChildren(LeftistNode&lt;AnyType&gt; t) &#123; LeftistNode&lt;AnyType&gt; tmp = t.left; t.left = t.right; t.right = tmp; &#125; private static class LeftistNode&lt;AnyType&gt; &#123; LeftistNode(AnyType theElement) &#123; this(theElement, null, null); &#125; LeftistNode(AnyType theElement, LeftistNode&lt;AnyType&gt; lt, LeftistNode&lt;AnyType&gt; rt) &#123; element = theElement; left = lt; right = rt; npl = 0; &#125; /** * 数据节点 */ AnyType element; /** * 左儿子 */ LeftistNode&lt;AnyType&gt; left; /** * 右儿子 */ LeftistNode&lt;AnyType&gt; right; /** * 零路径长 */ int npl; &#125; 排序选择排序找到数组中最小的那个元素, 其次, 将它和数组第一个元素交换位置. 再次, 在剩下的元素中找到最小的元素, 将它与数组的第二个元素交换位置, 如此往复. 直到将整个数组排序, 运行时间和输入无关, 不管你输入的元素是否有序. 运行时间不会改变. 数据移动是最少的. 选择排序用了N次交换, 交换的次数和数组的大小是线性关系, 123456789101112131415161718192021222324public void sort(Comparable&lt;T&gt;[] a) &#123; final int n = a.length; for (int i = 0; i &lt; n; i++) &#123; int min = i; /*内层循环从i+1开始, 查找比min小的j, 如果找不到i就是最小的*/ for (int j = i + 1; j &lt; n; j++) &#123; if (less(a[j], a[min])) &#123; min = j; &#125; &#125; /*交换当前i和min的位置*/ exch(a, i, min); &#125;&#125;void exch(Comparable&lt;T&gt;[] a, int i, int j) &#123; Comparable&lt;T&gt; t = a[i]; a[i] = a[j]; a[j] = t;&#125;boolean less(Comparable&lt;T&gt; v, Comparable&lt;T&gt; w) &#123; return v.compareTo((T) w) &lt; 0;&#125; 插入排序将一个元素插入到有序集合中.(当集合中只有一个元素时,他是有序的). 在计算机实现中, 为了给要插入的元素腾出空间. 我们需要将其余元素咋插入之前都向右移动一位. 和选择排序不同. 插入排序所需的时间取决于输入中元素的初始顺序.典型的部分有序数组: 数组中每个元素距离它的最终位置都不远 一个有序的大数组接一个小数组 数组中只有几个元素的位置不正确 1234567891011121314151617181920212223/** * 插入排序 * * @param arr 目标数组 */ public void sort(Comparable&lt;T&gt;[] arr) &#123; final int n = arr.length; for (int i = 1; i &lt; n; i++) &#123; for (int j = i; j &gt; 0 &amp;&amp; less(arr[j], arr[j - 1]); j--) &#123; exch(arr, j, j - 1); &#125; &#125; &#125; void exch(Comparable&lt;T&gt;[] a, int i, int j) &#123; Comparable&lt;T&gt; t = a[i]; a[i] = a[j]; a[j] = t; &#125; boolean less(Comparable&lt;T&gt; v, Comparable&lt;T&gt; w) &#123; return v.compareTo((T) w) &lt; 0; &#125; 由于嵌套循环每一个都花费N次迭代.因此插入排序O(N平方).另一方面,如果输入数据已预先排序.那么运行时间是O(N),因为内层for循环的检测总是立即判定不成立而终止.事实上,如果输入集合几乎被排序,那么插入排序将运行的很快. 希尔排序希尔排序就是基于插入排序完成的.各趟比较所用的距离随着算法的进行而减小,直到只比较相邻元素的最后一趟排序为止.希尔排序使用一个序列h1,h2,….hi,叫做增量序列.可以理解为: 对于每个h,用插入排序将h个子数组独立的排序.但因为子数组是相互独立的.一个更简单的方法是在h-子数组中将每个元素交换到比它大的元素之前去,只需要在插入排序的代码中将移动元素的距离由1改为h即可. 希尔排序高效的原因在于是它权衡了子数组的规模和有序性 1234567891011121314151617181920212223242526272829303132/** * 增量序列:h = 3h+1 的希尔排序. * 对h个独立的子数组执行一次插入排序. * * @param a 目标数组.需要排序的数组 */ public void sort(Comparable&lt;T&gt;[] a) &#123; final int n = a.length; int h = 1; while (h &lt; n / 3) &#123; h = 3 * h + 1; &#125; while (h &gt;= 1) &#123; for (int i = h; i &lt; n; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j - h]); j -= h) &#123; exch(a, j, j - h); &#125; h = h / 3; &#125; &#125; &#125; boolean less(Comparable&lt;T&gt; v, Comparable&lt;T&gt; w) &#123; return v.compareTo((T) w) &lt; 0; &#125; void exch(Comparable&lt;T&gt;[] a, int i, int j) &#123; Comparable&lt;T&gt; t = a[i]; a[i] = a[j]; a[j] = t; &#125; 堆排序优先队列提供了一个思路,每次执行deleteMin操作.按照顺序,最小的元素先离开堆.通过将这些元素记录到第二个数组然后在将数组拷贝回来,得到N个元素的排序.由于每个deleteMin花费时间O(logN),因此总的运行时间是O(NlogN). 问题在于使用了附加数组.存储要求增加了一倍.回避使用第二个数组的方法是利用.每次deleteMin之后,堆缩小1.因此,位于堆中最后的单元可以用来存放刚刚删去的元素.但是基于这个方案,我们实现的排序是倒序的.因此需要实现Max堆.根节点是最大元素. 另外需要注意的二叉堆是从1索引开始的.这里的堆是从0索引开始的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 计算堆左儿子节点位置 * * @param i 节点索引 * @return 左儿子节点位置 */private static int leftChild(int i) &#123; return 2 * i + 1;&#125;/** * 堆内方法,恢复堆有序的方法 * * @param a 素组 * @index i 需要下滤的位置 * @int n 堆的大小 */private static &lt;AnyType extends Comparable&lt;? super AnyType&gt;&gt;void percDown(AnyType[] a, int i, int n) &#123; /*孩子节点索引*/ int child; /*需要下滤的值*/ AnyType tmp; /*构建二叉堆,max堆*/ for (tmp = a[i]; leftChild(i) &lt; n; i = child) &#123; /*找到当前i的左孩子节点*/ child = leftChild(i); /*如果child不是末尾,并且左儿子小于右儿子 child自增1*/ if (child != n - 1 &amp;&amp; a[child].compareTo(a[child + 1]) &lt; 0) &#123; child++; &#125; /*目标数据比child小*/ if (tmp.compareTo(a[child]) &lt; 0) &#123; /*大值上浮*/ a[i] = a[child]; &#125; else &#123; break; &#125; &#125; /*i是tmp在树有序的位置*/ a[i] = tmp;&#125;/** * 堆排序算法 最大堆,有序指的是 当一个颗二叉树的每个节点都大于等于它的两个子节点时,它被称为堆有序 * 每次deleteMax后 堆都缩小1,将删除的最大元素放入.依次类推, 这要就完成排序了 * * @param a 需要排序的数组 */public static &lt;AnyType extends Comparable&lt;? super AnyType&gt;&gt;void heapsort(AnyType[] a) &#123; /* buildHeap */ for (int i = a.length / 2 - 1; i &gt;= 0; i--) &#123; percDown(a, i, a.length); &#125; /* deleteMax */ for (int i = a.length - 1; i &gt; 0; i--) &#123; /*根节点和最后一个元素交换位置 相当于deleteMax*/ swapReferences(a, 0, i); /*将破坏堆有序的元素(即刚才交换到根节点的元素)下滤*/ percDown(a, 0, i); &#125;&#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表和双向链表]]></title>
    <url>%2F2018%2F07%2F17%2F%E5%8D%95%E9%93%BE%E8%A1%A8%E5%92%8C%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[单链表(可以用来实现栈和队列)12345678910private class Node &#123; /** * 链表存储的数据(泛型) */ Item item; /** * 指向下一个节点的指针 */ Node next;&#125; 删除链表的元素 添加元素 双向链表(实现LinkedList)1234567891011121314151617181920212223242526272829/** * 链表节点 * @param &lt;AnyType&gt; */ private static class Node&lt;AnyType&gt; &#123; /** * @param d 数据 * @param p 上一个节点 * @param n 下一个节点 */ public Node(AnyType d, Node&lt;AnyType&gt; p, Node&lt;AnyType&gt; n) &#123; data = d; prev = p; next = n; &#125; /** * 数据 */ public AnyType data; /** * 上一个节点 */ public Node&lt;AnyType&gt; prev; /** * 下一个节点 */ public Node&lt;AnyType&gt; next; &#125; 添加元素 123456789101112131415161718/** * 向目标元素p之前插入x * * @param p 目标p * @param x 插入的元素 */private void addBefore(Node&lt;AnyType&gt; p, AnyType x) &#123; /*构建一个新node,prev是p.prev,next是p 1,3*/ Node&lt;AnyType&gt; newNode = new Node&lt;&gt;(x, p.prev, p); /*新node的上一个节点的next 指向自己 2*/ newNode.prev.next = newNode; /*p的prev 指向自己 4*/ p.prev = newNode; theSize++; modCount++;&#125; 删除元素 12345678910111213/** * 删除目标节点 * * @param p 目标节点 * @return 删除的数据 */private AnyType remove(Node&lt;AnyType&gt; p) &#123; p.next.prev = p.prev; p.prev.next = p.next; theSize--; modCount++; return p.data;&#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法相关总结和梳理]]></title>
    <url>%2F2018%2F07%2F17%2F%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%92%8C%E6%A2%B3%E7%90%86%2F</url>
    <content type="text"><![CDATA[表, 栈和队列表list ADT有两种流行的实现方式,在JDK中都有体现, ArrayList类提供了List ADT的一种可增长数组的实现.使用ArrayList的优点在于,对get和set的调用花费常数时间,其缺点是新项的插入和现有项的删除代价昂贵,除非变动是在数组的末端进行. LinkedList类则提供了List ADT双链表实现,使用LinkedList的优点在于,新项的插入和现有项的删除均开销很小.这里假设变动项的位置是已知的,这意味着,在表的前端添加和删除都是常数时间的操作,由此LinkedList提供了方法addFirst removeFirst addLast removeLast以及getFirst和getLast等以有效的添加和删除和访问表两端项.使用LinkedList的缺点是它不容易做索引.因此对get的调用时昂贵的.除非调用非常接近表的两端. 栈ADT栈的两种实现方式 链表实现. 单项链表: 通过在表的前端插入实现push,通过删除表的顶端实现pop, 所以需要持有first. 数组实现. 数组: 通过向数组尾端插入实现push,删除尾端实现pop. 需要实现一个N,表示栈的深浅.必要的时候需要实现扩容. 队列ADT队列的两种实现方式 数组实现,维护数组元素个数currentSize,和头front,尾back. 链表实现,单项链表,维护数组元素个数currentSize,和头first,尾last. 树树的遍历 先序遍历. 根左右 中序遍历. 左根右 后序遍历. 左右根 查找树ADT(二叉查找树)对于树中的每个节点X,它的左子树中所有项的值小于X中的项.而它的右子树中所有项的值大于X中的项. findMin 从根开始并且只要有左儿子就向左进行,终止点就是最小元素 findMax 从根开始并且只要有右儿子就向右进行,终止点就是最大元素 remove 1. 节点是一片叶子. 那么它可以立即被删除 2. 节点有一个儿子. 该节点可以在其父节点调整自己的链以绕过该节点后被删除. 3. 节点有两个儿子. 用其右子树的最小的数据代替该节点的数据并递归地删除那个节点,insert 为了将X插入到树T中,需要沿树查找,如果找到X,则什么也不做.否则,将X插入到遍历的路径上的最后一点上,(要保证二叉树的性质) contains 如果在树T中存在含有项X的节点,那额这个需要返回true,否则返回false.如果树T是空集,返回false.我们队树T的左子树和右子树进行一次递归调用,这依赖X和存储在T中的项的关系. 缺点: 当把预先拍好序的数据,insert树中,会出现极端情况.树没有左节点或者没有右节点. 一种解决办法就是要有一个称为平衡的附加结构条件:任何节点的深度均不得过深. AVL树AVL树是带有平衡条件的二叉树.(每个节点的左子树和右子树的高度最多差1) 旋转在每一次插入数值之后，树的平衡性都可能被破坏，这时可以通过一个简单的操作来矫正平衡–旋转。 旋转的目的就是减少高度，通过降低整棵树的高度来平衡。哪边的树高，就把那边的树向上旋转。 通过旋转可以降低高度。 所谓的左旋和右旋都是以子树为原点的：如b是a的子树，那么旋转就围绕b来进行。 如果b是a的左子树，那么就围绕b将a向右旋转，看着就像是a直接掉下来了，掉成了b的右子树。 如果b是a的右子树，那么就围绕b将a向左旋转，看着就像是a直接掉下来了，掉成了b的左子树。插入节点时分四种情况，四种情况对应的旋转方法是不同的： 例如对于被破坏平衡的节点 a 来说： 插入方式 描述 旋转方式 LL 在a的左子树根节点的左子树上插入节点而破坏平衡 右旋转 RR 在a的右子树根节点的右子树上插入节点而破坏平衡 左旋转 LR 在a的左子树根节点的右子树上插入节点而破坏平衡 先左旋后右旋 RL 在a的右子树根节点的左子树上插入节点而破坏平衡 先右旋后左旋 单旋转: 看先后插入 3,2,1,4,5,6,7. insert方法构建的过程 双旋转]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写ArrayList]]></title>
    <url>%2F2018%2F06%2F20%2F%E6%89%8B%E5%86%99ArrayList%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124/** * 自己实现的ArrayList * 1 保持基础数组,数组的容量,已经存储在MyArrayList中的当前项数 * 2 提供一种机制以改变基础数组的容量,通过获得一个新数组,将老数组拷贝到新数组中来改变数组的容量,允许虚拟机回收老数组 * 3 提供get和set方法 * 4 提供基本方法 如 size isEmpty clear;还提供remove,已经两种不同版本的add.如果数组的大小和容量相同,那么这两个add都将增加容量 * 5 提供实现Iterator接口类,这个类提供存储迭代序列中的下一项的下标,并提供next hasNext remove等方法实现, * * @author Darcy * Created By Darcy on 2018/6/19 上午11:26 */public class MyArrayList&lt;AnyType&gt; implements Iterable&lt;AnyType&gt; &#123; private static final int DEFAULT_CAPACITY = 10; private int theSize; private AnyType[] theItems; public MyArrayList() &#123; doClear(); &#125; private void doClear() &#123; theSize = 0; ensureCapacity(DEFAULT_CAPACITY); &#125; public void ensureCapacity(int newCapacity) &#123; if (newCapacity &lt; theSize) &#123; return; &#125; AnyType[] old = theItems; theItems = (AnyType[]) new Object[newCapacity]; for (int i = 0; i &lt; size(); i++) &#123; theItems[i] = old[i]; &#125; &#125; public AnyType remove(int idx) &#123; AnyType removeItem = theItems[idx]; for (int i = idx; i &lt; size() - 1; i++) &#123; theItems[i] = theItems[i + 1]; &#125; theSize--; return removeItem; &#125; public boolean add(AnyType x) &#123; add(size(), x); return true; &#125; public void add(int idx, AnyType x) &#123; if (theItems.length == size()) &#123; ensureCapacity(2 * theItems.length); &#125; for (int i = theSize; i &gt; idx; i--) &#123; theItems[i] = theItems[i - 1]; &#125; theItems[idx] = x; theSize++; &#125; public AnyType get(int idx) &#123; if (idx &lt; 0 || idx &gt;= size()) &#123; throw new ArrayIndexOutOfBoundsException(); &#125; return theItems[idx]; &#125; public AnyType set(int idx, AnyType newVal) &#123; if (idx &lt; 0 || idx &gt;= size()) &#123; throw new ArrayIndexOutOfBoundsException(); &#125; AnyType old = theItems[idx]; theItems[idx] = newVal; return old; &#125; public void trimToSize() &#123; ensureCapacity(size()); &#125; public boolean isEmpty() &#123; return size() == 0; &#125; public void clear() &#123; doClear(); &#125; public int size() &#123; return theSize; &#125; @Override public Iterator&lt;AnyType&gt; iterator() &#123; return new ArrayListIterator(); &#125; private class ArrayListIterator implements Iterator&lt;AnyType&gt; &#123; private int current = 0; @Override public boolean hasNext() &#123; return current &lt; size(); &#125; @Override public AnyType next() &#123; if (!hasNext()) &#123; throw new NoSuchElementException(); &#125; return theItems[current++]; &#125; @Override public void remove() &#123; MyArrayList.this.remove(--current); &#125; &#125;&#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写LinkedList]]></title>
    <url>%2F2018%2F06%2F20%2F%E6%89%8B%E5%86%99LinkedList%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189/** * 手写linkList(双向链表实现) * * @author Darcy * Created By Darcy on 2018/6/19 下午3:35 */public class MyLinkedList&lt;AnyType&gt; implements Iterable&lt;AnyType&gt; &#123; /** * 表的大小 */ private int theSize; /** * 从构造以来对链表所做改变的次数 */ private int modCount = 0; /** * 头节点 */ private Node&lt;AnyType&gt; beginMarker; /** * 尾节点 */ private Node&lt;AnyType&gt; endMarker; private static class Node&lt;AnyType&gt; &#123; public Node(AnyType d, Node&lt;AnyType&gt; p, Node&lt;AnyType&gt; n) &#123; data = d; prev = p; next = n; &#125; public AnyType data; public Node&lt;AnyType&gt; prev; public Node&lt;AnyType&gt; next; &#125;&lt;!-- more --&gt; public void clear() &#123; doClear(); &#125; public int size() &#123; return theSize; &#125; public boolean isEmpty() &#123; return size() == 0; &#125; public AnyType get(int idx) &#123; return getNode(idx).data; &#125; public AnyType set(int idx, AnyType newVal) &#123; Node&lt;AnyType&gt; p = getNode(idx); AnyType oldVal = p.data; p.data = newVal; return oldVal; &#125; public boolean add(AnyType x) &#123; add(size(), x); return true; &#125; public void add(int idx, AnyType x) &#123; addBefore(getNode(idx, 0, size()), x); &#125; /** * 获取idx位置节点 * * @param idx 获取node的位置 * @return 节点 */ private Node&lt;AnyType&gt; getNode(int idx) &#123; return getNode(idx, 0, size() - 1); &#125; /** * 获取idx位置的node * * @param idx 索引 * @param lower 开始位置 * @param upper 结束位置 * @return 节点 */ private Node&lt;AnyType&gt; getNode(int idx, int lower, int upper) &#123; Node&lt;AnyType&gt; p; if (idx &lt; lower || idx &gt; upper) &#123; throw new IndexOutOfBoundsException(); &#125; /*判断索引idx的位置,小于size的一半,就从头开始遍历*/ if (idx &lt; size() / 2) &#123; p = beginMarker.next; for (int i = 0; i &lt; idx; i++) &#123; p = p.next; &#125; /*大于size的一半.就从尾部向前遍历*/ &#125; else &#123; p = endMarker; for (int i = size(); i &lt; idx; i--) &#123; p = p.prev; &#125; &#125; return p; &#125; /** * 删除目标节点 * @param p 目标节点 * @return 删除的数据 */ private AnyType remove(Node&lt;AnyType&gt; p) &#123; p.next.prev = p.prev; p.prev.next = p.next; theSize--; modCount++; return p.data; &#125; private void addBefore(Node&lt;AnyType&gt; p, AnyType x) &#123; Node&lt;AnyType&gt; newNode = new Node&lt;&gt;(x, p.prev, p); newNode.prev.next = newNode; p.prev = newNode; theSize++; modCount++; &#125; /** * 清空链表 * 设置头尾节点,并连接起来,设置链表大小为0,操作次数+1 */ private void doClear() &#123; beginMarker = new Node&lt;&gt;(null, null, null); endMarker = new Node&lt;&gt;(null, beginMarker, null); beginMarker.next = endMarker; theSize = 0; modCount++; &#125; @Override public java.util.Iterator&lt;AnyType&gt; iterator() &#123; return new LinkedListIterator(); &#125; private class LinkedListIterator implements java.util.Iterator&lt;AnyType&gt; &#123; private Node&lt;AnyType&gt; current = beginMarker.next; private int expectedModCount = modCount; private boolean okToRemove = false; @Override public boolean hasNext() &#123; return current != endMarker; &#125; @Override public AnyType next() &#123; if (modCount != expectedModCount) &#123; throw new java.util.ConcurrentModificationException(); &#125; if (!hasNext()) &#123; throw new java.util.NoSuchElementException(); &#125; AnyType nextItem = current.data; current = current.next; okToRemove = true; return nextItem; &#125; @Override public void remove() &#123; if (modCount != expectedModCount) &#123; throw new java.util.ConcurrentModificationException(); &#125; if (!okToRemove) &#123; throw new IllegalStateException(); &#125; MyLinkedList.this.remove(current.prev); expectedModCount++; okToRemove = false; &#125; &#125;&#125;]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类和接口]]></title>
    <url>%2F2018%2F05%2F17%2F%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[使类和成员的可访问性最小化设计良好的模块会隐藏所有的实现细节.把它的API与它的实现清晰地隔离开来,然后.模块之间只通过它们的API进行通信,一个模块不需要知道其他模块的内部工作情况,这叫信息隐藏或封装. 封装之所以非常重要有许多原因,其中大多数理由都源于这样一个事实: 它可以有效地接触组成系统的各模块之间的耦合关系.使得这些模块可以独立地开发.测试.优化.使用,理解和修改, 尽可能地是每个类或者成员不被外界访问. 在共有类中使用访问方法而非公有域私有化成员变量,提供setter和getter坚持面向对象程序设计思路的看法是正确的: 如果类可以在它所在的包的外部进行访问.就提供访问方法. 共有类永远都不应该暴漏可变域,虽然还有有问题,但是让共有类暴露不可变的域其危害比较小. 使可变性最小化不可变类只是其实例不能被修改的类.每个实例中包含的所有信息都必须在创建改实例的时候提供.并在对象的整个生命周期内固定不变. 为了使类成为不可变,要遵循五条规则: 不要提供任何会修改对象状态的方法. 保证类不会被拓展 使所有的域都是final的. 使所有的域成为私有的. 确保对于任何可变组件的互斥访问 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public final class Complex &#123; private final double re; private final double im; public Complex(double re, double im) &#123; this.re = re; this.im = im; &#125; public double realPart() &#123; return re; &#125; public double imaginaryPart() &#123; return im; &#125; public Complex add(Complex c) &#123; return new Complex(re + c.re, im + c.im); &#125; public Complex subtract(Complex c) &#123; return new Complex(re - c.re, im - c.im); &#125; public Complex multiply(Complex c) &#123; return new Complex(re * c.re - im * c.im, re * c.im + im * c.re); &#125; public Complex divide(Complex c) &#123; double temp = c.re * c.re + c.im * c.im; return new Complex((re * c.re + im * c.im) / temp, (im * c.re - re * c.im) / temp); &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || getClass() != o.getClass()) &#123; return false; &#125; Complex complex = (Complex) o; return new EqualsBuilder() .append(re, complex.re) .append(im, complex.im) .isEquals(); &#125; @Override public int hashCode() &#123; return new HashCodeBuilder(17, 37) .append(re) .append(im) .toHashCode(); &#125; @Override public String toString() &#123; return new ToStringBuilder(this) .append(&quot;re&quot;, re) .append(&quot;im&quot;, im) .toString(); &#125;&#125; 这个类表示一个复数,除了标准的Object方法之外,它还提供了针对实部和虚部的访问方法,以及4中基本的算术运算,加法,减法,乘法和除法.这些算术运算是创建并返回新的Complex实例,而不是修改这个实例.大多数重要的不可变类都使用了这个模式,他被称为函数(functional)做法. 不可变对象本质上是线程安全的,他们不要求同步在对象从并发访问这样的对象时,他们不会遭到破坏,这无疑是获得线程安全最容易方法,不可变对象可以被自由地共享,不可变类应该充分利用这个优势,鼓励客户端尽可能地重用现有的实例,为了做到这一点,一个简单的方案就是,对于一些常用的值,为他们提供公有的静态final常量.例如: 123public static final Complex ZERO = new Complex(0, 0);public static final Complex ONE = new Complex(1, 0);public static final Complex I = new Complex(0, 1); 不可变类真正唯一的缺点是,对于每个不同的值都需要一个单独的对象.创建这种对象代价可能很高,特别是对于大型对象的情形. 为了确保不可变性,类绝对不允许自身被子类化.除了”使类成为final的”这种方法之外,还有另外一种更加灵活的办法可以做到这一次点,让不可变类变成final的另一种做法是,让类所有构造器都变成私有的或者包级私有的.并添加共有的静态工厂来代替公有的构造器.例如下面的: 123456789101112131415161718public class Complex &#123; public static final Complex ZERO = new Complex(0, 0); public static final Complex ONE = new Complex(1, 0); public static final Complex I = new Complex(0, 1); private final double re; private final double im; private Complex(double re, double im) &#123; this.re = re; this.im = im; &#125; public static Complex valueOf(double re, double im) &#123; return new Complex(re, im); &#125; 为了性能目的.我们可以对所有域都必须是final的要求放宽一些,形成的要求应该是这样的,没有一个方法能够对对象的状态产生外部可见的改变,许多不可变类拥有一个或者多个非final的域.他们在第一次被请求执行这些计算的时候,把一些开销昂贵的结果缓存在这些域中,如果将来再次请求同样的计算,就直接返回这些缓存值,从而节约了重新计算所需要的开销.这种技巧能很好的工作.因为对象是不可变的.它的不可变性保护了这些计算如果被再次执行,产生同样的结果.例如 String类的hash值,在构造String就生产了.缓存起来,等客户调用hashCode()时做个检查就可以了.请看源码 坚决不要为每个get方法编写一个相应的set方法,除非有很好的理由让类变成可变的类,否则就应该是不可变的. 对于有些类而言,其不可变性是不切实际的.如果累不能被做成是不可变的,任然应该尽可能地限制它的可变性. 复合优先于继承]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>Effective Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建和销毁对象]]></title>
    <url>%2F2018%2F05%2F16%2F%E5%88%9B%E5%BB%BA%E5%92%8C%E9%94%80%E6%AF%81%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[考虑用静态工厂方法代替构造器 对于类而言,为了让客户端获取它自身的实例,最常见的就是提供pubic的构造器.还有一个种方案,也应该在工具箱中栈有一席之地,类可以提供一个公有的静态工厂方法.它只是返回一类的实例的静态方法.例如: 123 public static Boolean valueOf(boolean b) &#123; return (b ? TRUE : FALSE);&#125; 提供静态工厂方法而不是共有的构造器,具有很多优势 静态工厂方法有名称. 这样客户端可以更具名称构建不同的实例对象 不必再每次调用它们的时候都创建一个新的对象. 这使得不可变类可以使用预先构建好的实例,或者将构建好的实例缓存起来.进行重复利用.从而避免创建不必要的重复对象. 它们可以返回原返回类型的任何子类型的对象,这样我们在选择返回对象的类时就有了更大的灵活性,例如下面代码: 12345public static &lt;E extends Enum&lt;E&gt;&gt; EnumSet&lt;E&gt; of(E e) &#123; EnumSet&lt;E&gt; result = noneOf(e.getDeclaringClass()); result.add(e); return result; &#125; 遇到多个构造器参数时要考虑用构建器 重叠构造器模式可行.但是当许多参数时候,客户端代码会很难编写.并且任然难以阅读. 还有一种解决方案是JavaBeans模式,提供无参构造器来创建对象,然后调用setter方法来设置每个必要的参数. 缺点也很明显.在构建过程中JavaBean可能处于不一致的状态.这个模式阻止了把类做成不可变的可能. Builder模式. 代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class NutritionFacts &#123; private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; public static class Builder &#123; private final int servingSize; private final int servings; private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; public Builder(int servingSize, int servings) &#123; this.servingSize = servingSize; this.servings = servings; &#125; public Builder calories(int val) &#123; calories = val; return this; &#125; public Builder fat(int val) &#123; fat = val; return this; &#125; public Builder sodium(int val) &#123; sodium = val; return this; &#125; public Builder carbohydrate(int val) &#123; carbohydrate = val; return this; &#125; public NutritionFacts build() &#123; return new NutritionFacts(this); &#125; &#125; private NutritionFacts(Builder builder) &#123; servingSize = builder.servingSize; servings = builder.servings; calories = builder.calories; fat = builder.fat; sodium = builder.sodium; carbohydrate = builder.carbohydrate; &#125; public static void main(String[] args) &#123; NutritionFacts co = new NutritionFacts.Builder(240, 8).calories(1).sodium(2).carbohydrate(34).build(); &#125;&#125; 用私有构造器强化不可实例化的能力 我们需要编写一些只包含静态方法和静态域的类.这些类的名声很不好,因为有些人在面向对象的语言中滥用这样的类编写过程化的程序,但即便如此,他们还是有用途的.我们可以像Math或者Arrays的方式,使用他们. 这样的工具类不需要被实例化.实例它没有任何意义.然而在缺少显示构造器的情况下.编译器会自动添加一个共有,无参的构造器. 我们可以提供一个私有的无参数的构造器,来阻止客户端实例化它. 避免创建不必要的对象最好能重用对象而不是在每次需要的时候就创建一个相同功能的新对象,如果对象是不可变的,它就始终可以被重用. 1String s = new String("Hello"); 该语句每次被执行的时候都创建一个新的String实例,但是这些创建对象的动作全都是不必要的.传递给构造器的参数”Hello”本身就是一个String实例.对于同时提供静态工厂方法和构造器的不可变类,通常可以使用静态工厂方法而不是构造器.以避免创建不必要对象.例如 静态工厂方法Boolean.valueOf(String)几乎总是优先于构造器Boolean(String). 另外在编程中,许多在方法中实例化的对象.可以考虑用static{} 进行初始化.这样可以重用. 要优先使用基本类型而不是装箱的基本类型.要当心无意识的自动装箱.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>Effective Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2018%2F05%2F11%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java内存模型的抽象结构 在Java中,所有实例域,静态域和数据元素都存储在堆内存中,堆内存在线程之间共享, Java线程之间的通信由Java内存模型JMM控制.JMM决定一个线程对共享变量的写入何时对另一个线程可见, JMM定义了线程和主内存之间的抽象关系,线程之间的共享变量存储在主内存(Main),每个线程都有一个私有的本地内存(Local),本地内存中存储了该线程已读/写共享变量的副本,本地内存是JMM的一个抽象概念,它涵盖了缓存,写缓冲区,寄存器以及其他的硬件和编译器优化. 指令序列的重排序为了提供性能,编译器和处理器常常会做重排序, 编译器优化的重排序 指令级并行的重排序, 现代处理器采用指令级并行技术,来将多条指令重叠执行. 处理器重拍序 内存徐彤的重排序, 由于处理器使用缓存和读/写缓冲区,这使得加载和存储操作看上去可能是在乱序执行, 处理器重拍序 对于编译器,JMM的编译器重排序规则禁止特定类型的编译器重排序 对于处理器重排序,JMM的处理器重排序规则会要求Java编译器在生成指令序列时,插入特定类型的内存屏障指令,通过这个禁止特定类型的处理器重排序 JMM把内存屏障指令分为4类: 屏障类型 指令示例 说明 LoadLoad Barriers Load1;LoadLoad;Load2 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作 StoreStore Barriers Store1;StoreStore;Store2 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作 LoadStore Barriers Load1;LoadStore;Store2 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 StoreLoad Barriers Store1;StoreLoad;Load2 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作.它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令 happens-before简介《JSR-133:Java Memory Model and Thread Specification》定义了如下happens-before规则。 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 JMM中,如果一个操作执行的结果需要对另一个操作可见,那么这两个操作之间必须存在happens-before关系. 这里的两个操作既可以是在一个线程之内,也可以是在不同线程之间. 重排序as-if-serial语义 不管怎么重排序(编译器和处理器为了提高并行度)(单线程)程序的执行结果不能被改变,.编译器,runtime和处理器都必须遵守as-if-serial语义. as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。 重排序对多线程的影响 重排序会破坏多线程程序语义.例如下面代码的执行结果: 1234567891011121314151617 public class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; // 1 flag = true;// 2 &#125; public void reader() &#123; if (flag) &#123; // 3 int i = a * a;//4 &#125; &#125;&#125; 线程A执行writer操作,线程B执行reader操作,那么当B执行到4时,能否看见A线程的1操作呢? 当然是不一定的, 1与2,3与4都没有数据依赖关系,所以是可以重排序的.那么就会存在线程B读取a的时候,线程A还没有对a赋值. 在单线程程序中,对存在依赖的操作重排序,不会改变执行结果(as-if-serial语义),但是在多线程程序中,可能就会改变执行结果 数据竞争和顺序一致性java内存模型规范对数据竞争的定义是: 在一个线程中写变量,在另一个线程中读同一个变量,而且写和读没有通过同步来排序. JMM对正确同步的多线程程序的内存一致性做了保证,即程序的执行结果与该程序在顺序一致性内存模型中的执行结果是相同的.这里的同步指的就是 synchronized,volatile和final 未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，在没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其他线程看到的操作执行顺序将不一致。 对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，Null，False）， JMM保证线程读操作读取到的值不会无中生有（Out Of Thin Air）的冒出来。为了实现最小安全性，JVM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象（JVM内部会同步这两个操作）。因此，在已清零的内存空间（Pre-zeroed Memory）分配对象时，域的默认初始化已经完成了。 volatile特性 把对volatile变量的单个读写.看成是使用同一个锁对这些单个读/写操作做了同步. 可见性. 对一个volatile变量的读,总是能看到(任意线程)对这个volatile变量最后的写入 原子性. 对任意单个volatile变量的读/写具有原子性,单类似于volatile++这种复合操作不具有原子性. volatile写-读建立的happens-before关系从JSR-133开始（即从JDK5开始），volatile变量的写-读可以实现线程之间的通信。 从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果：volatile写和锁的释放有相同的内存语义；volatile读与锁的获取有相同的内存语义。 volatile写-读的内存语义当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。 当读一个volatile变量时,JMM会把该线程对应的本地内存置为无效.线程接下来将从主内存中读取共享变量 volatile写和volatile读的内存语义做个总结。 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所做修改的）消息。 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。 volatile内存语义的实现为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 锁锁的释放和获取建立happens-before关系监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 这条规则保证了 获得锁的线程一定能看到上个线程的操作, 锁的释放-获取的内存语义当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。当线程获取锁时，JMM会把该线程对应的本地内存置为无效。 下面对锁释放和锁获取的内存语义做个总结。 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。 final对final于的读和写更像是普通变量的访问 final域的重排序规则对于final域，编译器和处理器要遵守两个重排序规则。 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。 写final域的重排序规则 JMM禁止编译器把final域的写重排序到构造函数之外。 编译器会在final域的写之后，构造函数return之前，插入一个StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。 写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域不具有这个保障. 读final域的重排序规则读final域的重排序规则是，在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作（注意，这个规则仅仅针对处理器）。编译器会在读final域操作的前面插入一个LoadLoad屏障。 读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读包含这个final域的对象的引用。在这个示例程序中，如果该引用不为null，那么引用对象的final域一定已经被A线程初始化过了。 final域为引用类型在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 final语义在处理器的实现写final域的重排序规则会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore障屏。读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障。 请参考 方腾飞/魏鹏/程晓明 Java并发编程的艺术]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整理并发机制实现原理]]></title>
    <url>%2F2018%2F05%2F10%2F%E6%95%B4%E7%90%86%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[volatile 在并发编程中synchronized和volatile都有重要的角色.volatile是轻量级的synchronized,它在多线程开发中保证了共享变量的可见性, 可见性的意思是当一个线程修改一个共享变量时,另外一个线程能读到这个修改的值 volatile变量修饰使用恰当的话,它比synchronized的使用和执行成本更低.因为没有线程的上下文的切换和调度. volatile通过lock前缀的汇编命令来保证可见性. lock前缀命令在多核处理器上会引起两件事 1.将当期处理器缓存行的数据写回到系统内存 2.这个写回内存的操作会使咋其他cpu里缓存了该内存地址的数据无效. 现代处理器为了提供处理数据速度,处理器不直接和内存进行通信,而是先将内存的数据读到内部缓存(L1,L2或其他) 后再操作,但操作完不知道何时写到内存. 如果对volatile变量进行写操作,JVM会向处理器发送一条lock前缀的指令.将这个变量的缓存行的数据写回到系统内存.但是如果其他处理器不知道这个操作,其他处理器看到的数据还是旧的. 所以多核处理器下.为了保证各个处理器的缓存是一直的.就会实现缓存一致性协议.每个处理器通过嗅探在总线上传播数据来检查自己缓存的值是不是过期了,当处理器发现自己缓存行对应的内存地址被修改,就会将当期处理器的缓存行设置为无效状态.这样处理器对这个数据进行修改操作的时候,会重新从系统内存中把数据读到处理器缓存里. synchronized1.6以后jdk对他进行了各种优化.已经不那么重了.synchronized的三种形式: 对于普通同步方法,锁是当前实例对象 对于静态同步方法,锁是当前类的class类 对于同步方法块,锁是Synchonized括号里配置的对象. 当一个线程试图访问代码块时.它首先必须得到锁.退出或者抛异常时必须释放锁.锁到底存在哪里呢?锁里存储的又是什么呢 synchronized用的锁是存在Java对象头里的. 对象头里的Mark Word里默认存储对象的HashCode,分代年龄,锁标记位.运行期间,Mark Word里存储的数据会随着锁标志位的变化而变化. 锁的升级 一种4中状态. 级别从低到高.无锁,偏向锁,轻量级锁,重量级锁.这几个状态会随着竞争情况逐渐升级,锁可以升级但不能降级 偏向锁 经过研究发现.大多数情况下,锁不仅不存在多线程竞争,而且总是由同一个线程多次获得.为了让线程获得锁的代价更低而引入偏向锁.当一个线程访问同步快并获取锁时.会在对象头和栈帧中的锁记录里存储锁偏向的线程ID,以后线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁,只需要简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁, 测试成功,表示当前线程获得了锁.失败,则需要在测试一下Mark Word中偏向锁的标识是否设置成1(表示当前是偏向锁). 没有设置,则使用CAS竞争锁.设置了,则尝试使用CAS将对象头的偏向锁指向当前线程. 偏向锁的撤销. 只有竞争出现才释放锁,所以当其他线程尝试竞争偏向锁时,持有偏向锁的线程才会释放锁.撤销,需要等待全局安全点(在这个时间点上没有正在执行的字节码),它会首先暂停拥有偏向锁的线程,然后检查持有偏向锁的线程是否活着,如果线程不处于活动状态.则将对象头设置成无锁状态.如果线程仍然活着.拥有偏向锁的栈会被执行,遍历偏向对象的锁记录,栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程,要么恢复到无锁或者标记对象不是和作为偏向锁,最后唤醒暂停的线程. 轻量级锁 加锁 线程执行同步块之前,JVM会先在当前线程的栈帧中创建用于存储锁记录的空间,并将对象头中的Mark Word复制到锁记录中,这个过程叫做 Displaced Mark Word. 然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针.如果成功,当前线程获得锁,如果失败,表现其他线程竞争锁,当前线程便尝试自旋来获取锁. 解锁 会使用原子的CAS操作将Displaced Mark Work替换回到对象头,如果成功,泽表示没有竞争发生,如果失败,表示当前锁存在竞争,锁会膨胀成重量级锁, 原子操作的实现原理 不能被进一步分割的最小粒子,而原子操作意为 不可被中断的一个或一系列操作 处理器保证原子操作处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性: 使用总线锁保证原子性, 就是处理器提供了LOCK #信息,当一个处理器在总线上输出此信号时,其他处理器的请求被阻塞,那么该处理器可以独占共享内存, 使用缓存锁保证原子性, 同一时刻我们只需保证对某个内存地址的操作是原子性的即可,总线锁开销比较大,目前处理器在很多场合使用缓存锁代替总线锁来进行优化 所谓缓存锁定,是指内存区域如果被缓存在处理器缓存行中,并且在Lock操作期间被锁定,那么当它执行锁操作回写到内存时,处理器不在总线上声言LOCK#信号,而是修改内部的内存地址,并允许它的缓存一致性机制来保证操作的原子性,因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据,当其他处理器回写已被锁定的缓存行的数据时,会使缓存行无效,]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程]]></title>
    <url>%2F2018%2F05%2F09%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[上下文切换CPU通过给每个线程分配时间片来实现这个机制,时间片就是 CPU 分配给各个线程的时间. CPU通过时间片分配算法来循环执行任务.当前任务执行一个时间片后切换到一下个任务.但是.在切换前会保存上一个任务的状态.以便下次切换回这个任务时,可以在加载这个任务状态 由于有线程创建和上下文切换的开销,导致多线程并不一定比单线程快. 减少上下文切换 无锁并发编程, CAS 算法, JAVA的Atomic包使用CAS算法来更新数据,而不需要加锁 使用最少线程 避免创建不需要的线程,比如任务少,但是创建很多线程,这样会造成大量线程处于等待状态 协程: 在单线程里实现多任务的调度,并在单线程里未出多个任务的切换 避免死锁 避免一个线程同时获取多个锁 避免一个线程在锁内同时占用多个资源,尽量保证每个锁只占用一个资源 尝试使用带时间的锁,例如 lock.tryLock(timeout)来代替使用内部锁机制 对于数据库锁,加锁和解锁必须在一个数据库连接里,否则出现解锁失败的情况 资源限制程序的执行数据受限于计算机硬件资源和软件资源,硬件资源限制有带宽的长传/下载速度,硬盘的读写速度, CPU的处理速度,软件资源限制有数据库的连接数和socket链接数 硬件资源限制:可以考虑用集群,例如 ODPS,Hadoop 软件资源限制: 可以考虑使用资源池将资源复用.]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LocalDate和LocalDateTime]]></title>
    <url>%2F2018%2F05%2F09%2FLocalDate%E5%92%8CLocalDateTime%2F</url>
    <content type="text"><![CDATA[使用LocalDate和LocalTime1234567891011//2017-03-20LocalDate date = LocalDate.of(2017, 3, 20);int year = date.getYear();//2017 返回年份Month month = date.getMonth();//MARCH 返回月份 3月int dayOfMonth = date.getDayOfMonth();//20 返回月中的第几天DayOfWeek dayOfWeek = date.getDayOfWeek();//MONDAY 返回星期几int len = date.lengthOfMonth();//31 返回这个月有多少天boolean leapYear = date.isLeapYear(); //false 是否是闰年//获取系统时间LocalDate now = LocalDate.now(); //相当于 new Date() 123456789//14:33:45LocalTime time = LocalTime.of(14, 33, 45);int hour = time.getHour();//时int minute = time.getMinute();//分int second = time.getSecond();//秒//还可以通过解析代表他们的字符串创建.LocalDate date = LocalDate.parse("2017-03-20");LocalDate dateTime = LocalDate.parse("14:33:20"); 合并日期和时间12345678910LocalDate date = LocalDate.of(2017, 3, 20);LocalTime time = LocalTime.of(14, 33, 45);LocalDateTime dateTime = LocalDateTime.of(2017, 3, 20, 14, 41, 40);LocalDateTime dateTime1 = LocalDateTime.of(date, time);LocalDateTime dateTime2 = date.atTime(14, 33, 45);LocalDateTime dateTime3 = date.atTime(time);LocalDateTime dateTime4 = time.atDate(date);//从LocalDateTime装换为LocalDate和LocalTimeLocalDate localDate = dateTime.toLocalDate();LocalTime localTime = dateTime.toLocalTime(); 操纵,解析和格式化日期1234567891011//以直观的方式操作LocalDate属性LocalDate date = LocalDate.of(2017, 3, 20);//2017-3-20LocalDate localDate = date.withYear(2011);//2011-3-20LocalDate localDate1 = localDate.withDayOfMonth(25);//2011-3-25LocalDate with = localDate1.with(ChronoField.MONTH_OF_YEAR, 9);//2011-9-25//以相对的方式操作LocalDate属性LocalDate localDate2 = date.plusWeeks(1);//一周后 2017-03-27LocalDate localDate3 = localDate2.minusYears(3);//3年前 2014-03-27LocalDate plus = localDate3.plus(6, ChronoUnit.MONTHS);//6个月后 2014-09-27 下面介绍LocalDate LocalTime LocalDateTime Instant的通用方法:123456789101112//Temporal是接口 所有的日期时间类 实现了该接口//from 依据传入的Temporal对象创建对象实例//now 依据系统时钟创建Temporal对象//of 有Temporal对象的某个部分创建该对象的实例//parse 由字符串创建Temporal对象的实例//atOffset 将Temporal对象和某个时区偏移相结合//atZone 将Temporal对象和某个时区相结合//format 使用某个指定的格式器将Temporal对象转换为字符串(Instant类不提供该方法)//get 读取Temporal对象的某一部分//minus 创建Temporal对象的一个副本,通过将当前Temporal对象的值减去一定的时长创建该副本//plus 创建Temporal对象的一个副本,通过将当前Temporal对象的值加上一定的时长创建该副本//with 以该Temporal对象为模板,对某些状态进行修改创建该对象的副本 使用TemporalAdjuster日期和时间 API 提供了大量预定义的TemporalAdjuster,我们可以通过TemporalAdjuster类的静态工方法访问它们. 12345678910111213141516import java.time.LocalDate;import static java.time.temporal.TemporalAdjusters.*;/** * @author Darcy * Created by Administrator on 2017/3/20. */public class TestTemporalAdjuster &#123; public static void main(String[] args) &#123; LocalDate date = LocalDate.of(2017, 3, 20); LocalDate date1 = date.with(nextOrSame(DayOfWeek.SUNDAY));//下一个周日 2017-03-26 LocalDate date3 = date1.with(lastDayOfMonth());//当月最后一天 2017-03-31 System.out.println(date3); &#125;&#125; 常用的工厂方法介绍12345678910111213//dayOfWeekInMonth 创建一个新的日期,它的值为同一个月中每一周的第几天,//firstDayOfMonth 创建一个新的日期,它的值为当月的第一天//firstDayOfNextMonth 创建一个新的日期,它的值为下个月的第一天//firstDayOfNextYear 创建一个新的日期,它的值为明年的第一天//firstDayOfYear 创建一个新的日期,它的值为当年的第一天//firstInMonth 创建一个新的日期 它的值同一个月中,第一个符合星期几要求的值//lastDayOfMonth 创建一个新的日期,它的值为当月的最后一天//lastDayOfNextMonth 创建一个新的日期,它的值为下个月的最后一天//lastDayOfNextYear 创建一个新的日期,它的值为明年的最后一天//lastDayOfYear 创建一个新的日期,它的值为当年的最后一天//lastInMonth 创建一个新的日期 它的值同一个月中,最后一个符合星期几要求的值//next/previous 创建一个新的日期 并将其值设定为日期调整后或者调整前,第一个符合指定星期几要求的日期//nextOrSame/previousOrSame 创建一个新的日期 并将其值设定为日期调整后或者调整前,第一个符合指定星期几要求的日期 如果该日期符合要求,直接返回改对象 定制TemporalAdjuster实现自定义的日期操作定制TemporalAdjuster 能计算明天的日期,同时过滤掉周六和周日 12345678910111213141516171819/** * 定制TemporalAdjuster 能计算明天的日期,同时过滤掉周六和周日 * * @author Darcy * Created by Administrator on 2017/3/20. */public class NextWorkingDay implements TemporalAdjuster &#123; @Override public Temporal adjustInto(Temporal temporal) &#123; //读取当天日期 DayOfWeek dow = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK)); int dayToAdd = 1;//正常情况下增加一天 if (dow == DayOfWeek.FRIDAY) dayToAdd = 3; if (dow == DayOfWeek.SATURDAY) dayToAdd = 2; return temporal.plus(dayToAdd, ChronoUnit.DAYS); &#125;&#125; 使用方式: 12LocalDate date = LocalDate.of(2017, 3, 20);LocalDate with = date.with(new NextWorkingDay()); 还有2种实现方式: 12345678910111213141516171819//或者用lambda表达式 但是这种不利于复用LocalDate with1 = date.with(temporal -&gt; &#123; DayOfWeek dow = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK)); int dayToAdd = 1;//正常情况下增加一天 if (dow == DayOfWeek.FRIDAY) dayToAdd = 3; if (dow == DayOfWeek.SATURDAY) dayToAdd = 2; return temporal.plus(dayToAdd, ChronoUnit.DAYS);&#125;);//便于复用TemporalAdjuster nextWorkingDay = TemporalAdjusters.ofDateAdjuster(temporal -&gt; &#123; //读取当天日期 DayOfWeek dow = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK)); int dayToAdd = 1;//正常情况下增加一天 if (dow == DayOfWeek.FRIDAY) dayToAdd = 3; if (dow == DayOfWeek.SATURDAY) dayToAdd = 2; return temporal.plus(dayToAdd, ChronoUnit.DAYS);&#125;);date.with(nextWorkingDay); 打印输出及解析日期-时间对象1234567891011121314151617181920212223LocalDate date = LocalDate.of(2017, 3, 20);String format = date.format(DateTimeFormatter.BASIC_ISO_DATE);//20170320String format2 = date.format(DateTimeFormatter.ISO_LOCAL_DATE);//2017-03-20LocalDate.parse("20170320", DateTimeFormatter.BASIC_ISO_DATE);LocalDate.parse("2017-03-20", DateTimeFormatter.ISO_LOCAL_DATE);//按照某种格式创建DateTimeFormatterDateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern("dd/MM/yyyy");String format1 = date.format(dateTimeFormatter);LocalDate parse = LocalDate.parse(format1, dateTimeFormatter);//如果需要更加细粒度的控制,DateTimeFormatterBuilder类提供了更复杂的格式器,可以使用 一步一步的构造自己的格式器DateTimeFormatter formatter = new DateTimeFormatterBuilder() .appendText(ChronoField.DAY_OF_MONTH) .appendLiteral(". ") .appendText(ChronoField.MONTH_OF_YEAR) .appendLiteral(" ") .appendText(ChronoField.YEAR) .parseCaseInsensitive()//对大小写不敏感 .toFormatter(Locale.CHINA);LocalDate date3 = LocalDate.of(2017, 3, 20);String format3 = date3.format(formatter); //20. 三月 2017 处理不同时区的历法12345678910111213141516171819//地区ID都为&#123;区域&#125;/&#123;城市&#125;的格式,这些地区集合的设定都由英特网编号分配机构(IANA)的市区数据库提供ZoneId romeZone = ZoneId.of("Europe/Rome");//可以通过Java8的新方法 将老的时区装换为ZoneIdZoneId zoneId = TimeZone.getDefault().toZoneId();LocalDate date = LocalDate.of(2017, 3, 20);ZonedDateTime zonedDateTime = date.atStartOfDay(romeZone);LocalDateTime dateTime = LocalDateTime.of(2017, 3, 20, 14, 41, 40);ZonedDateTime zonedDateTime1 = dateTime.atZone(romeZone);Instant now = Instant.now();ZonedDateTime zonedDateTime2 = now.atZone(romeZone);//使用别的日历系统//java8 另外提供了4中其他的日历系统 ThaiBuddhistDate MinguoDate JapaneseDate HijrahDateThaiBuddhistDate now1 = ThaiBuddhistDate.now();//ThaiBuddhist BE 2560-03-20MinguoDate now2 = MinguoDate.now();//Minguo ROC 106-03-20JapaneseDate now3 = JapaneseDate.now();//Japanese Heisei 29-03-20HijrahDate now4 = HijrahDate.now();//Hijrah-umalqura AH 1438-06-21JapaneseDate from = JapaneseDate.from(date); //Japanese Heisei 29-03-20]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>java8</tag>
      </tags>
  </entry>
</search>
